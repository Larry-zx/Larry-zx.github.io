<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>StyTR2 | 扁同学不发言的个人博客</title><meta name="keywords" content="风格迁移,cs.CV,深度学习,Transformer"><meta name="author" content="扁同学不发言"><meta name="copyright" content="扁同学不发言"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Abstract 风格转换的目标是在保持原有内容的同时，在风格参照的指导下呈现出具有艺术特征的图像 由于卷积神经网络（CNN）的局部性，很难提取和维护输入图像的全局信息。 因此，传统的神经风格转换方法面临着有偏见的内容表示 为了解决这个关键问题，我们提出了一种基于转换器的方法，称为StyTr2 &gt; 将输入图像的长期依赖性考虑到图像样式传输中 与其他视觉任务的视觉转换器不同 StyTr2包含两">
<meta property="og:type" content="article">
<meta property="og:title" content="StyTR2">
<meta property="og:url" content="http://www.larryai.com/2022/05/06/StyTR2/index.html">
<meta property="og:site_name" content="扁同学不发言的个人博客">
<meta property="og:description" content="Abstract 风格转换的目标是在保持原有内容的同时，在风格参照的指导下呈现出具有艺术特征的图像 由于卷积神经网络（CNN）的局部性，很难提取和维护输入图像的全局信息。 因此，传统的神经风格转换方法面临着有偏见的内容表示 为了解决这个关键问题，我们提出了一种基于转换器的方法，称为StyTr2 &gt; 将输入图像的长期依赖性考虑到图像样式传输中 与其他视觉任务的视觉转换器不同 StyTr2包含两">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.larryai.com/2022/05/06/StyTR2/%E5%B0%81%E9%9D%A2.png">
<meta property="article:published_time" content="2022-05-06T12:18:40.000Z">
<meta property="article:modified_time" content="2022-05-07T00:11:38.306Z">
<meta property="article:author" content="扁同学不发言">
<meta property="article:tag" content="风格迁移">
<meta property="article:tag" content="cs.CV">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.larryai.com/2022/05/06/StyTR2/%E5%B0%81%E9%9D%A2.png"><link rel="shortcut icon" href="/img/bian_logo.png"><link rel="canonical" href="http://www.larryai.com/2022/05/06/StyTR2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'StyTR2',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-07 08:11:38'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="扁同学不发言的个人博客" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/%E6%96%B0%E4%B8%80.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">40</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 专栏</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/picture/"><i class="fa-fw fas fa-image"></i><span> 图库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2022/05/06/StyTR2/%E5%B0%81%E9%9D%A2.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">扁同学不发言的个人博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 专栏</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/picture/"><i class="fa-fw fas fa-image"></i><span> 图库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">StyTR2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-06T12:18:40.000Z" title="发表于 2022-05-06 20:18:40">2022-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-07T00:11:38.306Z" title="更新于 2022-05-07 08:11:38">2022-05-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="StyTR2"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="abstract">Abstract</h1>
<p><strong><em>风格转换的目标是在保持原有内容的同时，在风格参照的指导下呈现出具有艺术特征的图像</em></strong></p>
<p>由于卷积神经网络（CNN）的局部性，很难提取和维护输入图像的全局信息。</p>
<p>因此，<strong>传统的神经风格转换方法面临着有偏见的内容表示</strong></p>
<p>为了解决这个关键问题，我们提出了一种基于转换器的方法，称为StyTr2 &gt;
将输入图像的长期依赖性考虑到图像样式传输中</p>
<p>与其他视觉任务的视觉转换器不同
<strong>StyTr2包含两个不同的转换器编码器，分别为内容和样式生成特定于域的序列</strong>
在编码器之后
<strong>采用多层转换器解码器根据样式序列对内容序列进行样式化</strong></p>
<p>我们还分析了现有位置编码方法的不足，提出了<strong>内容感知位置编码（CAPE）</strong>
&gt; 它具有尺度不变性，更适合于图像样式传输任务</p>
<p>定性和定量实验表明，与最先进的基于CNN和基于流的方法相比，所提出的StyTr2是有效的。</p>
<p>代码和模型可在https://github.com/diyiiyiii/StyTR-2</p>
<h1 id="introduce">1.Introduce</h1>
<p>此处省略一些内容 详细可查看原论文</p>
<p>总之，我们的主要贡献包括 -
一个名为StyTr2的基于转换器的风格转换框架，以生成风格化结果，并保留输入内容图像的结构和细节
- 一种基于内容的位置编码方案，具有尺度不变性，适用于样式转换任务 -
综合实验表明，StyTr2形成了基线方法，并以理想的内容结构和风格模式取得了显著的效果</p>
<h1 id="relate-work">2.Relate Work</h1>
<ul>
<li>图像风格迁移</li>
<li>视觉任务的transformer &gt;
在本文中，我们介绍了用于样式转换任务的基于变换器的结构，可以将其视为图像块的序列到序列生成</li>
<li>位置编码 &gt;
在本文中，我们提出了一种基于内容的位置编码机制，该机制具有尺度不变性，更适合于图像生成任务</li>
</ul>
<h1 id="method">3.Method</h1>
<p>为了利用transformers的功能捕获图像特征的长距离依赖性以进行样式转换</p>
<p>我们将该问题描述为一个连续的补丁生成任务</p>
<p>给定一个内容图像image (H,W,3) 并显示一个样式图像style (H,W,3)</p>
<p>我们将两幅图像分割成块patch（类似于NLP任务中的标记）</p>
<p>使用线性投影层将输入块投影到型如L×dim中嵌入 <span
class="math inline">\(\varepsilon\)</span> 的序列特征中</p>
<p><span class="math display">\[
L = \frac{H\times W}{m\times m}
\]</span></p>
<blockquote>
<p>L是特征序列的长度</p>
<p>m=8是patches的size</p>
<p>dim是特征序列的维度</p>
</blockquote>
<h2 id="content-aware-positional-encodingcape">3.1Content-Aware
Positional Encoding（CAPE）</h2>
<p>当使用transformer-based的模型时，位置编码（PE）应包含在输入序列中，以获取结构信息</p>
<p>第i个patch和第j个patch的注意力得分计算如下：</p>
<p><img src="公式1.png" /> &gt; Wq 用于查询的参数矩阵 &gt;
Wk用于密钥计算的参数矩阵 &gt; Pi 第i个一维的PE</p>
<blockquote>
<p>在二维情况下两个像素点(xi,yi) (xj,yj)之间的位置相对关系:</p>
</blockquote>
<p><img src="公式2.png" /></p>
<ul>
<li><span class="math inline">\(w_{k} =
\frac{1}{1000^{(\frac{2k}{128})}}\)</span></li>
<li>d = 512</li>
</ul>
<p><strong>两个patch之间的位置相对关系仅取决于它们的空间距离</strong></p>
<p>因此，我们提出两个问题:</p>
<p><strong>第一</strong></p>
<p>对于图像生成任务，在计算PE时是否应该考虑图像语义？</p>
<p>传统的PE是为按逻辑排列的句子设计的，但图像补丁是根据内容组织的。</p>
<p>我们将两个patch之间的距离表示为d( · , · )</p>
<p><img src="fig3.png" /></p>
<p>在图3(a)的右侧</p>
<p><strong>d((x0,y3),(x1,y3))</strong>(红色和绿色补丁) 和
<strong>d((x0,y3),(x3,y3))</strong>(红色和青色补丁)之间的差异应该很小</p>
<blockquote>
<p>因为我们预计类似的内容patch会有类似的样式化结果</p>
</blockquote>
<p><strong>第二</strong></p>
<p>当输入图像的大小呈指数增长时
传统的正弦位置编码是否仍然适用于视觉任务？</p>
<p>如图3(a)所示</p>
<p>调整图像大小时
相同位置的面片（用蓝色小矩形表示）之间的相对距离可能会发生显著变化</p>
<p>这可能不适用于视觉任务中的多尺度方法</p>
<p>为此，我们提出了<strong>内容感知位置编码（CAPE）</strong></p>
<blockquote>
<p>它是尺度不变的，更适合风格迁移任务</p>
</blockquote>
<p>与仅考虑补丁相对距离的正弦 PE 不同，CAPE 以图像内容的语义为条件</p>
<p>我们假设使用 n × n 位置编码足以表示图像的语义</p>
<p>对于图像 <span class="math inline">\(I \in \mathbb{R}^{H \times W
\times 3}\)</span> , 我们将固定的 n × n 位置编码重新缩放为<span
class="math inline">\(\frac{H}{m} \times \frac{H}{m}\)</span> ，如图
3(b) 所示</p>
<p>这样，<strong>各种图像尺度就不会影响两个补丁之间的空间关系</strong></p>
<p>补丁 (x, y) 的 CAPE 即<strong>PCA(x, y)</strong>被表述为</p>
<p><img src="公式3.png" /></p>
<ul>
<li><span class="math inline">\(AvgPool_{n\times n}\)</span>
是平均池化函数</li>
<li><span class="math inline">\(\mathcal{F}_{pos}\)</span> 是 1 × 1
卷积运算，用作可学习的位置编码函数</li>
<li><span class="math inline">\(\mathcal{P}_{\mathcal{L}}\)</span>
是遵循序列<span
class="math inline">\(\varepsilon\)</span>的可学习PE</li>
<li>在我们的实验中n 设置为 18</li>
<li>$a_{kl} $是插值权重，s 是相邻块的数量</li>
<li>最后，我们将 <span class="math inline">\(P_{CA_{i}}\)</span> 添加到
<span class="math inline">\(\varepsilon_{i}\)</span>，作为第 i
个补丁在像素位置 (x, y) 的最终特征嵌入</li>
</ul>
<h2 id="style-transfer-transformer">3.2 Style Transfer Transformer</h2>
<h4 id="transformer-编码器">3.2.1 Transformer 编码器</h4>
<p>我们通过使用基于 Transformer 的结构来学习
<strong>顺序视觉表示</strong> 来
<strong>捕获图像块的长期依赖关系</strong></p>
<p>与其他视觉任务不同，tjr风格迁移任务的输入来自两个不同的领域，分别对应于自然图像和艺术绘画</p>
<p>因此，StyTr2
有两个转换器编码器来<strong>编码特定领域的特征</strong>，用于在下一阶段将序列从一个域转换到另一个域</p>
<p>给定输入内容序列 <span class="math inline">\(Z_c = \{
\varepsilon_{ci} + \mathcal{P_{CA}}_i\}\)</span> 的嵌入</p>
<p>我们首先将其输入到转换器编码器中</p>
<p>编码器的每一层都由一个多头自注意力模块（MSA）和一个前馈网络（FFN）组成</p>
<p>输入序列被编码为查询（Q）、键（K）和值（V）： <span
class="math display">\[
Q =Z_cW_q , K=Z_cW_k , V=Z_cW_v
\]</span></p>
<ul>
<li><span class="math inline">\(W_q , W_k , W_v \in \mathbb{R}^{C \times
d_{head}}\)</span></li>
</ul>
<p>multi-head Attention的计算方式</p>
<p><img src="4.png" /></p>
<ul>
<li><span class="math inline">\(W_0 \in \mathbb{R}^{C \times
C}\)</span>是可学习的参数</li>
<li>N 是注意力头的数量，并且 <span class="math inline">\(d_{head} =
\frac{C}{N}\)</span></li>
</ul>
<p>应用残差连接来获得编码的内容序列 Yc</p>
<p><img src="5.png" /></p>
<ul>
<li>FFN是激活函数为relu的MLP</li>
<li>LN被应用到每一个块的末尾</li>
</ul>
<p>类似地，输入样式序列 Zs = {Es1, Es2, ..., EsL}
的嵌入按照相同的计算过程编码为序列 Ys</p>
<p>只是不考虑位置编码，因为我们不需要维护 最终输出中的输入样式</p>
<h4 id="transformer-解码器">3.2.2 Transformer 解码器</h4>
<p>我们的转换器解码器用于根据编码样式序列 Ys 以回归方式翻译编码内容序列
Yc</p>
<p>与 NLP
任务中的自回归过程不同，我们一次将所有顺序补丁作为输入来预测输出</p>
<p>如图 3(a) 所示，每个 Transformer 解码器层包含两个 MSA 层和一个
FFN</p>
<p>我们的 Transformer 解码器的输入包括编码后的内容序列</p>
<p>即 <span class="math inline">\(\bar{Y_c}\)</span> = {Yc1 + PCA1, Yc2
+ PCA2, ..., YcL + PCAl} 以及样式序列 Ys = {Ys1, Ys2, ..., YSL}</p>
<blockquote>
<p>我们使用<strong>内容序列生成查询 Q，并使用样式序列生成键 K 和值
V</strong></p>
</blockquote>
<p><span class="math display">\[
Q =\bar{Y_c}W_q , K=Y_sW_k , V=Y_sW_v
\]</span></p>
<p>然后，transformer解码器的输出序列X可以计算为</p>
<p><img src="6.png" /></p>
<h4 id="cnn解码器">3.2.3 CNN解码器</h4>
<p>Transformer 的输出序列 X 的形状为 【HW/64 , C】</p>
<p>我们没有直接对输出序列进行上采样来构造最终结果</p>
<p>而是使用三层 CNN 解码器来细化 Transformer 解码器的输出</p>
<p>对于每一层，我们通过采用包括 3 × 3 Conv + ReLU + 2 × Upsample
在内的一系列操作来扩大规模</p>
<p>最后，我们可以得到分辨率为 H × W × 3 的最终结果</p>
<h2 id="network-optimization">3.3 Network Optimization</h2>
<p>生成的结果应保持原始内容结构和参考样式模式</p>
<p>因此，我们构造了两个不同的感知损失项来衡量</p>
<ul>
<li><p>输出图像 Io 和输入内容图像 Ic
之间的<strong>内容差异</strong></p></li>
<li><p>Io 和输入风格参考 Is 之间的<strong>风格差异</strong></p></li>
</ul>
<p>我们使用由预训练的 VGG
模型提取的特征图来构建之后的内容损失和样式损失</p>
<p>内容感知损失 Lc 定义为</p>
<p><img src="7.png" /></p>
<ul>
<li>其中<span class="math inline">\(\phi_i()\)</span> 表示从预训练 VGG19
中的第 i 层提取的特征，<span class="math inline">\(N_l\)</span>
是层数。</li>
</ul>
<p>风格感知损失 Ls 定义为</p>
<p><img src="8.png" /></p>
<ul>
<li>其中 μ(·) 和 σ(·) 分别表示提取特征的均值和方差。</li>
</ul>
<p>我们还采用<strong>身份损失</strong>来学习更丰富、更准确的内容和风格表示</p>
<p>具体来说，我们将两个相同的内容（风格）图像放入 StyTr2，生成的输出
Icc(Iss) 应该与输入 Ic(Is) 相同</p>
<p>因此，我们计算两个身份损失项来衡量 Ic(Is) 和 Icc(Iss)
之间的差异：</p>
<p><img src="9.png" /></p>
<p>通过最小化以下函数来优化整个网络：</p>
<p><img src="10.png" /></p>
<p>我们将 λc、λs、λid1 和 λid2 设置为 10、7、50 和
1，以减轻幅度差异的影响</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://www.larryai.com">扁同学不发言</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.larryai.com/2022/05/06/StyTR2/">http://www.larryai.com/2022/05/06/StyTR2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.larryai.com" target="_blank">扁同学不发言的个人博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/">风格迁移</a><a class="post-meta__tags" href="/tags/cs-CV/">cs.CV</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/Transformer/">Transformer</a></div><div class="post_share"><div class="social-share" data-image="/2022/05/06/StyTR2/%E5%B0%81%E9%9D%A2.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/05/16/video2pic/"><img class="prev-cover" src="/2022/05/16/video2pic/a13.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">OPENCV-视频与图像的转换</div></div></a></div><div class="next-post pull-right"><a href="/2022/05/06/Pycharm%E5%BF%AB%E6%8D%B7%E9%94%AE/"><img class="next-cover" src="/2022/05/06/Pycharm%E5%BF%AB%E6%8D%B7%E9%94%AE/keychron.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Pycharm快捷键</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/05/04/Image%20Style%20Transfer/" title="Image Style Transfer"><img class="cover" src="/2022/05/04/Image%20Style%20Transfer/fig1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">Image Style Transfer</div></div></a></div><div><a href="/2022/05/04/MGUIT/" title="MGUIT"><img class="cover" src="/2022/05/04/MGUIT/1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">MGUIT</div></div></a></div><div><a href="/2022/05/04/PLST-SR/" title="Perceptual Losses for Real-Time Style Transfer and Super-Resolution"><img class="cover" src="https://pic4.zhimg.com/v2-8e9936fdcfd4e8371720b9834f8f97d7_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">Perceptual Losses for Real-Time Style Transfer and Super-Resolution</div></div></a></div><div><a href="/2022/05/04/ChipGAN/" title="ChipGAN"><img class="cover" src="/2022/05/04/ChipGAN/fig1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">ChipGAN</div></div></a></div><div><a href="/2022/05/04/GanGANv2/" title="GanGANv2"><img class="cover" src="/2022/05/04/GanGANv2/3.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">GanGANv2</div></div></a></div><div><a href="/2022/05/04/MASA-SR/" title="MASA-SR"><img class="cover" src="https://pic1.zhimg.com/v2-3486f59df8faa40673ddcbe4f5212844_1440w.jpg?source=172ae18b" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">MASA-SR</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/%E6%96%B0%E4%B8%80.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">扁同学不发言</div><div class="author-info__description">AIArt@HDU</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">40</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Larry-zx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Larry-zx" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://www.zhihu.com/people/larry-19-22-31" target="_blank" title="Zhihu"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="https://mobile.twitter.com/Larry37722397" target="_blank" title="Twitter"><i class="fa-brands fa-twitter"></i></a><a class="social-icon" href="https://www.youtube.com/channel/UCzDXYobI-mUP5WgvA37er6A" target="_blank" title="Youtube"><i class="fa-brands fa-youtube"></i></a><a class="social-icon" href="https://www.kaggle.com/larryzxai" target="_blank" title="Kaggle"><i class="fa-brands fa-kaggle"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Hi , welcome to my blog 🤔</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#introduce"><span class="toc-text">1.Introduce</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#relate-work"><span class="toc-text">2.Relate Work</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#method"><span class="toc-text">3.Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#content-aware-positional-encodingcape"><span class="toc-text">3.1Content-Aware
Positional Encoding（CAPE）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#style-transfer-transformer"><span class="toc-text">3.2 Style Transfer Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#transformer-%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-text">3.2.1 Transformer 编码器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#transformer-%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-text">3.2.2 Transformer 解码器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cnn%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-text">3.2.3 CNN解码器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#network-optimization"><span class="toc-text">3.3 Network Optimization</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/08/01/ucart-ai/" title="Understanding and Creating Art with AI"><img src="/2022/08/01/ucart-ai/fig1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Understanding and Creating Art with AI"/></a><div class="content"><a class="title" href="/2022/08/01/ucart-ai/" title="Understanding and Creating Art with AI">Understanding and Creating Art with AI</a><time datetime="2022-08-01T07:37:14.000Z" title="发表于 2022-08-01 15:37:14">2022-08-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/19/OmniArt1/" title="OmniArt: Multi-task Deep Learning for Artistic Data Analysis"><img src="/2022/07/19/OmniArt1/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OmniArt: Multi-task Deep Learning for Artistic Data Analysis"/></a><div class="content"><a class="title" href="/2022/07/19/OmniArt1/" title="OmniArt: Multi-task Deep Learning for Artistic Data Analysis">OmniArt: Multi-task Deep Learning for Artistic Data Analysis</a><time datetime="2022-07-19T13:52:50.000Z" title="发表于 2022-07-19 21:52:50">2022-07-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/16/SEAN/" title="SEAN:Image Synthesis With Semantic Region-Adaptive Normalization"><img src="/2022/05/16/SEAN/fig4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SEAN:Image Synthesis With Semantic Region-Adaptive Normalization"/></a><div class="content"><a class="title" href="/2022/05/16/SEAN/" title="SEAN:Image Synthesis With Semantic Region-Adaptive Normalization">SEAN:Image Synthesis With Semantic Region-Adaptive Normalization</a><time datetime="2022-05-16T09:53:19.000Z" title="发表于 2022-05-16 17:53:19">2022-05-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/16/%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/" title="图像的三种数据格式"><img src="/2022/05/16/%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/kil.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像的三种数据格式"/></a><div class="content"><a class="title" href="/2022/05/16/%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/" title="图像的三种数据格式">图像的三种数据格式</a><time datetime="2022-05-16T01:56:13.000Z" title="发表于 2022-05-16 09:56:13">2022-05-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/16/video2pic/" title="OPENCV-视频与图像的转换"><img src="/2022/05/16/video2pic/a13.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OPENCV-视频与图像的转换"/></a><div class="content"><a class="title" href="/2022/05/16/video2pic/" title="OPENCV-视频与图像的转换">OPENCV-视频与图像的转换</a><time datetime="2022-05-16T01:27:34.000Z" title="发表于 2022-05-16 09:27:34">2022-05-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By 扁同学不发言</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="#">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'H2XPsPqmRrVmO7wLvvlhsgyi-gzGzoHsz',
      appKey: 'qUDSqSmyX1JHlTwo3fQLXiSU',
      avatar: 'monsterid',
      serverURLs: 'https://h2xpspqm.lc-cn-n1-shared.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script>((window.gitter = {}).chat = {}).options = {
  disableDefaultChat: true,
};
document.addEventListener('gitter-sidecar-ready', (e) => {
  const GitterChat = e.detail.Chat
  let chat

  function initGitter () {
    chat = new GitterChat({
      room: 'babylearnDL/community',
      activationElement: '#chat_btn'
    });
  }

  initGitter()

  if (false) {
    document.addEventListener('pjax:complete', () => {
      chat.destroy()
      initGitter()
    })
  }

})</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async="async" defer="defer"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>