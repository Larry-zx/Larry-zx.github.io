<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Vision GNN-An Image is Worth Graph of Nodes | 扁同学不发言的个人博客</title><meta name="keywords" content="cs.CV,深度学习,GNN,图像分类"><meta name="author" content="扁同学不发言"><meta name="copyright" content="扁同学不发言"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Abstract 网络架构在基于深度学习的计算机视觉系统中起着关键作用。 广泛使用的卷积神经网络和transformer将图像视为网格或序列结构，不灵活地捕捉不规则和复杂的物体。 在本文中，我们建议将图像表示为图形结构，并引入新的 Vision GNN (ViG) 架构来提取视觉任务的图形级特征。 我们首先将图像分割成许多块，这些块被视为节点，并通过连接最近的邻居来构造一个图。 基于图像的图表示，">
<meta property="og:type" content="article">
<meta property="og:title" content="Vision GNN-An Image is Worth Graph of Nodes">
<meta property="og:url" content="http://www.larryai.com/2022/08/04/ViG/index.html">
<meta property="og:site_name" content="扁同学不发言的个人博客">
<meta property="og:description" content="Abstract 网络架构在基于深度学习的计算机视觉系统中起着关键作用。 广泛使用的卷积神经网络和transformer将图像视为网格或序列结构，不灵活地捕捉不规则和复杂的物体。 在本文中，我们建议将图像表示为图形结构，并引入新的 Vision GNN (ViG) 架构来提取视觉任务的图形级特征。 我们首先将图像分割成许多块，这些块被视为节点，并通过连接最近的邻居来构造一个图。 基于图像的图表示，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.larryai.com/2022/08/04/ViG/fig2.png">
<meta property="article:published_time" content="2022-08-04T11:33:23.000Z">
<meta property="article:modified_time" content="2022-08-04T11:36:20.341Z">
<meta property="article:author" content="扁同学不发言">
<meta property="article:tag" content="cs.CV">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="GNN">
<meta property="article:tag" content="图像分类">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.larryai.com/2022/08/04/ViG/fig2.png"><link rel="shortcut icon" href="/img/bian_logo.png"><link rel="canonical" href="http://www.larryai.com/2022/08/04/ViG/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Vision GNN-An Image is Worth Graph of Nodes',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-04 19:36:20'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="扁同学不发言的个人博客" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/%E6%96%B0%E4%B8%80.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 专栏</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/picture/"><i class="fa-fw fas fa-image"></i><span> 图库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2022/08/04/ViG/fig2.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">扁同学不发言的个人博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 专栏</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/picture/"><i class="fa-fw fas fa-image"></i><span> 图库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Vision GNN-An Image is Worth Graph of Nodes</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-04T11:33:23.000Z" title="发表于 2022-08-04 19:33:23">2022-08-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-04T11:36:20.341Z" title="更新于 2022-08-04 19:36:20">2022-08-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Vision GNN-An Image is Worth Graph of Nodes"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="abstract">Abstract</h2>
<p>网络架构在基于深度学习的计算机视觉系统中起着关键作用。</p>
<p>广泛使用的卷积神经网络和transformer将图像视为网格或序列结构，不灵活地捕捉不规则和复杂的物体。</p>
<p>在本文中，我们建议将图像表示为图形结构，并引入新的 Vision GNN (ViG)
架构来提取视觉任务的图形级特征。</p>
<p>我们首先将图像分割成许多块，这些块被视为节点，并通过连接最近的邻居来构造一个图。</p>
<p>基于图像的图表示，我们构建了我们的 ViG
模型来在所有节点之间转换和交换信息。</p>
<p>ViG 由两个基本模块组成：</p>
<ul>
<li><p>带有图卷积的 Grapher 模块，用于聚合和更新图信息</p></li>
<li><p>带有两个线性层的 FFN 模块，用于节点特征变换</p></li>
</ul>
<p>ViG 的各向同性和金字塔结构都是用不同的模型大小构建的。</p>
<p>图像识别和目标检测任务的大量实验证明了我们的 ViG 架构的优越性</p>
<p>我们希望 GNN
在一般视觉任务上的这项开创性研究能为未来的研究提供有益的启发和经验。</p>
<h2 id="introduction">1.Introduction</h2>
<p>在现代计算机视觉系统中，卷积神经网络 (CNN) 曾经是事实上的标准网络架构
[27、25、16]</p>
<p>最近，针对视觉任务 [8, 3] 引入了具有注意力机制的
Transformer，并获得了具有竞争力的性能。</p>
<p>基于 MLP（多层感知器）的视觉模型 [47、48]
在不使用卷积或自注意力的情况下也可以很好地工作。</p>
<p>这些进展将视觉模型推向了前所未有的高度。</p>
<p>不同的网络以不同的方式处理输入图像。</p>
<p>如图 1 所示，图像数据通常表示为欧几里得空间中的规则像素网格。</p>
<p>CNNs [27] 在图像上应用滑动窗口并引入移位不变性和局部性。
最近的视觉转换器 [8] 或 MLP [47] 将图像视为一系列补丁。</p>
<p>例如，ViT [8] 将一个 224 × 224 的图像划分为多个 16 × 16
的块，并形成一个长度为 196 的序列作为输入。</p>
<p><img src="fig1.png" /></p>
<p>我们以更灵活的方式处理图像，而不是常规的网格或序列表示。</p>
<p>计算机视觉的一项基本任务是识别图像中的对象。</p>
<p>由于对象通常不是形状不规则的正方形，因此以前的网络（如 ResNet 和
ViT）中常用的网格或序列结构是冗余且不灵活的处理它们。</p>
<p>一个物体可以看成是多个部分的组合，例如，一个人大致可以分为头、上身、手臂和腿。</p>
<p>这些由关节连接起来的部分自然形成了图结构。
通过分析图表，我们能够识别人类。</p>
<p>此外，图是一种广义的数据结构，网格和序列可以看作图的一种特殊情况。</p>
<p>将图像作为图形查看对于视觉感知来说更加灵活和有效。</p>
<p>基于图像的图表示，我们为视觉任务构建了视觉图神经网络（简称ViG）。</p>
<p>我们没有将每个像素视为会导致节点过多（&gt;10K）的节点，而是将输入图像划分为多个补丁并将每个补丁视为一个节点。</p>
<p>在构建图像块图之后，我们使用我们的 ViG
模型在所有节点之间转换和交换信息。</p>
<p>ViG 的基本单元包括两部分：Grapher 和 FFN（前馈网络）模块。</p>
<p>Grapher 模块是基于图卷积构建的，用于图信息处理。</p>
<p>为了缓解传统 GNN 的过度平滑现象，FFN
模块用于节点特征转换和鼓励节点多样性。</p>
<p>借助 Grapher 和 FFN 模块，我们以各向同性和金字塔方式构建 ViG
模型。</p>
<p>在实验中，我们展示了 ViG
模型在图像分类和对象检测等视觉任务上的有效性。</p>
<p>例如，我们的 Pyramid ViG-S 在 ImageNet 分类任务上达到 82.1% 的 top-1
准确率</p>
<blockquote>
<p>优于具有代表性的 CNN (ResNet [16])、MLP (CycleMLP [4]) 和 Transformer
(Swin-T [33]) 类似的 FLOP（大约 4.5G）。</p>
</blockquote>
<p>据我们所知，我们的工作是第一个成功地将图神经网络应用于大规模视觉任务的工作。
我们希望我们的工作能够激发社区进一步探索更强大的网络架构。</p>
<h2 id="related-work">2.Related Work</h2>
<p>在本节中，我们首先重新审视计算机视觉中的骨干网络。
然后我们回顾了图神经网络的发展，特别是 GCN 及其在视觉任务中的应用。</p>
<h4 id="cnn-transformer-and-mlp-for-vision">2.1 CNN, Transformer and MLP
for Vision</h4>
<p>计算机视觉中的主流网络架构曾经是卷积网络 [27,25,16]。</p>
<p>从 LeNet [27] 开始，CNN 已成功用于各种视觉任务，例如图像分类
[25]、对象检测 [40] 和语义分割 [34]。</p>
<p>CNN 架构在过去十年中发展迅速。 代表作品包括 ResNet [16]、MobileNet
[20] 和 NAS [68]。</p>
<p>从 2020 年开始，为视觉任务引入了视觉转换器 [13, 8, 3]。</p>
<p>从那时起，提出了许多 ViT [8] 的变体来提高视觉任务的性能。</p>
<p>主要改进包括金字塔架构 [54, 33]、局部注意力 [14, 33] 和位置编码
[58]。</p>
<p>受视觉转换器的启发，MLP 也在计算机视觉中得到了探索 [47, 48]。</p>
<p>借助专门设计的模块 [4, 30, 11, 46]，MLP
可以实现具有竞争力的性能，并可以处理对象检测和分割等一般视觉任务。</p>
<h4 id="graph-neural-network">2.2 Graph Neural Network</h4>
<p>最早的图神经网络最初是在 [10, 42] 中概述的。</p>
<p>Micheli [36]
通过架构复合非递归层提出了基于空间的图卷积网络的早期形式。</p>
<p>近年来，已经引入了基于空间的 GCN 的变体，例如 [37, 1, 9]。</p>
<p>基于光谱的 GCN 最早由 Bruna 等人提出。 [2]
介绍了基于谱图理论的图卷积。</p>
<p>从那时起，已经提出了许多改进和扩展基于谱的 GCN 的工作 [17, 6,
24]。</p>
<p>G<strong>CN 通常应用于图数据，例如社交网络 [12]、引文网络 [43]
和生化图 [53]。</strong></p>
<p><strong>GCN在计算机视觉领域的应用主要包括点云分类、场景图生成、动作识别等</strong>。</p>
<p>点云是空间中的一组 3D 点，通常由 LiDAR 扫描收集。</p>
<p>GCN 已被探索用于分类和分割点云 [26, 55]。</p>
<p><strong>场景图生成旨在将输入图像解析为带有对象及其关系的图，这通常通过结合对象检测器和
GCN [60, 63] 来解决。</strong></p>
<p>通过处理链接人体关节的自然形成图，GCN 被用于人体动作识别任务 [23,
62]。</p>
<p>GCN 只能通过自然构建的图来处理特定的视觉任务。</p>
<p>对于计算机视觉中的一般应用，我们需要一个基于 GCN
的骨干网络来直接处理图像数据。</p>
<h2 id="approach">3.Approach</h2>
<p>在本节中，我们将描述如何将图像转换为graph，并介绍视觉 GNN
架构来学习视觉表示。</p>
<p><img src="fig2.png" /></p>
<h3 id="vig-block">3.1 ViG Block</h3>
<h4 id="graph-structure-of-image">3.1.1 Graph Structure of Image</h4>
<p>对于大小为 H × W × 3 的图像，我们将其划分为 N 个块。</p>
<p>通过将每个补丁转换为特征向量<span class="math inline">\(x_i \in
\mathbb{R}^{D}\)</span>，我们有 X = [x1, x2, ···, xN] 其中 D
是特征维度，i = 1, 2,···, N。</p>
<p>这些特征可以看作是一组无序节点，记为 V = {v1, v2, ···, vN}。</p>
<p>对于每个节点 vi，<strong>我们找到它的 K 个最近邻居 N
(vi)</strong>，并为所有 vj ∈ N (vi) 添加一条从 vj 指向 vi 的边 eji。</p>
<p>然后我们得到一个图 G = (V, E)，其中 E 表示所有边。</p>
<p>下面我们将图构建过程表示为 G = G(X)。
通过将图像视为graph数据，我们探索如何利用 GNN 来提取其表示。</p>
<p>图像的图表示的优点包括：</p>
<ul>
<li><p>图是一种广义的数据结构，网格和序列可以看作图的一个特例</p></li>
<li><p>graph比网格或序列更灵活地对复杂对象进行建模，因为图像中的对象通常不是正方形，形状不规则</p></li>
<li><p>一个物体可以看成是由多个部分组成的（例如，一个人可以大致分为头、上身、手臂和腿），图结构可以构建这些部分之间的联系</p></li>
<li><p>GNN 的高级研究可以转移到解决视觉任务</p></li>
</ul>
<h4 id="graph-level-processing">3.1.2 Graph-level processing</h4>
<p>一般来说，我们从特征<span class="math inline">\(x_i \in \mathbb{R}^{N
\times D}\)</span>开始。 我们首先根据特征构建一个图：G = G(X)。</p>
<p><strong>图卷积层可以通过聚合来自其相邻节点的特征在节点之间交换信息</strong></p>
<p>具体来说，图卷积操作如下： <span class="math display">\[
\begin{aligned}
\mathcal{G}^{\prime} &amp;=F(\mathcal{G}, \mathcal{W}) \\
&amp;=\text { Update }\left(\text { Aggregate }\left(\mathcal{G}, W_{a g
g}\right), W_{\text {update }}\right)
\end{aligned}
\]</span> <strong>其中 Wagg 和 Wupdate
分别是聚合和更新操作的可学习权重</strong></p>
<p>更具体地说，<strong>聚合操作通过聚合相邻节点的特征来计算节点的表示，更新操作进一步合并聚合的特征</strong>：
<span class="math display">\[
\mathbf{x}_{i}^{\prime}=h\left(\mathbf{x}_{i}, g\left(\mathbf{x}_{i},
\mathcal{N}\left(\mathbf{x}_{i}\right), W_{a g g}\right), W_{\text
{update }}\right)
\]</span> 其中<span
class="math inline">\(\mathcal{N}\left(\mathbf{x}_{i}^{l}\right)\)</span>是
<span class="math inline">\(x_i^l\)</span>的邻居节点集。
在这里，我们采用<strong><em>max-relative graph convolution</em></strong>
[28] 的简单性和效率： <span class="math display">\[
\begin{aligned}
&amp;g(\cdot)=\mathbf{x}_{i}^{\prime \prime}=\left[\mathbf{x}_{i}, \max
\left(\left\{\mathbf{x}_{j}-\mathbf{x}_{i} \mid j \in
\mathcal{N}\left(\mathbf{x}_{i}\right)\right\}\right]\right. \\
&amp;h(\cdot)=\mathbf{x}_{i}^{\prime}=\mathbf{x}_{i}^{\prime \prime}
W_{\text {update }}
\end{aligned}
\]</span> 其中偏置项被省略。 上述图级处理可以表示为 <strong>X′ =
GraphConv(X)</strong></p>
<p>我们进一步介绍了图卷积的多头更新操作。</p>
<p>聚合后的特征 x′′ i 首先被分成 h 个 head，即
head1、head2、···、headh，然后分别用不同的权重更新这些 head。</p>
<p>所有的头都可以并行更新并连接为最终值： <span class="math display">\[
\mathbf{x}_{i}^{\prime}=\left[\text { head }^{1} W_{u p d a t e}^{1},
\text { head }{ }^{2} W_{u p d a t e}^{2}, \cdots, \text { head }{ }^{h}
W_{u p d a t e}^{h}\right]
\]</span>
<strong>多头更新操作允许模型在多个表示子空间中更新信息，这有利于特征的多样性。</strong></p>
<h4 id="vig-block.">3.1.3 ViG block.</h4>
<p>以前的 GCN 通常重复使用几个图卷积层来提取图数据的聚合特征。</p>
<p>深度 GCN [29, 38]
中的过度平滑现象会降低节点特征的独特性并导致视觉识别的性能下降，如图 3
所示，其中多样性被测量为 ‖X - 1 ̃ xT ‖ ̃ x = arg min ̃ x ‖X - 1 ̃ xT ‖
[7]。</p>
<p>为了缓解这个问题，<strong>我们在 ViG
块中引入了更多的特征转换和非线性激活。</strong></p>
<p><img src="fig3.png" /></p>
<p><strong>我们在图卷积之前和之后应用一个线性层来将节点特征投影到同一域中并增加特征多样性</strong></p>
<p><strong>在图卷积之后插入一个非线性激活函数以避免层崩溃</strong></p>
<p>我们将升级后的模块称为 Grapher 模块</p>
<p>在实践中，给定输入特征 <span class="math inline">\(x_i \in
\mathbb{R}^{N \times D}\)</span>，Grapher 模块可以表示为 <span
class="math display">\[
Y=\sigma\left(\operatorname{GraphConv}\left(X W_{i n}\right)\right) W_{o
u t}+X
\]</span> 其中<span class="math inline">\(Y \in \mathbb{R}^{N \times
D}\)</span>，Win 和 Wout 是全连接层的权重，σ 是激活函数，例如 ReLU 和
GeLU [18]，偏置项被省略。</p>
<p>为了进一步提高特征转换能力并缓解过度平滑现象，我们在每个节点上使用前馈网络（FFN）</p>
<p>FFN 模块是一个简单的多层感知器，具有两个全连接层： <span
class="math display">\[
Z=\sigma\left(Y W_{1}\right) W_{2}+Y
\]</span> 其中<span class="math inline">\(Z \in \mathbb{R}^{N \times
D}\)</span>，W1 和 W2 是全连接层的权重，偏置项被省略。</p>
<p><strong>FFN 的隐藏层维度通常大于 D</strong></p>
<p>在 Grapher 和 FFN
模块中，<strong>在每个全连接层或图卷积层之后都应用了批归一化</strong>，这在公式中省略了。</p>
<p>Grapher 模块和 FFN 模块的堆栈构成了 ViG
块，作为构建网络的基本构建单元。</p>
<p>基于图像的图形表示和提出的 ViG 块，我们可以为视觉任务构建 ViG
网络，如图 2 所示。</p>
<p>与普通 ResGCN [28] 相比，我们的 ViG 可以保持特征多样性（图 3）作为层
更深入地学习判别表示。</p>
<h3 id="network-architecture">3.2 Network Architecture</h3>
<p>在计算机视觉领域，常用的变压器通常具有各向同性架构（例如，ViT
[8]），而 CNN 更喜欢使用金字塔架构（即 ResNet [16]）。</p>
<p>为了与其他类型的神经网络进行广泛比较，我们为 ViG
构建了两种网络架构，即各向同性架构和金字塔架构。</p>
<h4 id="isotropic-architecture">3.2.1 Isotropic architecture</h4>
<p>各向同性架构意味着主体在整个网络中具有相同大小和形状的特征，例如 ViT
[8] 和 ResMLP [48]。</p>
<p>我们构建了三个版本的各向同性 ViG 架构，模型大小不同，即 ViG-Ti、S 和
B。</p>
<p>节点数设置为 N = 196。</p>
<p>为了逐渐扩大感受野，邻居节点数 K 从 9 个增加
随着层在这三个模型中的深入，线性增加到 18。</p>
<p>默认情况下，头数设置为 h = 4。 详细信息列于表 1。 <span
class="math display">\[
\begin{array}{l|c|c|c|c}
\hline \text { Model } &amp; \text { Depth } &amp; \text { Dimension } D
&amp; \text { Params (M) } &amp; \text { FLOPs (B) } \\
\hline \text { ViG-Ti } &amp; 12 &amp; 192 &amp; 7.1 &amp; 1.3 \\
\text { ViG-S } &amp; 16 &amp; 320 &amp; 22.7 &amp; 4.5 \\
\text { ViG-B } &amp; 16 &amp; 640 &amp; 86.8 &amp; 17.7 \\
\hline
\end{array}
\]</span></p>
<h4 id="pyramid-architecture.">3.2.2 Pyramid architecture.</h4>
<p>Pyramid
架构考虑了图像的多尺度特性，通过随着层的深入提取空间尺寸逐渐变小的特征，例如
ResNet [16] 和 PVT [54]。</p>
<p>经验证据表明，金字塔架构对于视觉任务是有效的 [54]。
因此，我们利用先进的设计并构建了四个版本的金字塔 ViG 模型。 详情如表 2
所示。</p>
<p><img src="table2.png" /></p>
<h4 id="positional-encoding">3.2.3 Positional encoding</h4>
<p>为了表示节点的位置信息，我们给每个节点特征添加一个位置编码向量：
<span class="math display">\[
x_i \leftarrow x_i + e_i
\]</span> 其中 ei ∈ RD。</p>
<p>等式中描述的绝对位置编码适用于各向同性和金字塔结构。</p>
<p>对于金字塔 ViG，我们按照 Swin Transformer [33]
等高级设计进一步包括相对位置编码。</p>
<p>对于节点 i 和 j，它们之间的相对位置距离为 <span
class="math inline">\(e_i^T
e_j\)</span>，将添加到构建图的特征距离中。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://www.larryai.com">扁同学不发言</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.larryai.com/2022/08/04/ViG/">http://www.larryai.com/2022/08/04/ViG/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.larryai.com" target="_blank">扁同学不发言的个人博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/cs-CV/">cs.CV</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/GNN/">GNN</a><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/">图像分类</a></div><div class="post_share"><div class="social-share" data-image="/2022/08/04/ViG/fig2.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/08/08/diffpool/"><img class="prev-cover" src="/2022/08/08/diffpool/fig1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hierarchical Graph Representation Learning with Differentiable Pooling</div></div></a></div><div class="next-post pull-right"><a href="/2022/08/01/ucart-ai/"><img class="next-cover" src="/2022/08/01/ucart-ai/fig1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Understanding and Creating Art with AI</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/05/04/GanGANv2/" title="GanGANv2"><img class="cover" src="/2022/05/04/GanGANv2/3.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">GanGANv2</div></div></a></div><div><a href="/2022/05/04/Image%20Style%20Transfer/" title="Image Style Transfer"><img class="cover" src="/2022/05/04/Image%20Style%20Transfer/fig1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">Image Style Transfer</div></div></a></div><div><a href="/2022/05/04/MASA-SR/" title="MASA-SR"><img class="cover" src="https://pic1.zhimg.com/v2-3486f59df8faa40673ddcbe4f5212844_1440w.jpg?source=172ae18b" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">MASA-SR</div></div></a></div><div><a href="/2022/05/04/MGUIT/" title="MGUIT"><img class="cover" src="/2022/05/04/MGUIT/1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">MGUIT</div></div></a></div><div><a href="/2022/05/04/PLST-SR/" title="Perceptual Losses for Real-Time Style Transfer and Super-Resolution"><img class="cover" src="https://pic4.zhimg.com/v2-8e9936fdcfd4e8371720b9834f8f97d7_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-04</div><div class="title">Perceptual Losses for Real-Time Style Transfer and Super-Resolution</div></div></a></div><div><a href="/2022/07/19/OmniArt1/" title="OmniArt: Multi-task Deep Learning for Artistic Data Analysis"><img class="cover" src="/2022/07/19/OmniArt1/1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-19</div><div class="title">OmniArt: Multi-task Deep Learning for Artistic Data Analysis</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/%E6%96%B0%E4%B8%80.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">扁同学不发言</div><div class="author-info__description">AIArt@HDU</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Larry-zx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Larry-zx" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://www.zhihu.com/people/larry-19-22-31" target="_blank" title="Zhihu"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="https://mobile.twitter.com/Larry37722397" target="_blank" title="Twitter"><i class="fa-brands fa-twitter"></i></a><a class="social-icon" href="https://www.youtube.com/channel/UCzDXYobI-mUP5WgvA37er6A" target="_blank" title="Youtube"><i class="fa-brands fa-youtube"></i></a><a class="social-icon" href="https://www.kaggle.com/larryzxai" target="_blank" title="Kaggle"><i class="fa-brands fa-kaggle"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Hi , welcome to my blog 🤔</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-text">1.Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#related-work"><span class="toc-text">2.Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cnn-transformer-and-mlp-for-vision"><span class="toc-text">2.1 CNN, Transformer and MLP
for Vision</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#graph-neural-network"><span class="toc-text">2.2 Graph Neural Network</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#approach"><span class="toc-text">3.Approach</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#vig-block"><span class="toc-text">3.1 ViG Block</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#graph-structure-of-image"><span class="toc-text">3.1.1 Graph Structure of Image</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#graph-level-processing"><span class="toc-text">3.1.2 Graph-level processing</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#vig-block."><span class="toc-text">3.1.3 ViG block.</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#network-architecture"><span class="toc-text">3.2 Network Architecture</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#isotropic-architecture"><span class="toc-text">3.2.1 Isotropic architecture</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pyramid-architecture."><span class="toc-text">3.2.2 Pyramid architecture.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#positional-encoding"><span class="toc-text">3.2.3 Positional encoding</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/08/08/diffpool/" title="Hierarchical Graph Representation Learning with Differentiable Pooling"><img src="/2022/08/08/diffpool/fig1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hierarchical Graph Representation Learning with Differentiable Pooling"/></a><div class="content"><a class="title" href="/2022/08/08/diffpool/" title="Hierarchical Graph Representation Learning with Differentiable Pooling">Hierarchical Graph Representation Learning with Differentiable Pooling</a><time datetime="2022-08-08T13:55:19.000Z" title="发表于 2022-08-08 21:55:19">2022-08-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/04/ViG/" title="Vision GNN-An Image is Worth Graph of Nodes"><img src="/2022/08/04/ViG/fig2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Vision GNN-An Image is Worth Graph of Nodes"/></a><div class="content"><a class="title" href="/2022/08/04/ViG/" title="Vision GNN-An Image is Worth Graph of Nodes">Vision GNN-An Image is Worth Graph of Nodes</a><time datetime="2022-08-04T11:33:23.000Z" title="发表于 2022-08-04 19:33:23">2022-08-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/01/ucart-ai/" title="Understanding and Creating Art with AI"><img src="/2022/08/01/ucart-ai/fig1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Understanding and Creating Art with AI"/></a><div class="content"><a class="title" href="/2022/08/01/ucart-ai/" title="Understanding and Creating Art with AI">Understanding and Creating Art with AI</a><time datetime="2022-08-01T07:37:14.000Z" title="发表于 2022-08-01 15:37:14">2022-08-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/19/OmniArt1/" title="OmniArt: Multi-task Deep Learning for Artistic Data Analysis"><img src="/2022/07/19/OmniArt1/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OmniArt: Multi-task Deep Learning for Artistic Data Analysis"/></a><div class="content"><a class="title" href="/2022/07/19/OmniArt1/" title="OmniArt: Multi-task Deep Learning for Artistic Data Analysis">OmniArt: Multi-task Deep Learning for Artistic Data Analysis</a><time datetime="2022-07-19T13:52:50.000Z" title="发表于 2022-07-19 21:52:50">2022-07-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/16/SEAN/" title="SEAN:Image Synthesis With Semantic Region-Adaptive Normalization"><img src="/2022/05/16/SEAN/fig4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SEAN:Image Synthesis With Semantic Region-Adaptive Normalization"/></a><div class="content"><a class="title" href="/2022/05/16/SEAN/" title="SEAN:Image Synthesis With Semantic Region-Adaptive Normalization">SEAN:Image Synthesis With Semantic Region-Adaptive Normalization</a><time datetime="2022-05-16T09:53:19.000Z" title="发表于 2022-05-16 17:53:19">2022-05-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By 扁同学不发言</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="#">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'H2XPsPqmRrVmO7wLvvlhsgyi-gzGzoHsz',
      appKey: 'qUDSqSmyX1JHlTwo3fQLXiSU',
      avatar: 'monsterid',
      serverURLs: 'https://h2xpspqm.lc-cn-n1-shared.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script>((window.gitter = {}).chat = {}).options = {
  disableDefaultChat: true,
};
document.addEventListener('gitter-sidecar-ready', (e) => {
  const GitterChat = e.detail.Chat
  let chat

  function initGitter () {
    chat = new GitterChat({
      room: 'babylearnDL/community',
      activationElement: '#chat_btn'
    });
  }

  initGitter()

  if (false) {
    document.addEventListener('pjax:complete', () => {
      chat.destroy()
      initGitter()
    })
  }

})</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async="async" defer="defer"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>