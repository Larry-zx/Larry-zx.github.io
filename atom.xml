<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>扁同学不发言的个人博客</title>
  
  
  <link href="http://www.larryai.com/atom.xml" rel="self"/>
  
  <link href="http://www.larryai.com/"/>
  <updated>2022-08-02T08:41:16.788Z</updated>
  <id>http://www.larryai.com/</id>
  
  <author>
    <name>扁同学不发言</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://www.larryai.com/2022/08/01/ucart-ai/"/>
    <id>http://www.larryai.com/2022/08/01/ucart-ai/</id>
    <published>2022-08-01T07:37:14.000Z</published>
    <updated>2022-08-02T08:41:16.788Z</updated>
    
    <content type="html"><![CDATA[<h1id="understanding-and-creating-art-with-ai-review-and-outlook">Understandingand Creating Art with AI: Review and Outlook</h1><h2 id="abstract">ABSTRACT</h2><p>与人工智能（AI）相关的技术对视觉艺术研究和创作实践的变化产生了强烈的影响。</p><p>越来越多的研究计划和创意应用出现在 AI与艺术的交叉领域，促使我们审视和讨论 AI技术在艺术背景下的创意和探索潜力。</p><p>本文对<strong>人工智能</strong>和<strong>艺术</strong>的两个方面进行了综合回顾：</p><ul><li>1）人工智能用于艺术分析，并用于数字化艺术品收藏</li><li>2）人工智能用于创意目的和产生新颖的艺术品</li></ul><p>在与人工智能相关的艺术理解研究的背景下，我们对艺术品数据集和最近的作品进行了全面的概述，这些作品解决了各种任务，如<strong>分类、对象检测、相似性检索、多模态表示、计算美学</strong>等。</p><p>人工智能在艺术创作中的作用，我们解决了人工智能艺术的各种实践和理论方面，并整合了详细处理这些主题的相关作品。</p><p>最后，我们对人工智能技术的未来发展和对我们对艺术的理解和创作的潜在影响提供了一个简明的展望</p><h2 id="introduction">1.Introduction</h2><p>机器学习的最新进展导致人们对人工智能 (AI) 研究的兴趣加速。</p><p>这促进了对人工智能在各个领域的可能应用的探索，并引发了针对<strong>缺乏可解释性</strong>、<strong>机器智能的局限性</strong>、<strong>潜在风险和社会挑战的批判性</strong>讨论。</p><p>在探索“人与人工智能”关系的设定中，也许<strong>最令人难以捉摸的兴趣领域是对艺术的创造和理解</strong>。</p><p>在人工智能和艺术的交汇处出现了许多有趣的举措，但是对艺术的理解和欣赏仍然被认为是人类独有的能力。</p><p>植根于艺术的存在和意义确实与人与人之间的互动密不可分的想法，本文背后的动机是探索将人工智能引入循环如何不仅可以促进数字艺术和艺术史领域的进步，但也激发了我们对艺术未来的看法。</p><p>与“人工智能与艺术”相关的各种活动和研究举措，一般可以分为两类：</p><ul><li><p>人工智能用于<strong>分析</strong>现有艺术的过程</p></li><li><p>AI 用于<strong>创作</strong>新艺术的过程。</p></li></ul><p>本文讨论了这两个类别的相关方面和贡献，特别关注<strong>人工智能与视觉艺术的关系</strong>。</p><p>近年来，艺术家、技术人员和研究人员对探索人工智能技术的创造潜力的兴趣激增。</p><p>随着生成对抗网络 (GAN)的出现，人工智能在视觉艺术创作过程中的使用显着加快。</p><p>越来越多的艺术家使用人工智能技术，以及画廊和拍卖行对人工智能艺术的兴趣日益浓厚，促进了对这一新运动的各种实践和理论方面的讨论。</p><p>另一方面，数字化艺术收藏的在线可用性不断增加，为使用人工智能技术分析艺术史提供了新的机会。</p><p>特别是，卷积神经网络 (CNN)的使用实现了对大量艺术品图像数据进行分类、分类和可视化的高级自动化。</p><p>除了构建高效的检索平台、智能推荐系统和探索数字化艺术收藏的先进工具外，人工智能技术还可以通过分析特定艺术品或艺术作品之间关系的新方法来支持艺术史领域的新知识生产。</p><p>越来越多的艺术作品、研究和应用出现在人工智能和艺术的交叉领域，促使我们需要在我们对艺术的历史、当代和未来理解的背景下讨论人工智能技术的创造和探索潜力。</p><h2 id="understanding-art-with-ai-ai理解艺术">2.Understanding Art withAI (AI理解艺术)</h2><h3 id="艺术收藏品作为数据源">2.1 艺术收藏品作为数据源</h3><p>过去几十年发生的大规模数字化努力导致在线可用艺术收藏品的大量增加。</p><p>这些艺术收藏品使我们能够轻松探索和欣赏位于世界各地各种博物馆或艺术画廊的艺术品。</p><p>除了使我们能够直观地检查各种艺术品外，大量数字化艺术图像的可用性引发了新的跨学科研究视角。</p><p>物理绘画及其数字化对应物以不同的材料模式存在，但它们编码和传达相同的复杂信息结构。</p><p>正如画布和颜料的属性通常包括艺术史学家可能非常感兴趣的背景信息一样，数字化艺术品的数字表示也包括其潜力尚未充分开发的信息。</p><p>数字化项目的主要目标通常是建立数字存储库，以便更轻松地访问和探索馆藏。</p><p>尽管这通常被认为是许多数字化项目的最终目标，但重要的是要强调，这些馆藏的存在只是应用先进计算方法和开辟新研究视角的开始和必要前提。</p><blockquote><p>图 1 说明了使用计算方法从数字化到定量分析、知识发现和可视化的过程。从该过程的最后阶段获得的研究结果通常用于通过添加先进的内容探索方式来增强存储库和在线馆藏的功能。</p></blockquote><p><img src="fig1.png" /></p><p>在数字化艺术分析的背景下，计算方法通常用于采用远视或近距离阅读方法。</p><p>细读意味着关注一件特定作品或艺术作品的特定方面，通常解决诸如<strong>视觉风格测量</strong>和<strong>计算艺术家身份验证</strong>等问题</p><p>大多数专门针对这些主题的研究都依赖于所分析艺术品的高质量数字复制品的可用性，并且主要关注笔触和纹理属性。</p><p>远程查看通常涉及通过专注于特定特征或相似关系并产生相应的统计可视化来分析大型集合。</p><p>最近与艺术计算分析有关的大多数研究都在利用包含各种质量图像的大型数字化收藏品的可用性，因此采用了远距离观察方法。</p><p>在过去的几年里，越来越多的研究合作涉及计算机视觉和深度学习方法在数字艺术史领域的应用。</p><p>最常见的任务包括<strong>自动分类、对象检测、基于内容和多模态检索、不同特征和概念的定量分析、计算美学</strong>等问题。</p><p><strong>大规模和注释良好的数据集</strong>的可用性是为各种任务采用深度学习模型的必要要求。</p><p>近年来，许多博物馆和画廊都发布了其藏品的数字在线版本。</p><p>由于很难列出所有现有的在线艺术收藏品，因此本文仅关注过去几年最常用于计算机视觉和深度学习研究的那些收藏品和数据集。</p><p>表2列出了最知名的主要西方艺术收藏品，这些收藏品经常被用作创建不同任务特定数据集的来源。</p><p>此外，它还包括专门为特定研究任务开发的知名和新颖的数据集。</p><p><img src="table1.png" /></p><p>表 2 中的数据集与它们设计或最常用的任务相关联。</p><p>大多数在线艺术收藏都包含与整个图像相关的一般注释，并且通常用于分类或检索任务。</p><p>这些注释大多由艺术专家提供，包含有关<strong>艺术家、风格、流派、技术、时期</strong>等的信息。</p><p>一些特定的任务，如<strong>对象检测</strong>，需要<strong>对特定图像区域进行更详细的注释</strong>。</p><p>最近出现了几个与<strong>文本描述相关的图像数据集</strong>，以执行不同的<strong>多模式任务</strong>。</p><p>用于<strong>情感分析和审美质量评估</strong>的数据集通常包含通过特定调查或众包平台从多个注释者那里收集的注释。</p><h3 id="艺术品的自动分类">2.2 艺术品的自动分类</h3><p>在过去十年中，基于艺术家、风格或流派等类别的艺术品自动分类一直是计算艺术分析的核心挑战之一。</p><p>大多数早期研究通过提取各种手工制作的图像特征并使用这些特征的不同机器学习算法来解决自动艺术家、风格和流派分类的问题。</p><p>在实现更好的分类精度方面，卷积神经网络 (CNN)的采用取得了重大进展。</p><p>一开始，CNNs首先被用作特征提取器。</p><p>卡拉耶夫等人是第一个利用在 ImageNet上训练的 CNN的层激活，一个大型手工标记的对象数据集，作为艺术风格分类的特征。</p><p>在他们的工作中，他们表明，从针对完全不同的任务（自然图像数据集上的对象识别）训练的网络中提取的特征在风格分类任务上优于所有其他低级图像特征。</p><p>艺术家 、风格和流派分类确认了基于 CNN的特征的主导地位，特别是与其他手工制作的特征相结合。</p><p>除了使用预训练的 CNN 作为特征提取器之外，Girshick等人表明<strong>可以通过在新目标数据集上微调预训练网络来进一步提高各种视觉识别任务的性能</strong>。</p><p>CNN特征提取和微调都代表了迁移学习的形式，其中模型在一项任务上学到的知识正在被用于新任务。</p><blockquote><p>迁移学习方法，特别是微调，已被证明可以为不同的艺术数据集和各种分类任务提供最先进的结果</p></blockquote><p>为了更好地理解预训练模型的可迁移性，Cetic 等人探讨了在使用相同的 CNN架构时，不<strong>同的微调策略和特定领域的模型初始化如何影响各种艺术分类任务和数据集的分类性能</strong>。</p><p>萨巴泰利等人分析不同 CNN 架构的可迁移性和微调影响并得出结论，与Gothier等人类似还进行了迁移学习分析，当应用于艺术领域的不同任务和数据集时，在艺术数据集上微调的模型优于ImageNet预训练模型中介绍了与艺术品分类相关的当前工作的全面概述，以及基于图像元素对艺术品进行分类的方法。</p><h3 id="对象检测和相似度检索">2.3 对象检测和相似度检索</h3><p>除了分类之外，深度神经网络的使用在探索艺术品内容和自动识别绘画中的物体、面孔或其他特定图案方面显示出可喜的成果。</p><p>作为该领域的开创性工作之一，Crowley 等人表明，使用来自自然图像的 CNN特征训练的对象分类器可以非常成功地检索包含这些对象的绘画。</p><p>后来的研究不仅解决了检索描绘特定对象的绘画的问题，而且还确定了对象在图像中的位置，以及检测内容以发现集合中同时出现的模式。</p><p>获得特别关注的内容的一个方面是对人脸的描绘。</p><p>在绘画中的人物和人脸检测主题以及基于性别和其他特征的检测到的人脸的分析和分类，已经做了一些有趣的工作。</p><p>除了人脸，我们还努力识别艺术品中其他与内容相关的元素，例如检测绘画中人物的姿势,识别特定人物或检测绘画中描绘的材料</p><p>在艺术图像中采用计算方法进行自动内容和风格识别的主要实际目标之一是构建智能检索系统，该系统可以帮助以有效的方式组织和分析大量艺术品收藏。</p><p>许多现有的检索系统依赖于基于其相应的元数据和文本描述来检索图像。然而，使用卷积神经网络，在通过基于图像的查询获得相关结果方面取得了重大进展。</p><p><strong>“视觉相似性”</strong>的概念通常被认为是各种检索系统中的关键因素。</p><p>然而，在艺术的语境中，“相似性”是一个复杂的术语，可以包括内容匹配的不同方面（相同对象的描述或相似的图像表示）或与风格更相关的对应关系，如笔触、颜色、构图、等。 CNN 的应用在检索绘画收藏中的视觉链接图像方面显示出有希望的结果。</p><p>为了解决艺术中相似性的复杂性，Mao 等人提出了 DeepArt检索系统，该系统对可以同时捕获内容和样式特征的联合表示进行编码</p><h3 id="多模式任务">2.4 多模式任务</h3><h3 id="艺术史中的知识发现">2.5 艺术史中的知识发现</h3><h3 id="美学与知觉">2.6 美学与知觉</h3><h2 id="creating-ai-artai生成艺术作品">Creating AIArt（AI生成艺术作品）</h2><h3 id="technological-milestones">3.1 Technological Milestones</h3><p><img src="fig2.png" /></p><h3 id="the-contemporary-ai-art-scene">3.2 The Contemporary AI ArtScene</h3><h3 id="novelty-of-ai-art">3.3 Novelty of AI Art</h3><h3 id="machine-autonomy-and-the-role-of-the-artist">3.4 MachineAutonomy and the Role of the Artist</h3><h3 id="authorship-copyright-and-ethical-issues">3.5 Authorship,Copyright and Ethical Issues</h3><h3 id="perception-of-ai-art">3.6 Perception of AI Art</h3><h2 id="conclusion-and-future-outlook">Conclusion and FutureOutlook</h2><p>目前的趋势表明，人工智能技术将在艺术的分析和生产中变得更加重要。</p><p>在过去的几年里，许多大学已经建立了数字人文 (DH)硕士和博士课程，以教育新一代研究人员熟悉定量和基于人工智能的方法及其在人文数据中的应用。</p><p>我们可以预期，这将加强人文学科从传统研究实践向数字研究实践的方法论转变，并导致越来越多的创新研究项目应用大规模定量方法来研究与艺术相关的历史问题。</p><p><strong>从计算机视觉的角度来看，为了协助研究人员从事文化数字档案工作，仍有许多实际挑战需要解决。</strong></p><blockquote><p>特别是与注释标准、高级对象检测和检索、交叉描述、图像分类、多模态对齐和图像理解相关的问题。</p></blockquote><p>以前，深度神经网络模型的使用取决于大规模数据集的可用性。</p><p>通过利用迁移学习和标签稀缺技术（例如少镜头学习）的概念，深度神经网络模型可以应用于较小的数据集，并用于不同的细粒度任务和各种图像集合。</p><p>未来许多特定领域的数字艺术史项目可能会利用这些方法。</p><p>除了采用深度学习模型来加强艺术史研究实践之外，值得注意的是，艺术领域的任务和数据源在开发新的计算机视觉和深度学习技术方面具有的潜力。</p><p>数字化艺术收藏是图像的数据源，通常包括与其形成的历史和技术方面相关的丰富背景信息，但也代表了融合了内容和风格的交织概念的感性视觉信息的来源。</p><p>因为它们包含不同的信息层，艺术收藏品代表了一个有用的数据源，用于解决计算图像理解的各种复杂任务。</p><p><strong>在艺术创作和生产的背景下，人工智能技术开始发挥越来越重要的作用。</strong></p><p>不仅在数字化和人工智能产生的艺术方面，而且在传统艺术的策展、展览和销售的各个方面也是如此。</p><p>考虑到由于当前的全球大流行，注意力迅速转移到在线平台和数字展厅，目前的情况导致人们对加密艺术和区块链技术的兴趣已经上升，这些技术有可能对艺术市场产生重大影响和转变。</p><p>关于使用 AI 技术创作艺术，在过去几年中，基于 GAN 的方法在 AI艺术领域占据主导地位。</p><p>最近，多模态生成模型的发展取得了重大突破，例如可以从文本生成图像的模型。</p><p>这个方向的技术进步可能会对艺术的生产和创作产生重大影响。</p><p>可以将来自不同模态的数据转换为联合语义空间的模型代表了一种有趣的艺术探索工具，因为多模态的概念是许多艺术形式不可或缺的一部分，并且在创作过程中一直发挥着重要作用。</p><p>此外，很明显，在艺术创作中越来越多地使用人工智能技术将对与作者身份相关的问题以及我们人类对艺术的感知产生重大影响。</p><p>随着人工智能模型的发展，可以生成非常令人信服地模仿人类文本、视觉或音乐创作的内容，我们对艺术的许多传统以及当代、理论和实践理解可能会受到挑战。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1
id=&quot;understanding-and-creating-art-with-ai-review-and-outlook&quot;&gt;Understanding
and Creating Art with AI: Review and Outlook&lt;/h1&gt;
&lt;h2 id=&quot;a</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="AiArt" scheme="http://www.larryai.com/tags/AiArt/"/>
    
  </entry>
  
  <entry>
    <title>OmniArt: Multi-task Deep Learning for Artistic Data Analysis</title>
    <link href="http://www.larryai.com/2022/07/19/OmniArt1/"/>
    <id>http://www.larryai.com/2022/07/19/OmniArt1/</id>
    <published>2022-07-19T13:52:50.000Z</published>
    <updated>2022-07-19T13:55:40.048Z</updated>
    
    <content type="html"><![CDATA[<h1id="omniart-multi-task-deep-learning-for-artistic-data-analysis">OmniArt:Multi-task Deep Learning for Artistic Data Analysis</h1><h2 id="abstract">ABSTRACT</h2><p>大量的艺术数据分散在网上，来自博物馆和艺术应用程序</p><p>收集、处理和研究所有相关属性是一个昂贵的过程</p><p>为了加快和提高艺术领域分类分析的质量，在本文中，我们提出了一种有效且准确的多任务学习方法，该方法具有应用于艺术领域的共享表示。</p><p>我们继续展示我们方法的<strong>不同多任务</strong>配置如何在艺术数据上表现，并<strong>优于手工特征方法以及卷积神经网络</strong>。</p><p>除了方法和分析之外，我们还对包含近 50万个样本和结构化元数据的新聚合数据集提出了挑战，以鼓励进一步的研究和社会参与。</p><h2 id="introduction">1 INTRODUCTION</h2><p>诸如 <em>WikiArt 1、Europeana 2、ArtUk 3、WGA 4 和 Google Art Project5</em>等<strong>艺术应用程序</strong>将各种艺术收藏品与基本元数据聚合在一起，并通过网络将其公开。</p><p>另一方面，<strong>博物馆</strong>基于以博物馆为中心的观点，公开了大部分元数据和结构。</p><p>通常，这些集合包含比在线艺术应用程序中发现的更丰富、专业设计的元数据。</p><p>以博物馆为中心的数据将准确的元数据与收藏品的高质量照片复制相结合，是分析的理想选择，因为它们允许从多个角度进行更深入的艺术探索。</p><p>在此类以博物馆为中心的藏品中，可用信息与注释中包含的数据之间存在差距。</p><p>通常，可用于特定艺术作品的语义元数据在不同的用例场景中以不同的方式传递。</p><p><strong>这给这些集合的搜索和索引带来了问题</strong>。</p><p>施莱伯等人，在<strong>以标准化方式将元数据归因于艺术品</strong>方面，迈出了重要的一步。</p><p>他们从各种收藏中收集了超过 200,000个艺术样本，并在这些样本之上创建了一个用于<strong>描述艺术作品的词汇</strong>。</p><p>使用这个词汇表，<strong>他们将具有 RDF关系的现有元数据映射到链接开放数据云中的其他实体</strong>。</p><p>这样做有效地提供了标准化的注释，并极大地扩展了语义上下文可用的元数据</p><figure><img src="OmniArt1/1.png" alt="1" /><figcaption aria-hidden="true">1</figcaption></figure><p>然而，即使没有关联数据的扩展，文化遗产通常也是一个知识丰富的领域。</p><p>例如，在艺术绘画中，大多数艺术品都有着名的<strong>艺术家、风格、创作年份、材料、地理来源</strong>，甚至关于其内容的非常详细的文字描述。</p><p>通过材料科学的特定方法，<strong>可以将颜色的化学成分与绘画中的画布线图案一起提取</strong>。</p><p>这些数据集的信息在更精细的范围内可用。</p><p>使用高分辨率摄影和 X 射线，我们能够看到虚幻的细节并产生比以往更多的洞察力。</p><p><strong>每个提到的信息块都对科学家提出了不同的挑战</strong>。</p><p>随着这种以博物馆为中心、内容丰富的数据的数量不断增长，对探索和分析艺术收藏品的有效工具的需求变得越来越迫切。</p><p>对于这项工作，我们专注于该数据池的一个子域，即<strong>艺术品的原始照片复制品与博物馆提供的文本元数据相结合</strong>。</p><p>我们在元数据中的重点领域包含我们假设在语义上相关的属性。</p><p><strong>具有多种类型的属性，为每种类型创建了单独的任务的可能性，从而使这项研究具有多任务性质。</strong></p><p>处理多个任务最省时的方法是同时进行，这就是为什么在论文中我们提出了一种多任务深度学习方法</p><p>在图 1 中描绘的任务之间具有<strong>共享数据表示</strong>。</p><p><strong>创建共享表示允许我们利用不同任务之间的语义纠缠</strong>。</p><p>考虑到在缩小上述信息鸿沟方面鼓励科学进步，我们对论文中解决的任务提出了挑战。</p><p><strong>挑战一再被证明是激励社区为某项事业做出贡献的良好催化剂</strong></p><p>自 2009年以来，多媒体大挑战就是多媒体挑战成功的一个光辉例子，它一直将商业工业需求引起科学研究人员的注意。</p><p>在计算机视觉领域，ImageNet 大规模视觉识别竞赛 (ILSVRC) 让位于一些最大的突破。</p><p>Mensink 等人于 2014年推出了一项这样的艺术挑战，即结合丰富的艺术数据信息，同时提供以博物馆为中心的视角，作为国立博物馆挑战。</p><p>国立博物馆挑战赛由四个独立的任务组成</p><blockquote><p>即：<strong>艺术家</strong>归属、预测<strong>艺术类型</strong>、预测使用的<strong>材料</strong>和预测收藏中特定艺术品的<strong>创作年份</strong>。</p></blockquote><p>2014 年，该数据集包含近 120,000条国家博物馆在线收藏的艺术品的各种摄影复制品条目。</p><p>挑战中的单个艺术品由许多属性描述，例如艺术家、创作时期、使用的材料、艺术品类型等。</p><p>该数据集中的艺术作品可以追溯到远古时代到 19 世纪后期，并归属于 6000多名艺术家。</p><p>尽管艺术数据提供了多种分析方法，但<strong>大多数当前的艺术数据分析方法分别解决了每项任务</strong>。</p><p>在<strong>单个端到端系统中解决这个多任务问题会更有效</strong>，因为这样可以显着减少多个模型所需的训练时间。</p><p>在某些情况下，如果每<strong>个任务中的类别之间存在相关性，多任务学习环境甚至可以提高分类性能</strong></p><p>Kokkinos等人所做的工作成功地展示了适用于一次解决多个任务的深度模型的好处。</p><p><strong>他们的架构试图通过模型一次传播输入数据来执行多项计算机视觉任务</strong>，这在一定程度上启发了我们的工作。</p><p>使用我们提出的方法，称为 OmniArt，我们报告了 2014年国立博物馆挑战赛的最先进结果，并提出了一个新的挑战，扩展了一个更好的结构化数据集。</p><p>接受后，我们将通过数据集、训练好的模型和评估引擎公开挑战，以刺激进一步的发展。</p><p>在这项工作中，我们详细阐述了以下贡献：</p><ul><li>我们提出了<strong>一种高效且准确的多任务端到端方法</strong>，用于学习关于所有任务的输入数据的共享表示</li><li>我们提供了一个以博物馆为中心的数据集，其中包含超过 430,000个样本和更新的元数据，名为 TheOmniArt挑战刺激参与，鼓励新的研究和最大化社会影响。</li><li>我们报告了 2014 年国立博物馆挑战赛和 OmniArt挑战赛的最新结果，训练时间显着缩短</li></ul><p>本文的其余部分结构如下：</p><ul><li>第 2 部分包含从多任务学习角度和一般艺术数据分析的相关工作。</li><li>第 3 节介绍了所提出的方法及其背后的逻辑。</li><li>第 4 节是关于实验设置、用于训练和测试的数据集以及实验结果。</li><li>在最后一节中，我们给出了结论性意见以及我们进行的分析的定性发现。</li></ul><h2 id="related-work">2 RELATED WORK</h2><p>该领域的相关工作可以分为<strong>艺术数据分析</strong>和<strong>多任务学习</strong>两个部分。</p><h3 id="艺术数据分析">2.1 艺术数据分析</h3><p>早在 1979 年，J. Rush 就得出结论</p><blockquote><p>对特定艺术家的个别艺术实例的体验 可以导致 识别同一艺术家以前从未见过的作品 的能力。</p></blockquote><p>虽然来自艺术家的样本的纯视觉体验有效地教会了受试者识别这些从未见过的艺术品</p><p>但当其他上下文信息与原始图像结合呈现时，性能得到了显着提升。</p><p>通过添加上下文，消除了可能的混淆来源并提高了识别性能。</p><p>琼森等人使用 Gabor、Complex 和 D4 小波结合支持向量机 (SVM)和阈值对梵高作品中的笔触进行了详细分析。</p><p>这种分析是在非常小的范围内完成的，只有 101张图像，输入是全分辨率复制品。</p><p>他们得出结论，<strong>笔触分析有助于艺术家归因</strong>，但它也取决于许多外部因素，如画布退化和颜料损失。</p><p>对于大规模的准确分析，艺术品需要按比例缩小的表示形式，并且信息损失最小。</p><p>我们建议大规模进行此类分类。</p><p>作为较大的艺术数据集之一，Rijks'14 数据集由 Mensink 等人引入，2014年参加国立博物馆挑战赛。</p><p>此时，数据集的基线分数是在Fisher向量中表示的对手和强度SIFT特征的帮助下计算的。</p><p>对于分类，他们使用了 liblinear SVM 库 。</p><p>在同一数据集上，Van Noord 等使用他们自己的子集和名为 PigeoNET的卷积神经网络进行艺术家归属。</p><p>他们的实现具有五个卷积层和三个堆叠的全连接层，例如 Alexnet。</p><p>具有艺术家属性的表演报告在具有三个变化来源的子集上：1)异质性与同质性，2) 集合中的艺术家数量和 3) 每个艺术家的艺术品数量。</p><p>从这项研究得出的结论表明</p><blockquote><p><strong>模型的性能与每类的样本数量成正比——每类更多的样本等于更好的归因能力。</strong></p></blockquote><p>此外，当模型在单一类型的艺术品（例如仅印刷品）上进行训练时，性能会提高，因为模型不必处理来自同一艺术家的艺术品之间的巨大差异</p><p>虽然，类似的艺术品类型提高学习更好特征的能力，有时会由于样本相似性而使分类混乱。</p><p>范诺德等人对艺术家属性进行了广泛的分析，但没有使用我们利用并证明对确定艺术品属性有益的其他元数据（时期、材料、类型……）</p><p>另一个大量的艺术数据是 WikiArt 数据集。</p><p>多种艺术数据分析方法已在 WikiArt上进行了测试，因为它具有艺术家、时期和艺术类型的质量注释。</p><p>但是，由于缺少有关艺术品的材料信息，我们在 OmniArt 挑战中仅包含WikiArt 数据的子集中用于人物检测的毕加索数据集包含 218幅毕加索画作，其中大部分已经作为新数据集当前版本的子集包含在内。</p><p>谈到艺术，艺术家和时期等有形信息只是拼图的一部分。</p><p>风格在识别艺术品的起源方面也起着重要作用。</p><p>2016 年，Gatys 等人出了一种使用能量最小化观点的风格转移方法。</p><p>他们使用预训练的卷积神经网络作为样式原始图像和样式应转移到的图像的特征提取器。</p><p>捕获这些细节并以有意义的方式传输它表明可以使用卷积神经网络从艺术数据中提取质量信息中介绍了另一种最近的艺术数据生成方法，其中朱等人无需使用生成对抗训练配对即可有效地转移图像的风格、增强和变形。</p><h3 id="多任务学习">2.2 多任务学习</h3><p>多任务学习是归纳迁移的一种范式，其目标是通过利用相关任务中训练数据的特定领域信息来提高泛化性能。</p><p>随着数据集变得越来越大，最大限度地利用数据的每次传递的想法变得相当有吸引力，并且一次分析数据的多个方面的方法变得越来越流行。</p><p>鉴于多任务学习的优点，本文从分类设置中的多任务角度解决了艺术数据分析。</p><p>Kokkinos引入了一种卷积神经网络架构，该架构联合处理不同级别的视觉特征，称为UberNet。</p><p>在他的工作中，他在通过模型的图像的单次前向传递中生成对象边界、显着性图、语义分割、表面法线和检测。</p><p>Ubernet是我们工作背后动机的一部分，因为它使用类似的端到端范例来解决多任务问题。</p><p>虽然它在任务之间使用了明确的分离，但 Ubernet不允许在任务之间共享重要的信息，除了影响特定输出下所有层的联合损失。</p><p>然而，在<strong>不同的任务表示之间共享信息被证明有利于模型在训练中</strong>，如Misra 等人得出结论。</p><p>他们解决的一个拼接层提供了一个共享的单元结构，它将来自多个网络的激活组合成一个端到端的可训练模型。</p><p>在自然语言处理中，深度学习的多任务方法也被证明是有益的。</p><p>刘等人使用多个共享层对文本进行多域分类申述。</p><p>跨越不同领域，多任务学习可以通过显式或隐式信息共享来完成</p><p>最近的研究表明</p><blockquote><p>任务之间的信息共享对于动作检测、零镜头动作识别、人体姿态估计和用于面部表情改进的自适应视觉反馈生成是有益的。</p></blockquote><p>当前的方法<strong>使用不同的层深度来处理具有不同复杂性的任务或在其模型中使用多个输入</strong></p><p>因此不同的任务具有适合在最终块中训练分类器/回归器的特征。</p><p>在我们的方法中，我们对每个任务使用相同的功能，并<strong>根据任务的性质应用任务特定的缩放和权重</strong>。</p><p>我们方法的另一个好处是，<strong>即使不同任务的目标之间存在轻微的相关性，它也可以提高整体模型的性能</strong>。</p><p>在我们的方法中，我们<strong>旨在学习任务之间的语义联系，并利用这种洞察力以高效和准确的方式同时预测艺术品的多个属性。</strong></p><h2 id="method">3 METHOD</h2><blockquote><p>为该数据集中的每个任务训练单独的模型是一个计算效率低且耗时的过程。</p></blockquote><p>与多任务数据集的情况一样，在<strong>前向传递</strong>中通过模型传播的图像对于每个任务都是相同的。</p><p>由于标签空间、维度和损失类型的不同，只能在最终分类/回归块的<strong>反向传播中观察到差异</strong>。</p><p>此外，这些类型的任务通常在不同的标签类型之间存在相关性，从而影响某个预测的结果。</p><p>这意味着具有<strong>已知创作时期和艺术品类型的特定艺术品显着缩小了艺术家归属任务的可能艺术家列表</strong></p><p>这个例子的数学解释在等式 1 中以简单的条件概率显示 <spanclass="math display">\[P\left(T_{1} \mid T_{2}, T_{3}\right)=\frac{P\left(T_{1} \cap T_{2} \midT_{3}\right)}{P\left(T_{2} \mid T_{3}\right)}\]</span></p><ul><li><p>其中 T1 代表属于特定艺术家的艺术品</p></li><li><p>而 T2 和 T3 对应于创作时期和使用的材料类型</p></li></ul><p>这种相关性的一个真实世界的例子是一幅创作时期为 1635年的绘画和一种布面油画。</p><p>这幅画成为梵高的可能性几乎为零，因为梵高直到 1853 年才出生。</p><p>它更有可能是伦勃朗，因为他在那个时期很活跃。</p><p>因此，我们<strong>假设艺术数据中不同属性之间存在语义纠缠</strong>。</p><h3 id="方法概述">3.1 方法概述</h3><p>在本文中，我们提出了一种</p><blockquote><p>基于艺术数据多个属性之间的语义纠缠来学习共享表示的多任务学习方法。</p></blockquote><p>如图 2 所示，我们的方法包括</p><ul><li><p>用于<strong>特征提取</strong>的基础层块</p></li><li><p><strong>共享表示</strong>块</p></li><li><p>聚合所有任务的损失的组合<strong>损失</strong>层</p></li><li><p>每个任务的<strong>单独评估</strong>块</p></li></ul><p>我们在总和中执行损失聚合，根据它们源自的任务类型以及该特定属性对整体表现。</p><p>使用这种方法，我们提高了每项任务的判别性能，减少了训练和测试时间，因为一次性数据集遍历。</p><figure><img src="OmniArt1/2.png" alt="2" /><figcaption aria-hidden="true">2</figcaption></figure><h3 id="组合损失层">3.2 组合损失层</h3><p>我们提出了一个多任务卷积神经网络，该网络学习关于多种伴随元数据的艺术品的共享表示。</p><p>对于每个元数据属性，我们创建单独的任务并在模型中<strong>分配一个单独的分类/回归块</strong>，<strong>每个都有自己的损失函数</strong>。</p><p>通过我们的模型有效地传播这些梯度并让它们都正确影响训练的自然方法是总和。</p><p>在等式 2 中，Lt 是所有任务的组合损失，而 Li表示每个单独任务的损失。</p><p>参数 wi 和 si代表任务特定的损失权重矩阵，分别为每个任务分配不同的权重和任务特定的比例因子。<span class="math display">\[L_{t} = \sum_i^nw_is_iL_i\]</span>需要注意的是，这种组合损失函数的方式仅在它们共享具有可训练参数的层时才有效。</p><p>共享这样一个层意味着他们从同一级别获得输入</p><p>在损失函数方面，对于艺术家归因等分类任务，我们使用带有<strong>softmax 函数的分类交叉熵损失</strong>。</p><p>对于回归，我们<strong>应用缩放的平均绝对损失和公差为 ±50年的间隔精度</strong>。</p><p>由于区间精度本质上意味着分类，我们利用<strong>平均绝对损失来训练回归块</strong>。</p><p>这个挑战中的两个任务是多标签分类任务，因此我们在稀疏标签上使用二元交叉熵损失函数和sigmoid 激活。</p><p>虽然在这样的场景中自然会想到这种类型的损失聚合，但必须考虑损失值的影响和规模</p><p>实际上，<strong>产生的损失值回归任务被证明至少是分类任务或多标签任务中生成的任务的10 倍</strong></p><p>这会对学习产生负面影响，因为对共享表示的调整受回归任务的影响最大，而分类损失的重要性则降低了。</p><p>为了平衡影响并使分配的任务权重再次可靠，我们在反向传播时手动将回归（平均绝对）损失缩小了10 倍（sper iod = 10）。</p><p><strong>具体的比例因子可以通过在验证阶段监测损失值来确定</strong>。</p><h3 id="共享表示层">3.3 共享表示层</h3><p>由于我们使用深度模型作为特征提取器，我们将<strong>反向传播效果限制为仅附加层</strong>（每个任务的输出和共享层）。</p><p>反过来，与模型中包含的参数总数相比，我们只训练少量参数，因为：</p><ul><li>我们没有足够的标记数据来有效地从头开始调整深度模型中的过滤器（例如，Resnet-50有 25,583,592 个可训练参数而没有顶级输出层）</li><li>仅训练最终输出块可加快整个过程，同时仍能学习到良好的表示</li><li>数据维度更易于管理，训练效果更易于研究。</li></ul><p>鉴于不同任务Ti中的每个类之间存在联合概率，共享层是关于每个任务的数据的联合表示。</p><p>我们根据<strong>激活和隐藏单元的数量</strong>通过实验确定共享层配置。</p><blockquote><p>Tanh和 Sigmoid 等不同的<strong>激活函数</strong>不会像ReLU那样在我们的表示中促进稀疏性。</p></blockquote><p>我们认为稀疏因子在共享层的信息吸收中起着关键作用。</p><blockquote><p>共享层中<strong>隐藏单元</strong>的数量取决于每个任务的输出目标数量和数据的多样性本身。</p></blockquote><p>从学习的角度来看，这是可以预期的，因为更多的目标需要更多的可训练参数来学习有效的表示，反之亦然。</p><p>从这项工作第一阶段的实验中得出的另一种观点表明，并非所有任务都需要相同的<strong>输出深度</strong>。</p><p>实验结果表明，类型和周期预测任务可以通过较浅的架构有效地解决。</p><p>这也意味着训练时间的加快并减少内存消耗，因为可训练参数的数量在<strong>微调</strong>和<strong>从头开始设置</strong>中都会减少。</p><p>然而，<strong>将输出层分散在模型的不同深度意味着我们无法在共享表示层中对影响所有任务的组合数据表示的联合损失进行建模。</strong></p><p>由于该层不是网络的输出，它也可以用作高级特征提取点。</p><p>如果模型在每个任务上都表现良好，<strong>那么此时提取的特征将是输入数据的有效代表</strong>。</p><p>由于共享层中的单元数量有限，因此维度较低，当内存和计算能力有限时，这些特征将是首选。</p><h3 id="基础层">3.4 基础层</h3><p>我们的方法本质上与选择特征提取器作为共享表示的基础无关</p><p>因为用于预测和评估的特征是在共享层中学习的特征。</p><p>随着深度模型在视觉识别任务中的成功，我们尝试了许多不同的深度架构，如VGG-16、VGG-19、Inception V2 和 ResNet-50 作为特征提取器。</p><p>我们的实验结果表明，ResNet-50模型生成了最好的基础特征，因此我们在我们的方法中指定为特征提取器。</p><p>从分类器之前的最后一层提取特征，并通过共享表示层传播到每个任务的不同评估块。</p><p>组合损失的反向传播会针对每个任务修改共享表示层中的特征</p><h2 id="experiments">4 EXPERIMENTS</h2><p>通过我们的实验过程，我们旨在回答以下问题：</p><ul><li><p>哪个深度模型作为艺术数据集中的基本特征提取器表现最好？</p></li><li><p>学习多个相互关联的任务的表示是否可以提高整体预测性能？如果是，如何？</p></li><li><p>不同类型的任务（分类、回归、多标签）在组合环境中如何相互影响？</p></li><li><p>当任务属于不同类型时，哪些参数在共享表示设置中效果最好？</p></li><li><p>共享表示能否学习任务之间的语义联系并产生定性洞察？</p></li></ul><p>我们的实验装置有两个阶段。</p><p>在第一阶段，我们评估了国家博物馆挑战赛中<strong>每个任务的单个模型的性能</strong>，并将深度学习与Mensink 等人和其他最先进的方法进行了比较。</p><p>我们还提供新 OmniArt 数据集上四个任务的基线结果。</p><p>在评估模型并选择具有最佳预测性能的模型后，我们继续进行第 2 阶段。</p><p>实验设置的第 2 阶段侧重于</p><blockquote><p><strong>针对性能最佳的单任务深度学习模型评估具有不同超参数集、数据集拆分和共享表示大小的多任务模型</strong></p></blockquote><p>在这个阶段，我们还会生成最终结果。</p><h3 id="datasets">4.1 Datasets</h3><p>在我们的研究中，我们依赖于多个数据源，如博物馆、艺术维基网站和预编译数据集。</p><p>首先，我们从 WikiArt 爬取了一个数据集，其中包含来自 3000多位艺术家、150 种类型和 14 个不同历史时期的 126,078 张图像。</p><p>该数据集已用于评估各种算法，因为它将艺术作品与风格和流派联系起来</p><p>但是，WikiArt 缺少材料信息，目前未包含在 OmniArt 中。</p><p>数字艺术数据的一个相对较新的补充是大都会博物馆的在线收藏品，其中包含近50 万件艺术品和广泛的元数据。</p><p>在组装这个数据集时，我们注意到几乎一半的样本不属于公共领域或没有照片复制品，无法使用。</p><p>一个相当小的仅包含绘画的数据集是包含 5000 个绘画样本的 YourPaintings数据集，并且可以通过对象级注释公开获得。</p><p>法国国家图书馆收藏有 4,000 个样本，也可用，但由于缺乏材料信息及其依赖于法语注释，如 YourPaintings数据集，目前也被排除在外。</p><p>所有结果都适用于相同的数据集和拆分类型。</p><blockquote><p>我们将 70% 的数据集用于训练，20% 用于验证，10% 用于测试目的。</p></blockquote><p>拆分是按class进行的，这样每个class在所有实验阶段都具有相同的分布。</p><p>我们的方法依赖于<strong>单次遍历数据集</strong>，因此只能针对单个任务(Ti) 进行拆分。</p><p>在我们的案例中，由于数据集中的类别数量最多且具有细粒度的性质，因此该任务是艺术家归因。</p><blockquote><p>像这样进行拆分会导致其他任务中每个类别的样本分布不平衡，但我们通过使用它们在验证集上的组合损失中的比率来分配任务权重(wi) 来解决这个问题。</p></blockquote><p>由于艺术家是层次结构中最具体的class，我们计算与此任务相关的数据分布。</p><p>出于这个原因，我们只能将我们的实验结果与 2014年的国立博物馆挑战赛，在周期、材料和类型预测的完整数据集上进行比较。</p><p>使用我们的方法，我们还报告了新 OmniArt挑战中相同四个任务的基线性能。</p><p>我们将在接受后发布用于特征提取、数据拆分和评估引擎的模型，作为以博物馆为中心的挑战，并继续收集更多数据</p><h4 id="rijks14-数据集">4.1.1 Rijks’14 数据集</h4><p>Rijks'14 数据集由 T. Mensink 等人介绍。</p><p>2014 年，作为提议的国立博物馆挑战的一部分。 该数据集包含 112,039幅在国立博物馆展出的艺术品的照片复制品</p><p>由于 2014年国立博物馆挑战赛的数据集是以博物馆为中心的观点，它提供了各种对象类型，包括绘画、照片、陶瓷、家具、雕塑等。</p><p>数据集中的每个条目最多有四个标签。</p><p><strong>如果标签丢失或未知，则为条目分配未知类。</strong></p><h4 id="omniart-challenge-2017.">4.1.2 OmniArt Challenge 2017.</h4><p>自 2014 年以来，国立博物馆更新了他们的数字可用内容，其中包含 90,000多幅来自其收藏的艺术品的摄影复制品。</p><p>大都会艺术博物馆实施了一项名为“开放获取”的新政策，根据知识共享零(CC0)的规定，它可以广泛且免费地提供其认为属于公共领域的艺术品图像，以供不受限制地使用。</p><p>大都会还制作了来自整个在线收藏的元数据，作为其网站上可用的艺术家、标题、时期、媒介和材料和尺寸等图像的注释。</p><p>目前估计他们收藏的艺术品总数为 442,554件，但其中只有一半拥有属于公共领域的摄影复制品。</p><p>类似的注释可以在 Web Gallery of Art 数据集中找到，其中 40,000 件（约28,000幅绘画）艺术品与丰富的元数据相关联，如艺术家、技术、时期、类型、学校、地理起源等。</p><p>使用更新后的国立博物馆藏品，大都会博物馆和网络艺术画廊收藏品中的新藏品，我们创建了一个新的数据集，其中包含432,217 件艺术品的摄影复制品以及丰富的元数据。</p><p>此外，由于所有类型和材料都已翻译成英文，注释的质量也得到了提高。</p><blockquote><p>在预定义的训练、验证和测试拆分中消除了艺术品上的模糊标签，如未知、匿名和首字母缩略词，以便明确定义分类问题。</p></blockquote><p>除了以前可用的数据之外，我们还提供了一个元数据扩展，其中包含IconClass 、颜色代码、当前位置、实际大小和地理起源和技术等属性。</p><p><span class="math display">\[\begin{aligned}&amp;\text { Table 1: Featured datasets task-wise statistics }\\&amp;\begin{array}{lccccc}\hline \text { Data set } &amp; \text { Entries } &amp; \text { Artists} &amp; \text { Types } &amp; \text { Periods } &amp; \text { Materials} \\\hline \text { Rijks&#39;14 } &amp; 112,039 &amp; 6,626 &amp; 1,054&amp; 628 &amp; 406 \\\text { The Met } &amp; 201,953 &amp; 6,602 &amp; 561 &amp; 2,340 &amp;5,221 \\\text { OmniArt } &amp; 432,217 &amp; 21,364 &amp; 837 &amp; 2,389 &amp;6,385 \\\hline\end{array}\end{aligned}\]</span></p><h3 id="preprocessing">4.2 Preprocessing</h3><p><strong>具有深度架构的模型的缺点是需要大量数据才能正确训练和学习相关特征。</strong></p><p>考虑到这一点，我们将数据增强技术应用于我们的数据，以扩展数据集并引入标签安全的变体。</p><p>我们尝试了水平翻转、随机旋转、均值减法和 ZCA 美白。</p><p>在所有情况下，均值减法会使性能变差。</p><p>虽然可能不是预期的，但对于周期、类型和材料的预测是合乎逻辑的，因为输入样本的完整性很重要。</p><p>从金属雕刻中减去平均值板会导致原始图像的印象模糊，丢失重要的纹理信息。</p><blockquote><p>当仅将<strong>水平翻转</strong>应用于数据集中的随机图像时，我们获得了最佳结果，因此这是我们使用的唯一增强。</p></blockquote><h3 id="tasks-description">4.3 Tasks description</h3><p>由于我们使用 The Rijksmuseum 2014挑战赛的结果作为我们的主要基线，下面我们将描述我们评估模型的挑战赛中提出的不同任务。</p><h4 id="艺术家归属">4.3.1 艺术家归属</h4><p>OmniArt 数据集中有超过 21,000 位艺术家，其中 23 位拥有超过 700件艺术品收藏。</p><p>在 OmniArt 数据集中，<strong>有一位未知艺术家的作品</strong>。</p><p>对于 Rijks’14 数据集，未知类在表 2 中用 +u 标记。</p><p>这些艺术品也被排除在实验之外，因为它们可能属于 OmniArt挑战的现有类别。</p><p>艺术家归属是一项多类分类任务。 此任务的评估块包含一个 <strong>softmax层</strong>和用于<strong>不平衡数据拆分的分类权重矩阵</strong>（用于Rijks'14）</p><h4 id="创作期估计">4.3.2 创作期估计</h4><p>艺术品的范围从古代史前时代到 19 世纪后期。</p><p>对于许多可以追溯到早期历史时期的艺术品，没有确切的创作日期，因此提供了估计的创作间隔。</p><p>在这些情况下，我们将<strong>间隔的平均值作为创建日期</strong>。</p><p>我们将创建周期估计视为<strong>回归任务</strong>，以<strong>平均绝对误差（以年为单位）为指标</strong>。</p><p>我们使用从我们的共享表示中提取的特征训练了一个回归器。</p><h4 id="材料预测">4.3.3 材料预测</h4><p>OmniArt 数据集中的每件艺术品都有超过 6300 种材料。</p><p>这个任务是一个<strong>多标签分类问题</strong>，因为每件艺术品都可以有一种或多种材料。</p><p>在 OmniArt 挑战赛的 180,387件艺术品中，<strong>纸张是最常见的材料</strong>。</p><blockquote><p>由于任务的<strong>不平衡性质</strong>，这有助于<strong>为材料任务分配较低的损失权重</strong>。</p></blockquote><p>由于材料通常有<strong>嘈杂</strong>的标签，我们将词干应用于材料的每个单词。</p><blockquote><p><strong>二元交叉熵</strong>被指定为材料预测的损失函数，以平均精度为度量</p></blockquote><h4 id="类型预测">4.3.4 类型预测</h4><p>类型预测是一项多标签分类任务，在 OmniArt 挑战赛中有 837个不同的类别。</p><p>最常见的艺术品类型是paint（s），出现了 108,823 次。</p><p>具有大量示例的有趣类型类别包括 36.785 个条目的painting和 31,396个条目的photograph。</p><p>对于这个任务，我们使用与材料预测相同的设置，但任务权重不同。</p><h3 id="第一阶段选择基础层">4.4 第一阶段：选择基础层</h3><p>在第一阶段，我们评估流行的深度模型在我们四个任务中的每一个的性能。</p><p>评估是在<strong>微调设置中进行的</strong>，从<strong>从头开始训练</strong>设置，最后是我们使用<strong>额外的外部数据集</strong>来调整模型的在为手头的任务进行微调之前的权重和过滤器的设置</p><p><strong>微调是通过仅训练模型的最后一层而不修改预先学习的过滤器来执行的</strong></p><p>此阶段允许查看不同的模型架构如何对我们的每个任务做出反应，并深入了解哪种模型最适合多任务场景中的所有任务。</p><p>实验设计的第 1阶段是关于在单个任务上测试模型性能，以评估用于它们组合的最佳架构。</p><p>我们在 ImageNet 上尝试了几种性能最好的深度架构，例如 Resnet-50、VGG-16、VGG-19 和 Inception v2</p><p>我们使用 ResNet-50模型（没有顶部块）的特征获得了最佳结果，并在其他实验中继续将其用作主要特征提取单元。</p><p>我们实验设计的这个阶段特别重要，因为它可以直接与所有四个任务中的最先进方法进行比较，因为我们可以使用相同的数据拆分。</p><p>表 2 显示了 Mensink 等人的手工特征方法、CNN 和我们的方法 OmniArt之间的直接比较。</p><figure><img src="OmniArt1/table2.png" alt="table2" /><figcaption aria-hidden="true">table2</figcaption></figure><h3 id="第二阶段评估我们的多任务方法">4.5第二阶段：评估我们的多任务方法</h3><p>第二阶段包括<strong>构建符合问题多任务性质的最优架构</strong>。</p><p>在方法部分中，<strong>我们解释了共享表示可以有利于目标相关的任务</strong>。</p><p>配置最佳共享表示是我们在此阶段尝试完成的目标，同时找到适合数据集每个拆分的最佳共享表示大小。</p><p>在这个阶段，我们<strong>测试了各种超参数</strong>并选择了整体性能最佳的设置，因为所有任务都有不同的性质，并且容易对架构的变化做出不同的反应。</p><p>我们通过比较在 The Rijksmuseum Challenge 中提出的所有 4个任务的分数来评估我们的多任务模型。</p><p>对于 Rijks'14 数据集，我们与 Mensink等人进行了比较。因为他们是国立博物馆挑战赛的原始创造者，并且对所有提议的任务都有分数。</p><p>对于 OmniArt数据集，我们比较了我们的方法与单任务深度卷积神经网络的性能。</p><p>在表 2 中，我们观察到使用多任务方法在所有 4个任务上都获得了最佳性能。</p><p>然而，在 374+u案例中，手工制作的特征在艺术家归因方面的表现优于深度网络。</p><p>这可能是由于每个类的示例数量非常有限，因此无法学习良好的表示，而手工制作的特征即使对于如此少量的数据也能保持其质量。</p><p>在表 4 中，我们看到了 OmniArt 方法与单任务深度 CNN 的性能对比。</p><p>一个有趣的发现是，随着<strong>每个艺术家阈值的样本降低，艺术家归因性能下降，但对于多标签任务则相反。</strong></p><p>我们相信，当我们使用更高百分比的数据集时，我们在多标签设置中每个类获得更多样本，而输出目标的数量保持不变，这对于表示学习很重要。</p><figure><img src="OmniArt1/table4.png" alt="table4" /><figcaption aria-hidden="true">table4</figcaption></figure><blockquote><p>共享表示大小对于性能也很重要。</p></blockquote><p>我们尝试了从 1024 到 8192 单位的大小，并在 6144单位的所有任务中实现了最佳的整体平衡。</p><p>通过本阶段的实验，我们观察到具<strong>有较小的共享表示层有利于周期估计</strong>，其中使用<strong>较小的共享表示大小</strong>可以实现8.3 年的平均绝对误差下降。</p><p>一个有趣的事实是，在保持良好的判别性能的同时，多任务方法显着缩短了训练和测试时间，使其比模型每任务方法更有效。</p><p>我们计算出，在测试阶段，所有 4 个任务需要 OmniArt 6.22 秒才能完成 200批 32 张图像。</p><p>对于相同的设置，单任务 CNN 每个任务需要 2.13 秒。</p><p>在这种情况下，这是 25% 的加速。</p><p>在训练阶段可以观察到执行时间的更大改进。</p><p>OmniArt 在单个 Nvidia Titan X 上每类设置 &gt; 1100个样本进行训练大约需要 73 分钟，而四个单任务模型的组合训练时间为 198分钟，比我们的多任务方法慢 2.6 倍。</p><h3 id="定性分析">4.6 定性分析</h3><p>定量表现测量显示出良好的艺术家归属表现，但存在艺术家归属的错误分类。</p><p>在我们移除主对角线后，进一步探索在图 5 和图 3中清晰可见的类之间的内部混淆，揭示了一个有趣的发现，我们称之为<strong>Luyken 案例</strong>。</p><figure><img src="OmniArt1/fig3.png" alt="fig3" /><figcaption aria-hidden="true">fig3</figcaption></figure><figure><img src="OmniArt1/fig5.png" alt="fig5" /><figcaption aria-hidden="true">fig5</figcaption></figure><h4 id="the-luyken-case">The Luyken case</h4><p>Luyken 案例源于 17 世纪晚期荷兰书籍插画家 Caspar Luyken（第 16 级）和Jan Luyken（第 12 级）之间的混淆，在图 5 中清晰可见。</p><p>Caspar Luyken是 JanLuyken（荷兰书籍插画家）的儿子，他的父亲也是他的老师，他们经常一起使用相同的技术和材料。</p><p>作为父子，他们也共享同一时期，平均误差为 52.2 年，很容易被忽略。</p><p>然而，几乎所有的混淆样本都来自他们共同活跃的时期，而正确的样本要么来自儿子生产生活的后期，要么来自父亲的早期</p><p>额外的数据集探索表明，正确指定的艺术品在材料和时期上存在差异，这进一步证明了将其视为多任务问题的好处。</p><p>这一发现表明，在与父亲分离并前往德国的一家艺术品经销商工作后，儿子的技术发生了演变。</p><p>这样的结果支持我们的假设，<strong>即不同任务中不同数据属性之间的语义纠缠可以用我们的方法在共享表示中建模。</strong></p><h2 id="conclusions">5 CONCLUSIONS</h2><p>OmniArt 方法在 Rijks的数据集上优于当前最先进的方法，并加快了训练和测试时间。</p><p>就最佳定量结果而言，性能可以受益于传统的提升技术，例如训练模型集合、应用不同的投票技术和调整超参数。</p><p>虽然绝对数字是一项重要的质量和性能衡量标准，但基本改进足以证明我们的方法是有效的。</p><p>我们不断扩展和改进的 OmniArt挑战以挑战的形式呈现，以刺激艺术数据领域的进一步研究和开发。</p><p>虽然这项工作只关注艺术数据，但同样的想法可以很容易地适应并转移到不同的领域。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1
id=&quot;omniart-multi-task-deep-learning-for-artistic-data-analysis&quot;&gt;OmniArt:
Multi-task Deep Learning for Artistic Data Analysis&lt;/h1&gt;
&lt;h2 i</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="属性识别" scheme="http://www.larryai.com/tags/%E5%B1%9E%E6%80%A7%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>SEAN:Image Synthesis With Semantic Region-Adaptive Normalization</title>
    <link href="http://www.larryai.com/2022/05/16/SEAN/"/>
    <id>http://www.larryai.com/2022/05/16/SEAN/</id>
    <published>2022-05-16T09:53:19.000Z</published>
    <updated>2022-05-16T10:04:53.546Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="图片/fig1.png" alt="fig1" /><figcaption aria-hidden="true">fig1</figcaption></figure><h1 id="abstract">Abstract</h1><p>我们提出语义区域自适应归一化（SEAN）</p><p>这是生成对抗网络的一个简单但有效的构建块，其条件是<strong>分割掩码</strong>，描述了所需输出图像中的语义区域</p><p>使用 SEAN归一化，我们可以构建一个可以单独控制每个语义区域的样式的网络架构</p><p>例如，我们可以为每个区域指定一个样式参考图像</p><p>在重建质量、可变性和视觉质量方面，SEAN比以前最好的方法更适合编码、转移和合成风格</p><p>我们在多个数据集上评估 SEAN，并报告比当前技术水平更好的定量指标（例如FID、PSNR）</p><p>SEAN 还推动了<strong>交互式图像编辑</strong>的前沿</p><p>我们可以通过<strong>更改分割掩码或任何给定区域的样式来交互式地编辑图像</strong></p><p>我们还可以从每个区域的两个参考图像中插入样式</p><p>代码：https://github.com/ZPdesu/SEAN</p><h1 id="introduction">1. Introduction</h1><p>在本文中，我们使用条件生成对抗网络 (cGAN) 解决合成图像生成问题</p><p>具体来说，我们想使用分割掩码来控制生成图像的布局</p><p><strong>每个语义区域都有标签</strong>，并根据标签为每个区域“添加”逼真的风格</p><ul><li><p>面部生成应用程序将使用区域标签，如眼睛、头发、鼻子、嘴巴等</p></li><li><p>风景画应用程序将使用水、森林、天空、云等标签</p></li></ul><p>虽然存在多种非常好的框架来解决这个问题</p><p>目前最好的架构是 SPADE （也称为 GauGAN)。因此，我们决定使用 SPADE作为我们研究的起点。</p><p>通过分析 SPADE 结果，我们发现了我们希望在工作中改进的两个缺点。</p><p>首先</p><p><strong><em>SPADE仅使用一个样式代码来控制图像的整个样式，这不足以进行高质量的合成或细节控制</em></strong></p><p>例如，所需输出图像的分割掩码很容易包含输入风格图像的分割掩码中不存在的标记区域。</p><p>在这种情况下，缺失区域的样式是未定义的，这会产生低质量的结果</p><p>此外，SPADE 不允许对分割掩码中的每个区域使用不同样式的输入图像</p><p>因此，<strong>我们的第一个主要思想是单独控制每个区域的样式</strong></p><p>即<strong>我们提出的架构接受每个区域（或每个区域实例）的一个样式图像作为输入</strong></p><p>其次</p><p>我们认为<strong><em>仅在网络开头插入样式信息不是一个好的架构选择</em></strong></p><p>最近的架构 [26, 32, 2]已经证明，如果将样式信息作为归一化参数注入到网络中的多个层中，则可以获得更高质量的结果，例如使用 AdaIN</p><p>然而，这些先前的网络都没有使用样式信息来生成空间变化的归一化参数</p><p>为了缓解这个缺点，我们的第二个主要想法是设计一个标准化构建块，称为SEAN</p><p><strong>它可以使用样式输入图像为每个语义区域创建空间变化的归一化参数</strong></p><p>这项工作的一个重要方面是<strong>空间变化的归一化参数取决于分割掩码以及样式输入图像</strong></p><p>根据经验，我们在几个具有挑战性的数据集上对我们的方法进行了广泛的评估</p><p>CelebAMaskHQ 、CityScapes 、ADE20K 和我们自己的 Facades 数据集</p><p>定量地，我们评估我们在广泛的指标上的工作，包括 FID、PSNR、RMSE和分割性能</p><p>定性地，我们展示了可以通过视觉检查评估的合成图像的示例</p><p>我们的实验结果表明，与当前最先进的方法相比有了很大的改进</p><p>综上所述，我们引入了一种新的架构构建块 SEAN，它具有以下优点：</p><ul><li>SEAN 提高了条件 GAN 合成图像的质量。 我们与最先进的方法 SPADE 和Pix2PixHD 进行了比较，并在定量指标（例如 FID分数）和目视检查方面取得了明显的改进。</li><li>SEAN 改进了每个区域的风格编码，因此可以使重建的图像更类似于通过 PSNR和视觉检查测量的输入风格图像</li><li>SEAN 允许用户为每个语义区域选择不同风格的输入图像。与当前最先进的方法相比，这使图像编辑功能能够产生更高的质量并提供更好的控制。示例图像编辑功能是逐个区域的交互式风格转换和每个区域的风格插值（参见图1、2 和 5）</li></ul><figure><img src="图片/fig2.png" alt="fig2" /><figcaption aria-hidden="true">fig2</figcaption></figure><h1 id="related-work">2. Related Work</h1><h2 id="generative-adversarial-networks">2.1 Generative AdversarialNetworks</h2><p>自 2014 年推出以来，生成对抗网络 (GAN)已成功应用于各种图像合成任务</p><p>例如 图像修复 ，图像处理 和纹理合成</p><p>随着 GAN 架构 、损失函数 和 正则化 的不断改进 GAN合成的图像变得越来越逼真</p><p>例如，StyleGAN生成的人脸图像质量非常高，与未经训练的观看者的照片几乎没有区别</p><p>传统的 GAN 使用噪声向量作为输入，因此几乎不提供用户控制</p><p>这激发了条件GAN（cGAN）的发展，用户可以通过向生成器提供条件信息来控制合成</p><p>示例包括类标签 文本 和图像</p><p>我们的工作建立在具有图像输入的条件 GAN之上，旨在解决图像到图像的转换问题</p><h2 id="image-to-image-translation">2.2 Image-to-Image Translation</h2><p>图像到图像的转换是一个总括概念，可用于描述计算机视觉和计算机图形学中的许多问题</p><p>作为一个里程碑，Isola 等人 首先表明图像条件 GAN可以用作各种图像到图像转换问题的通用解决方案</p><p>从那时起，他们的方法通过以下几项工作扩展到场景，包括：</p><p>无监督学习 ，少样本学习 ，高分辨率图像合成 ，多模态图像合成和多模态图像合成 域图像合成</p><p>在各种图像到图像的翻译问题中，语义图像合成是一种特别有用的类型，因为它可以通过修改输入的语义布局图像来轻松控制</p><p>迄今为止，SPADE 模型（也称为 GauGAN）产生了最高质量的结果</p><p>在本文中，我们将通过引入 per-region 样式编码来改进 SPADE</p><h2 id="style-encoding">2.3 Style Encoding</h2><p>样式控制是各种图像合成和处理应用程序的重要组成部分</p><p>样式通常不是由用户手动设计的，而是从参考图像中提取的</p><p>在大多数现有方法中，样式在三个地方进行编码：</p><ul><li><p>图像特征的统计</p></li><li><p>神经网络权重（例如快速风格迁移）</p></li><li><p>网络标准化层的参数</p></li></ul><p>当应用于风格控制时</p><p>第一种编码方法通常很耗时，因为它需要一个缓慢的优化过程来匹配图像分类网络提取的图像特征的统计数据</p><p>第二种方法实时运行，但每个神经网络只编码所选参考图像的样式</p><p>因此，需要一个单独的神经网络为每个风格的图像进行训练，这限制了它在实践中的应用</p><p>迄今为止，第三种方法是最好的，因为它可以实时进行任意风格迁移</p><p>并且被 StyleGAN 、FUNIT 和 SPADE 等高质量网络使用</p><p>我们的按区域样式编码也建立在这种方法之上</p><p>我们将展示我们的方法产生更高质量的结果并实现更详细的用户控制。</p><h1 id="per-region-style-encoding-and-control">3. Per Region StyleEncoding and Control</h1><p>Per Region Style Encoding and Control 按区域样式编码和控制</p><p>给定一个输入风格图像及其对应的分割掩码，本节展示</p><ul><li><p>如何根据掩码从图像中提取每个区域的风格</p></li><li><p>如何使用提取的每个区域的风格代码来合成照片般逼真的图像</p></li></ul><h2 id="how-to-encode-style">3.1 How to Encode Style?</h2><p><strong>Per-Region Style Encoder(按区域样式编码器)</strong></p><p>为了提取每个区域的样式，我们提出了一种新颖的样式编码器网络</p><p>可以同时从输入图像的每个语义区域中提取相应的样式代码（参见图 4 (A)中的子网络样式编码器）</p><p>风格编码器的输出是一个 512×s 维度的风格矩阵 ST，其中 s是输入图像中语义区域的数量</p><p>矩阵的每一列对应一个语义区域的样式代码</p><p>与基于简单缩减卷积神经网络的标准编码器不同</p><p><strong>我们的（Per-Region StyleEncoder）每区域风格编码器采用“瓶颈”结构从输入图像中删除与风格无关的信息</strong></p><p>结合样式应该独立于语义区域形状的先验知识</p><p>我们将网络块 TConv-Layers 生成的中间特征图（512个通道）通过区域平均池化层并将它们减少到 512 个集合维向量</p><p>作为实现细节，我们要说明的是，我们使用 s作为数据集中语义标签的数量，并将输入图像中不存在的区域对应的列设置为0</p><p>作为这种架构的变体，我们还可以提取具有实例标签的数据集的每个区域实例的样式，例如 CityScapes</p><figure><img src="图片/fig4.png" alt="fig4" /><figcaption aria-hidden="true">fig4</figcaption></figure><h2 id="how-to-control-style">3.2 How to Control Style?</h2><p>以每个区域的<strong>样式代码</strong>和分割掩码作为输入</p><p>我们提出了一种<strong>新的条件归一化技术</strong>，称为<strong>语义区域自适应归一化(SEAN)</strong></p><p>以实现对逼真图像合成的样式的详细控制</p><p>与现有的归一化技术类似，SEAN 通过调制生成器激活的尺度和偏差来工作</p><p>与所有现有方法相比，<strong>SEAN学习的调制参数取决于样式代码和分段掩码</strong></p><p>在 SEAN 块中（图 3）</p><p><strong>样式映射</strong> 是第一代通过根据输入<strong>分割掩码</strong> 将 <strong>样式代码</strong>广播到其相应的语义区域来进行操作</p><p>然后将该 样式图 与 输入<strong>分割掩码</strong>一起<strong>通过两个单独的卷积神经网络来学习两组调制参数</strong></p><p>它们的加权和用作最终的 SEAN 参数，以调节生成器激活的尺度和偏差</p><p>权重参数在训练期间也是可学习的。 SEAN的正式定义介绍如下</p><figure><img src="图片/fig3.png" alt="fig3" /><figcaption aria-hidden="true">fig3</figcaption></figure><p><strong>Semantic Region-Adaptive Normalization(SEAN)</strong>（语义区域自适应归一化）</p><p>一个 SEAN 块有两个输入：</p><ul><li><p>一个编码每个区域样式代码的<strong>样式矩阵 ST</strong></p></li><li><p>一个<strong>分割掩码 M</strong></p></li></ul><p>让 h 表示在深度卷积网络中当前 SEAN 块的输入激活，用于一批 N个样本</p><p>令 H、W 和 C 为激活图中的高度、宽度和通道数</p><p>位点 (n ∈ N, c ∈ C, y ∈ H, x ∈ W ) 处的调制激活值由下式给出 <spanclass="math display">\[\gamma_{c, y, x}(\mathbf{S T}, \mathbf{M}) \frac{h_{n, c, y,x}-\mu_{c}}{\sigma_{c}}+\beta_{c, y, x}(\mathbf{S T}, \mathbf{M})\]</span></p><ul><li><span class="math inline">\(h_{n, c, y, x}\)</span> 是标准化前</li><li>调制参数<span class="math inline">\(\gamma_{c, y, x}\)</span>和<spanclass="math inline">\(\beta_{c, y, x}\)</span>是 <spanclass="math inline">\(\gamma_{c, y, x}^{s}, \gamma_{c, y,x}^{o}\)</span> 和 <span class="math inline">\(\beta_{c, y, x}^{s},\beta_{c, y, x}^{o}\)</span>的加权和</li></ul><p><span class="math display">\[\begin{aligned}&amp;\gamma_{c, y, x}(\mathbf{S T}, \mathbf{M})=\alpha_{\gamma}\gamma_{c, y, x}^{s}(\mathbf{S T})+\left(1-\alpha_{\gamma}\right)\gamma_{c, y, x}^{o}(\mathbf{M}) \\&amp;\beta_{c, y, x}(\mathbf{S T}, \mathbf{M})=\alpha_{\beta} \beta_{c,y, x}^{s}(\mathbf{S T})+\left(1-\alpha_{\beta}\right) \beta_{c, y,x}^{o}(\mathbf{M})\end{aligned}\]</span></p><ul><li><span class="math inline">\(\mu_c\)</span> 和 <spanclass="math inline">\(\sigma_{c}\)</span>是在通道c上的激活均值和标准差<span class="math display">\[\begin{gathered}\mu_{c}=\frac{1}{N H W} \sum_{n, y, x} h_{n, c, y, x} \\\sigma_{c}=\sqrt{\frac{1}{N H W}\left(\sum_{n, y, x} h_{n, c, y,x}^{2}\right)-\mu_{c}^{2}}\end{gathered}\]</span></li></ul><h1 id="experimental-setup">4. Experimental Setup</h1><h2 id="network-architecture">4.1 Network Architecture</h2><figure><img src="图片/fig4.png" alt="fig4" /><figcaption aria-hidden="true">fig4</figcaption></figure><p>图 4 (A) 显示了我们的生成器网络的概述，它建立在 SPADE 的基础上</p><p>我们<strong>使用了一个由几个带有上采样层的 SEAN ResNet 块 (SEANResBlk) 组成的生成器</strong></p><p><strong>SEAN ResBlk</strong></p><p>图 4 (B) 显示了我们的 SEAN ResBlk 的结构</p><p>它由三个卷积层组成，其尺度和偏差分别由三个 SEAN 块调制</p><p>每个 SEAN 块有两个输入：</p><ul><li><p>一组每个区域的样式代码 ST</p></li><li><p>一个语义掩码 M</p></li></ul><p>请注意，两个输入都在开始时进行了调整：</p><ul><li><p><strong>输入分割掩码被下采样到与特征图相同的高度和宽度层</strong></p></li><li><p><strong>来自 ST 的输入样式代码使用 1 × 1 卷积层 Aij对每个区域进行转换</strong></p></li></ul><p>我们观察到初始转换是架构中不可或缺的组成部分，因为它们根据每个神经网络层的不同角色转换样式代码</p><p>例如，早期层可能控制人脸图像的发型（例如波浪形、直发），而后面的层可能涉及照明和颜色</p><p>此外，我们观察到在 SEAN 的输入中添加噪声可以提高合成图像的质量</p><p><strong>这种噪声的大小由训练期间学习的每通道缩放因子 B进行调整</strong>，类似于 StyleGAN</p><h2 id="training-and-inference">4.2 Training and Inference</h2><h3 id="training">4.2.1 Training</h3><p><strong>我们将训练制定为图像重建问题</strong></p><p>也就是说，<strong>风格编码器被训练为根据其对应的分割掩码从输入图像中提取每个区域的风格代码</strong></p><p>生成器网络经过训练，以<strong>提取的每个区域样式代码和相应的分割掩码作为输入来重建输入图像</strong></p><p>继 SPADE 和 Pix2PixHD之后，<strong>输入图像和重建图像之间的差异通过由三个损失项组成的整体损失函数来衡量</strong>：</p><ul><li><p>条件对抗损失</p></li><li><p>特征匹配损失</p></li><li><p>感知损失</p></li></ul><p>损失函数的详细信息包含在补充材料中</p><h3 id="inference">4.2.2 Inference</h3><p>在推理过程中，我们将任意分割掩码作为掩码输入</p><p>并实现每个区域的样式通过为每个语义区域选择单独的 512维样式代码作为样式输入来进行控制</p><p>这使得各种高质量的图像合成应用成为可能，这将在下一节中介绍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;figure&gt;
&lt;img src=&quot;图片/fig1.png&quot; alt=&quot;fig1&quot; /&gt;
&lt;figcaption aria-hidden=&quot;true&quot;&gt;fig1&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图像生成" scheme="http://www.larryai.com/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"/>
    
    <category term="GAN" scheme="http://www.larryai.com/tags/GAN/"/>
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>图像的三种数据格式</title>
    <link href="http://www.larryai.com/2022/05/16/%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/"/>
    <id>http://www.larryai.com/2022/05/16/%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/</id>
    <published>2022-05-16T01:56:13.000Z</published>
    <updated>2022-05-16T14:09:51.598Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图像的三种数据格式">1.图像的三种数据格式</h1><ul><li>numpy</li><li>tensor</li><li>PIL.Image</li></ul><h1 id="图像格式的转换基础转换">2.图像格式的转换——基础转换</h1><h2 id="numpy与tensor的转换">numpy与tensor的转换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">tensor_data = torch.tensor(np_data)</span><br><span class="line">np_data = np.array(tensor_data)</span><br></pre></td></tr></table></figure><h2 id="numpy与pil.image的转换">numpy与PIL.Image的转换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">np_data = np.array(PIL_img, dtype=np.uint8)</span><br><span class="line">PIL_img = Image.fromarray(numpy_img)</span><br></pre></td></tr></table></figure><h2 id="pil.image与tensor的转换">PIL.Image与tensor的转换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms </span><br><span class="line"></span><br><span class="line">tensor_img  = transforms.ToTensor()(PIL_img)</span><br><span class="line">PIL_img = transforms.ToPILImage()(tensor_img) </span><br></pre></td></tr></table></figure><h1 id="不同图像格式的保存">3.不同图像格式的保存</h1><h2 id="numpy格式图像保存">numpy格式图像保存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;&#x27;</span></span><br><span class="line">np_img = <span class="string">&#x27;&#x27;</span></span><br><span class="line">cv.imwrite(save_path , np_img)</span><br></pre></td></tr></table></figure><h2 id="pil.image格式图像保存">PIL.Image格式图像保存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PIL_img.save(save_path)</span><br></pre></td></tr></table></figure><h2 id="tensor格式的图像保存">tensor格式的图像保存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line">save_image(tensor_img , <span class="string">&#x27;save_path&#x27;</span>)</span><br></pre></td></tr></table></figure><h1id="深度学习图像生成情况下的保存图像">4.深度学习图像生成情况下的保存图像</h1><h2 id="得到pil.image图像">得到PIL.Image图像</h2><ul><li>创建生成网络G</li><li>输入图像img（PIL.Image格式）</li><li>print工具</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># print工具 定义输出size</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_print_tool</span>(<span class="params">size=<span class="number">512</span></span>):</span><br><span class="line">    <span class="keyword">return</span> torch.hub.load(<span class="string">&quot;bryandlee/animegan2-pytorch:main&quot;</span>, <span class="string">&quot;face2paint&quot;</span>, size=size)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 生成网络</span></span><br><span class="line">  G = <span class="literal">None</span></span><br><span class="line">  <span class="comment"># 输入图像 （由路径获得）</span></span><br><span class="line">  PIL_img  = Image,<span class="built_in">open</span>(path).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">  out_imgPIL = imgpaint(netG, PIL_img)</span><br></pre></td></tr></table></figure><p>得到PIL.Image格式图片后 ， 接下来有两者保存方式</p><p>1.直接保存</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_imgPIL.save(save_path)</span><br></pre></td></tr></table></figure><p>2.变成numpy格式（方便拼接）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img_np = np.array(out_imgPIL) <span class="comment">#变成numpy格式</span></span><br><span class="line">img_bgr = cv.cvtColor(img_np, cv.COLOR_RGB2BGR) <span class="comment">#变成BGR格式</span></span><br><span class="line"><span class="comment"># 一系列别的操作 #</span></span><br><span class="line">cv.imwrite(path,img_bgr)</span><br></pre></td></tr></table></figure><h2 id="得到tensor变量">得到tensor变量</h2><p>得到tensor格式图片后 ， 接下来有两者保存方式</p><ul><li>直接用tensor的保存方式</li><li>变为numpy进行一系列操作后保存【同上】</li></ul><h1 id="web端部署是处理的情况">5.web端部署是处理的情况</h1><p>在web端部署深度学习图像相关的应用时，我们需要处理从web获取图片并且返回图像的问题</p><p>1.从web获取图像变成PIL格式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"></span><br><span class="line">img = Image.<span class="built_in">open</span>(BytesIO(image)).convert(<span class="string">&quot;RGB&quot;</span>)</span><br></pre></td></tr></table></figure><p>2.由numpy格式的图像返回到web</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确保是BGR格式的 如果不是 参考上面的代码</span></span><br><span class="line">img_result = cv.imencode(<span class="string">&#x27;.jpg&#x27;</span>, img_bgr)[<span class="number">1</span>].tostring()</span><br><span class="line">img_result = base64.b64encode(img_result).decode()</span><br><span class="line"><span class="comment"># 将img_result返回即可</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;图像的三种数据格式&quot;&gt;1.图像的三种数据格式&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;numpy&lt;/li&gt;
&lt;li&gt;tensor&lt;/li&gt;
&lt;li&gt;PIL.Image&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;图像格式的转换基础转换&quot;&gt;2.图像格式的转换——基础转换&lt;/h1&gt;
&lt;</summary>
      
    
    
    
    
    <category term="Python" scheme="http://www.larryai.com/tags/Python/"/>
    
    <category term="Pytorch" scheme="http://www.larryai.com/tags/Pytorch/"/>
    
    <category term="Numpy" scheme="http://www.larryai.com/tags/Numpy/"/>
    
  </entry>
  
  <entry>
    <title>OPENCV-视频与图像的转换</title>
    <link href="http://www.larryai.com/2022/05/16/video2pic/"/>
    <id>http://www.larryai.com/2022/05/16/video2pic/</id>
    <published>2022-05-16T01:27:34.000Z</published>
    <updated>2022-05-16T01:39:36.654Z</updated>
    
    <content type="html"><![CDATA[<h2 id="video2pics">video2pics</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">video_path = <span class="literal">None</span>  <span class="comment"># 视频来源路径</span></span><br><span class="line">save_path = <span class="literal">None</span>  <span class="comment"># 图片保存路径</span></span><br><span class="line">cap = cv.VideoCapture(video_path)  <span class="comment"># 创建视频捕捉对象</span></span><br><span class="line">fps = <span class="built_in">int</span>(cap.get(cv.CAP_PROP_FPS))  <span class="comment"># 获取帧率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;FPS:&#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(fps))</span><br><span class="line"><span class="comment"># 获取视频总长</span></span><br><span class="line">rate = cap.get(<span class="number">5</span>)</span><br><span class="line">frame_num = cap.get(<span class="number">7</span>)</span><br><span class="line">duration = frame_num / rate</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;video total time:&#123;:.2f&#125;s&#x27;</span>.<span class="built_in">format</span>(duration))</span><br><span class="line"></span><br><span class="line">cnt = <span class="number">0</span></span><br><span class="line">num = <span class="number">0</span></span><br><span class="line">interval = <span class="number">1</span>  </span><br><span class="line">process_num = frame_num // interval</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;process frame:&#123;:.0f&#125;&#x27;</span>.<span class="built_in">format</span>(process_num))</span><br><span class="line"></span><br><span class="line">t0 = time.time()</span><br><span class="line"><span class="keyword">while</span> cap.isOpened():</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> ret:</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> cnt % interval == <span class="number">0</span>:</span><br><span class="line">            num += <span class="number">1</span></span><br><span class="line">            <span class="comment"># frame = cv.resize(frame, (width, height))</span></span><br><span class="line">            cv.imwrite(save_path + <span class="string">&quot;/%d.jpg&quot;</span> % num, frame)</span><br><span class="line">            remain_frame = process_num - num</span><br><span class="line">            t1 = time.time() - t0</span><br><span class="line">            t0 = time.time()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Processing %d.jpg, remain frame: %d, remain time: %.2fs&quot;</span> % (num, remain_frame, remain_frame * t1))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="pics2video">pics2video</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">fps = <span class="number">30</span>  <span class="comment"># 帧率</span></span><br><span class="line">photo_size = (<span class="number">828</span>, <span class="number">456</span>)  <span class="comment"># 尺寸大小</span></span><br><span class="line">fourcc = cv2.VideoWriter_fourcc(*<span class="string">&#x27;X264&#x27;</span>)  <span class="comment"># 格式</span></span><br><span class="line">video = <span class="string">&#x27;xxx.mov&#x27;</span>  <span class="comment"># 保存的视频路径</span></span><br><span class="line">videoWriter = cv2.VideoWriter(video, fourcc, fps, photo_size)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    image = <span class="string">&quot;out/gl&quot;</span> + <span class="built_in">str</span>(i) + <span class="string">&quot;.jpg&quot;</span>  <span class="comment"># 图片路径</span></span><br><span class="line">    frame = cv2.imread(image)</span><br><span class="line">    videoWriter.write(frame)</span><br><span class="line">videoWriter.release()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;video2pics&quot;&gt;video2pics&lt;/h2&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span</summary>
      
    
    
    
    
    <category term="OPENCV" scheme="http://www.larryai.com/tags/OPENCV/"/>
    
  </entry>
  
  <entry>
    <title>StyTR2</title>
    <link href="http://www.larryai.com/2022/05/06/StyTR2/"/>
    <id>http://www.larryai.com/2022/05/06/StyTR2/</id>
    <published>2022-05-06T12:18:40.000Z</published>
    <updated>2022-05-07T00:11:38.306Z</updated>
    
    <content type="html"><![CDATA[<h1 id="abstract">Abstract</h1><p><strong><em>风格转换的目标是在保持原有内容的同时，在风格参照的指导下呈现出具有艺术特征的图像</em></strong></p><p>由于卷积神经网络（CNN）的局部性，很难提取和维护输入图像的全局信息。</p><p>因此，<strong>传统的神经风格转换方法面临着有偏见的内容表示</strong></p><p>为了解决这个关键问题，我们提出了一种基于转换器的方法，称为StyTr2 &gt;将输入图像的长期依赖性考虑到图像样式传输中</p><p>与其他视觉任务的视觉转换器不同<strong>StyTr2包含两个不同的转换器编码器，分别为内容和样式生成特定于域的序列</strong>在编码器之后<strong>采用多层转换器解码器根据样式序列对内容序列进行样式化</strong></p><p>我们还分析了现有位置编码方法的不足，提出了<strong>内容感知位置编码（CAPE）</strong>&gt; 它具有尺度不变性，更适合于图像样式传输任务</p><p>定性和定量实验表明，与最先进的基于CNN和基于流的方法相比，所提出的StyTr2是有效的。</p><p>代码和模型可在https://github.com/diyiiyiii/StyTR-2</p><h1 id="introduce">1.Introduce</h1><p>此处省略一些内容 详细可查看原论文</p><p>总之，我们的主要贡献包括 -一个名为StyTr2的基于转换器的风格转换框架，以生成风格化结果，并保留输入内容图像的结构和细节- 一种基于内容的位置编码方案，具有尺度不变性，适用于样式转换任务 -综合实验表明，StyTr2形成了基线方法，并以理想的内容结构和风格模式取得了显著的效果</p><h1 id="relate-work">2.Relate Work</h1><ul><li>图像风格迁移</li><li>视觉任务的transformer &gt;在本文中，我们介绍了用于样式转换任务的基于变换器的结构，可以将其视为图像块的序列到序列生成</li><li>位置编码 &gt;在本文中，我们提出了一种基于内容的位置编码机制，该机制具有尺度不变性，更适合于图像生成任务</li></ul><h1 id="method">3.Method</h1><p>为了利用transformers的功能捕获图像特征的长距离依赖性以进行样式转换</p><p>我们将该问题描述为一个连续的补丁生成任务</p><p>给定一个内容图像image (H,W,3) 并显示一个样式图像style (H,W,3)</p><p>我们将两幅图像分割成块patch（类似于NLP任务中的标记）</p><p>使用线性投影层将输入块投影到型如L×dim中嵌入 <spanclass="math inline">\(\varepsilon\)</span> 的序列特征中</p><p><span class="math display">\[L = \frac{H\times W}{m\times m}\]</span></p><blockquote><p>L是特征序列的长度</p><p>m=8是patches的size</p><p>dim是特征序列的维度</p></blockquote><h2 id="content-aware-positional-encodingcape">3.1Content-AwarePositional Encoding（CAPE）</h2><p>当使用transformer-based的模型时，位置编码（PE）应包含在输入序列中，以获取结构信息</p><p>第i个patch和第j个patch的注意力得分计算如下：</p><p><img src="公式1.png" /> &gt; Wq 用于查询的参数矩阵 &gt;Wk用于密钥计算的参数矩阵 &gt; Pi 第i个一维的PE</p><blockquote><p>在二维情况下两个像素点(xi,yi) (xj,yj)之间的位置相对关系:</p></blockquote><p><img src="公式2.png" /></p><ul><li><span class="math inline">\(w_{k} =\frac{1}{1000^{(\frac{2k}{128})}}\)</span></li><li>d = 512</li></ul><p><strong>两个patch之间的位置相对关系仅取决于它们的空间距离</strong></p><p>因此，我们提出两个问题:</p><p><strong>第一</strong></p><p>对于图像生成任务，在计算PE时是否应该考虑图像语义？</p><p>传统的PE是为按逻辑排列的句子设计的，但图像补丁是根据内容组织的。</p><p>我们将两个patch之间的距离表示为d( · , · )</p><p><img src="fig3.png" /></p><p>在图3(a)的右侧</p><p><strong>d((x0,y3),(x1,y3))</strong>(红色和绿色补丁) 和<strong>d((x0,y3),(x3,y3))</strong>(红色和青色补丁)之间的差异应该很小</p><blockquote><p>因为我们预计类似的内容patch会有类似的样式化结果</p></blockquote><p><strong>第二</strong></p><p>当输入图像的大小呈指数增长时传统的正弦位置编码是否仍然适用于视觉任务？</p><p>如图3(a)所示</p><p>调整图像大小时相同位置的面片（用蓝色小矩形表示）之间的相对距离可能会发生显著变化</p><p>这可能不适用于视觉任务中的多尺度方法</p><p>为此，我们提出了<strong>内容感知位置编码（CAPE）</strong></p><blockquote><p>它是尺度不变的，更适合风格迁移任务</p></blockquote><p>与仅考虑补丁相对距离的正弦 PE 不同，CAPE 以图像内容的语义为条件</p><p>我们假设使用 n × n 位置编码足以表示图像的语义</p><p>对于图像 <span class="math inline">\(I \in \mathbb{R}^{H \times W\times 3}\)</span> , 我们将固定的 n × n 位置编码重新缩放为<spanclass="math inline">\(\frac{H}{m} \times \frac{H}{m}\)</span> ，如图3(b) 所示</p><p>这样，<strong>各种图像尺度就不会影响两个补丁之间的空间关系</strong></p><p>补丁 (x, y) 的 CAPE 即<strong>PCA(x, y)</strong>被表述为</p><p><img src="公式3.png" /></p><ul><li><span class="math inline">\(AvgPool_{n\times n}\)</span>是平均池化函数</li><li><span class="math inline">\(\mathcal{F}_{pos}\)</span> 是 1 × 1卷积运算，用作可学习的位置编码函数</li><li><span class="math inline">\(\mathcal{P}_{\mathcal{L}}\)</span>是遵循序列<spanclass="math inline">\(\varepsilon\)</span>的可学习PE</li><li>在我们的实验中n 设置为 18</li><li>$a_{kl} $是插值权重，s 是相邻块的数量</li><li>最后，我们将 <span class="math inline">\(P_{CA_{i}}\)</span> 添加到<span class="math inline">\(\varepsilon_{i}\)</span>，作为第 i个补丁在像素位置 (x, y) 的最终特征嵌入</li></ul><h2 id="style-transfer-transformer">3.2 Style Transfer Transformer</h2><h4 id="transformer-编码器">3.2.1 Transformer 编码器</h4><p>我们通过使用基于 Transformer 的结构来学习<strong>顺序视觉表示</strong> 来<strong>捕获图像块的长期依赖关系</strong></p><p>与其他视觉任务不同，tjr风格迁移任务的输入来自两个不同的领域，分别对应于自然图像和艺术绘画</p><p>因此，StyTr2有两个转换器编码器来<strong>编码特定领域的特征</strong>，用于在下一阶段将序列从一个域转换到另一个域</p><p>给定输入内容序列 <span class="math inline">\(Z_c = \{\varepsilon_{ci} + \mathcal{P_{CA}}_i\}\)</span> 的嵌入</p><p>我们首先将其输入到转换器编码器中</p><p>编码器的每一层都由一个多头自注意力模块（MSA）和一个前馈网络（FFN）组成</p><p>输入序列被编码为查询（Q）、键（K）和值（V）： <spanclass="math display">\[Q =Z_cW_q , K=Z_cW_k , V=Z_cW_v\]</span></p><ul><li><span class="math inline">\(W_q , W_k , W_v \in \mathbb{R}^{C \timesd_{head}}\)</span></li></ul><p>multi-head Attention的计算方式</p><p><img src="4.png" /></p><ul><li><span class="math inline">\(W_0 \in \mathbb{R}^{C \timesC}\)</span>是可学习的参数</li><li>N 是注意力头的数量，并且 <span class="math inline">\(d_{head} =\frac{C}{N}\)</span></li></ul><p>应用残差连接来获得编码的内容序列 Yc</p><p><img src="5.png" /></p><ul><li>FFN是激活函数为relu的MLP</li><li>LN被应用到每一个块的末尾</li></ul><p>类似地，输入样式序列 Zs = {Es1, Es2, ..., EsL}的嵌入按照相同的计算过程编码为序列 Ys</p><p>只是不考虑位置编码，因为我们不需要维护 最终输出中的输入样式</p><h4 id="transformer-解码器">3.2.2 Transformer 解码器</h4><p>我们的转换器解码器用于根据编码样式序列 Ys 以回归方式翻译编码内容序列Yc</p><p>与 NLP任务中的自回归过程不同，我们一次将所有顺序补丁作为输入来预测输出</p><p>如图 3(a) 所示，每个 Transformer 解码器层包含两个 MSA 层和一个FFN</p><p>我们的 Transformer 解码器的输入包括编码后的内容序列</p><p>即 <span class="math inline">\(\bar{Y_c}\)</span> = {Yc1 + PCA1, Yc2+ PCA2, ..., YcL + PCAl} 以及样式序列 Ys = {Ys1, Ys2, ..., YSL}</p><blockquote><p>我们使用<strong>内容序列生成查询 Q，并使用样式序列生成键 K 和值V</strong></p></blockquote><p><span class="math display">\[Q =\bar{Y_c}W_q , K=Y_sW_k , V=Y_sW_v\]</span></p><p>然后，transformer解码器的输出序列X可以计算为</p><p><img src="6.png" /></p><h4 id="cnn解码器">3.2.3 CNN解码器</h4><p>Transformer 的输出序列 X 的形状为 【HW/64 , C】</p><p>我们没有直接对输出序列进行上采样来构造最终结果</p><p>而是使用三层 CNN 解码器来细化 Transformer 解码器的输出</p><p>对于每一层，我们通过采用包括 3 × 3 Conv + ReLU + 2 × Upsample在内的一系列操作来扩大规模</p><p>最后，我们可以得到分辨率为 H × W × 3 的最终结果</p><h2 id="network-optimization">3.3 Network Optimization</h2><p>生成的结果应保持原始内容结构和参考样式模式</p><p>因此，我们构造了两个不同的感知损失项来衡量</p><ul><li><p>输出图像 Io 和输入内容图像 Ic之间的<strong>内容差异</strong></p></li><li><p>Io 和输入风格参考 Is 之间的<strong>风格差异</strong></p></li></ul><p>我们使用由预训练的 VGG模型提取的特征图来构建之后的内容损失和样式损失</p><p>内容感知损失 Lc 定义为</p><p><img src="7.png" /></p><ul><li>其中<span class="math inline">\(\phi_i()\)</span> 表示从预训练 VGG19中的第 i 层提取的特征，<span class="math inline">\(N_l\)</span>是层数。</li></ul><p>风格感知损失 Ls 定义为</p><p><img src="8.png" /></p><ul><li>其中 μ(·) 和 σ(·) 分别表示提取特征的均值和方差。</li></ul><p>我们还采用<strong>身份损失</strong>来学习更丰富、更准确的内容和风格表示</p><p>具体来说，我们将两个相同的内容（风格）图像放入 StyTr2，生成的输出Icc(Iss) 应该与输入 Ic(Is) 相同</p><p>因此，我们计算两个身份损失项来衡量 Ic(Is) 和 Icc(Iss)之间的差异：</p><p><img src="9.png" /></p><p>通过最小化以下函数来优化整个网络：</p><p><img src="10.png" /></p><p>我们将 λc、λs、λid1 和 λid2 设置为 10、7、50 和1，以减轻幅度差异的影响</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;风格转换的目标是在保持原有内容的同时，在风格参照的指导下呈现出具有艺术特征的图像&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于卷积神经网络（CNN）的局部性，很难提取和维护输入图像的全</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="风格迁移" scheme="http://www.larryai.com/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"/>
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Transformer" scheme="http://www.larryai.com/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>Pycharm快捷键</title>
    <link href="http://www.larryai.com/2022/05/06/Pycharm%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    <id>http://www.larryai.com/2022/05/06/Pycharm%E5%BF%AB%E6%8D%B7%E9%94%AE/</id>
    <published>2022-05-06T10:54:14.000Z</published>
    <updated>2022-05-06T11:32:16.665Z</updated>
    
    <content type="html"><![CDATA[<h1 id="pycharm-for-mac">Pycharm for Mac</h1><h4 id="l-使代码遵守pep8规范自动整齐代码">⌘ + ⌥ + L使代码遵守pep8规范（自动整齐代码）</h4><h4 id="b-查看申明-查看源代码">⌘ + B 查看申明 / 查看源代码</h4><h4 id="w-关闭当前文件标签">⌘ + W 关闭当前文件标签</h4><h4 id="f-查找">⌘ + F 查找</h4><h4 id="r-替换">⌘ + R 替换</h4><h4 id="k-更新到vcs">⌘ + K 更新到VCS</h4><h4 id="d-复制当前一整行">⌘ + D 复制当前一整行</h4><h4 id="x-剪贴当前一整行">⌘ + X 剪贴当前一整行</h4><h4 id="v-粘贴缓存历史粘贴板全部内容">⌘ + ⇧ + V粘贴缓存（历史粘贴板全部内容）</h4><h4 id="o-查找类名">⌘ + O 查找类名</h4><h4 id="a-查找动作">⌘ + ⇧ + A 查找动作</h4><h4 id="p-参数提示">⌘ + P 参数提示</h4><h4 id="折叠代码">⌘ + - 折叠代码</h4><h4 id="展开代码">⌘ + = 展开代码</h4><h4 id="tab-切换文件窗口">⌃ + Tab 切换文件窗口</h4><h4 id="r-运行">⌃ + R 运行</h4><h4 id="r-换文件运行">⌃ + ⌥ + R 换文件运行</h4><h4 id="d-启动调试">⌃ + D 启动调试</h4><h4 id="h-调用层次结构">⌃ + ⌥ + H 调用层次结构</h4><h4 id="f6-重命名">⇧ + F6 重命名</h4><h4 id="回车-下一行">⇧ + 回车 下一行</h4><h4 id="选择代码开始处-选择代码结束处">⌘ + ⇧ + ⌥ + [ 选择代码开始处]选择代码结束处</h4>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;pycharm-for-mac&quot;&gt;Pycharm for Mac&lt;/h1&gt;
&lt;h4 id=&quot;l-使代码遵守pep8规范自动整齐代码&quot;&gt;⌘ + ⌥ + L
使代码遵守pep8规范（自动整齐代码）&lt;/h4&gt;
&lt;h4 id=&quot;b-查看申明-查看源代码&quot;&gt;⌘ + B 查看</summary>
      
    
    
    
    <category term="高效工具" scheme="http://www.larryai.com/categories/%E9%AB%98%E6%95%88%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="快捷键" scheme="http://www.larryai.com/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    
    <category term="Pycharm" scheme="http://www.larryai.com/tags/Pycharm/"/>
    
  </entry>
  
  <entry>
    <title>ViT代码复现</title>
    <link href="http://www.larryai.com/2022/05/06/ViT/"/>
    <id>http://www.larryai.com/2022/05/06/ViT/</id>
    <published>2022-05-06T07:58:39.000Z</published>
    <updated>2022-05-06T12:22:57.358Z</updated>
    
    <content type="html"><![CDATA[<h2 id="patch-embedding模块">Patch-Embedding模块</h2><h3 id="section"><img src="2.png" /></h3><h3 id="转换流程">转换流程</h3><p>在<strong>Patch Embedding</strong>中</p><p>例如输入图片大小为256x256，将图片分为多个patch，每个patch大小为16x16</p><p>则每张图像会生成256x256/16x16=256个patches</p><ul><li>即输入序列长度L为patch_num = 256</li><li>每个patch维度dim = patchSize x patchSize x chanels=16x16x3 =768</li></ul><blockquote><p>输入的图像原始格式 [B , C , H ,W]</p><p>经过Patch-Embeding之后格式变为 [B , L , dim]</p><p>用上面的例子来讲便是[B , 3 , 256 ,256] -&gt; [B , 256 , 768]</p></blockquote><p><strong>线性投射层</strong>的维度为768xN(N=768)，因此输入通过线性投射层之后的维度依然为256x768</p><p>即一共有256个token，每个token的维度是768</p><p>代码实现如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">patch_embedding = nn.Sequential(</span><br><span class="line">  </span><br><span class="line">            Rearrange(<span class="string">&#x27;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&#x27;</span>, p1 = patch_height, p2 = patch_width),</span><br><span class="line">  </span><br><span class="line">            nn.Linear(patch_dim, dim), <span class="comment">#线性投影层</span></span><br><span class="line">  </span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>最后还需要加上一个特殊字符cls，因此最终的维度是<strong>256x768</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = atch_embedding(img) <span class="comment">#对输入图像进行patch-embedding</span></span><br><span class="line">b, n, _ = x.shape <span class="comment">#获取Batch以及token数量</span></span><br><span class="line">cls_token = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="number">1</span>, dim)) <span class="comment">#特殊字符cls</span></span><br><span class="line">cls_tokens = repeat(cls_token, <span class="string">&#x27;1 n d -&gt; b n d&#x27;</span>, b = b) <span class="comment">#将cls展到相等Batch</span></span><br><span class="line">x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>) <span class="comment">#进行拼接 token数量+1</span></span><br></pre></td></tr></table></figure><h2 id="positional-encoding模块">Positional encoding模块</h2><p><strong>位置编码</strong>可以理解为一个Nxdim的矩阵</p><ul><li>N就是token的数量</li><li>dim就是一个token的维度</li></ul><p>然后将位置编码进行与patch-embedding后的数据进行相加</p><blockquote><p>⚠️注意，这里是sum而非concat</p></blockquote><p>代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pos_embedding = nn.Parameter(torch.randn(<span class="number">1</span>, num_patches + <span class="number">1</span>, dim))</span><br><span class="line">x += pos_embedding[:, :(n + <span class="number">1</span>)] <span class="comment">#n+1 是patch-embedding后加上cls之后总共的tokens</span></span><br></pre></td></tr></table></figure><h2 id="layernorm模块">LayerNorm模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LayerNorm</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PreNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, fn</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        <span class="keyword">return</span> self.fn(self.norm(x), **kwargs)</span><br></pre></td></tr></table></figure><h2 id="attention模块">Attention模块</h2><p><img src="1.png" /></p><p>经过patch embedding 、pos_embedding 、LayerNorm之后</p><p>我们的数据要被分为VKQ那么会产生3个分支</p><p>研究发现将查询、键和值分别线性投影到 dk、dk 和 dv维度上的不同学习线性投影是有益的（投影到低维度）</p><blockquote><p>相当于给h次机会 希望能够学到不一样的投影的方式</p><p>使得在投影进去的度量空间里面 能够去匹配不同模式的相似函数</p><p>类似卷积神经网络中有多个输出通道的感觉</p></blockquote><p>代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, heads=<span class="number">8</span>, dk=<span class="number">64</span>, dropout=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        inner_dim = dk * heads</span><br><span class="line">        project_out = <span class="keyword">not</span> (heads == <span class="number">1</span> <span class="keyword">and</span> dk == dim)</span><br><span class="line"></span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.scale = dk ** -<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        self.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">        self.to_qkv = nn.Linear(dim, inner_dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># [B , L ,dim] -&gt; [B , L , dk * heads * 3]</span></span><br><span class="line">        <span class="comment"># dk 主要是为了将dim变成dk 投影到低维度</span></span><br><span class="line">        <span class="comment"># heads  产生多个qkv 有多少头 产生多少个qkv</span></span><br><span class="line">        <span class="comment"># 3 数字3是输入复制成3分 给kqv</span></span><br><span class="line"></span><br><span class="line">        self.to_out = nn.Sequential(</span><br><span class="line">            nn.Linear(inner_dim, dim),  <span class="comment"># [B,L,dk*heads] - &gt; [B,L,dim]回到跟输入一样对格式</span></span><br><span class="line">            nn.Dropout(dropout)</span><br><span class="line">        ) <span class="keyword">if</span> project_out <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x = [B , L , dim]</span></span><br><span class="line"></span><br><span class="line">        qkv = self.to_qkv(x).chunk(<span class="number">3</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># [B , L , dk*heads ]  [B , L , dk*heads ]  [B , L , dk*heads ]</span></span><br><span class="line"></span><br><span class="line">        q, k, v = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: rearrange(t, <span class="string">&#x27;b n (h d) -&gt; b h n d&#x27;</span>, h=self.heads), qkv)</span><br><span class="line">        <span class="comment"># [B , L ,dk*heads] - &gt; [B , heads , L , dk]</span></span><br><span class="line"></span><br><span class="line">        dots = torch.matmul(q, k.transpose(-<span class="number">1</span>, -<span class="number">2</span>)) * self.scale  <span class="comment"># 对最后两个维度进行转置 实现QK^T/sqrt(dk)</span></span><br><span class="line">        attn = self.softmax(dots)  <span class="comment"># softmax[QK^T/sqrt(dk)]</span></span><br><span class="line">        attn = self.dropout(attn)</span><br><span class="line"></span><br><span class="line">        out = torch.matmul(attn, v)  <span class="comment"># softmax[QK^T/sqrt(dk)]V</span></span><br><span class="line"></span><br><span class="line">        out = rearrange(out, <span class="string">&#x27;b h n d -&gt; b n (h d)&#x27;</span>)</span><br><span class="line">        <span class="comment"># [B , heads , L , dk] -&gt; [B , L , dk * heads]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.to_out(out)</span><br></pre></td></tr></table></figure><h2 id="算法结构代码汇总">算法结构代码汇总</h2><p><ahref="https://github.com/lucidrains/vit-pytorch/blob/b3e90a265284ba4df00e19fe7a1fd97ba3e3c113/vit_pytorch/vit.py#L47">详细链接访问Github获取</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange, repeat</span><br><span class="line"><span class="keyword">from</span> einops.layers.torch <span class="keyword">import</span> Rearrange</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># tools</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pair</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="keyword">return</span> t <span class="keyword">if</span> <span class="built_in">isinstance</span>(t, <span class="built_in">tuple</span>) <span class="keyword">else</span> (t, t)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># LayerNorm</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PreNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, fn</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        <span class="keyword">return</span> self.fn(self.norm(x), **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># MLP</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, hidden_dim, dropout=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(dim, hidden_dim),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">            nn.Linear(hidden_dim, dim),</span><br><span class="line">            nn.Dropout(dropout)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, heads=<span class="number">8</span>, dk=<span class="number">64</span>, dropout=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        inner_dim = dk * heads</span><br><span class="line">        project_out = <span class="keyword">not</span> (heads == <span class="number">1</span> <span class="keyword">and</span> dk == dim)</span><br><span class="line"></span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.scale = dk ** -<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        self.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">        self.to_qkv = nn.Linear(dim, inner_dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># [B , L ,dim] -&gt; [B , L , dk * heads * 3]</span></span><br><span class="line">        <span class="comment"># dk 主要是为了将dim变成dk 投影到低维度</span></span><br><span class="line">        <span class="comment"># heads  产生多个qkv 有多少头 产生多少个qkv</span></span><br><span class="line">        <span class="comment"># 3 数字3是输入复制成3分 给kqv</span></span><br><span class="line"></span><br><span class="line">        self.to_out = nn.Sequential(</span><br><span class="line">            nn.Linear(inner_dim, dim),  <span class="comment"># [B,L,dk*heads] - &gt; [B,L,dim]回到跟输入一样对格式</span></span><br><span class="line">            nn.Dropout(dropout)</span><br><span class="line">        ) <span class="keyword">if</span> project_out <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x = [B , L , dim]</span></span><br><span class="line"></span><br><span class="line">        qkv = self.to_qkv(x).chunk(<span class="number">3</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># [B , L , dk*heads ]  [B , L , dk*heads ]  [B , L , dk*heads ]</span></span><br><span class="line"></span><br><span class="line">        q, k, v = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: rearrange(t, <span class="string">&#x27;b n (h d) -&gt; b h n d&#x27;</span>, h=self.heads), qkv)</span><br><span class="line">        <span class="comment"># [B , L ,dk*heads] - &gt; [B , heads , L , dk]</span></span><br><span class="line"></span><br><span class="line">        dots = torch.matmul(q, k.transpose(-<span class="number">1</span>, -<span class="number">2</span>)) * self.scale  <span class="comment"># 对最后两个维度进行转置 实现QK^T/sqrt(dk)</span></span><br><span class="line">        attn = self.softmax(dots)  <span class="comment"># softmax[QK^T/sqrt(dk)]</span></span><br><span class="line">        attn = self.dropout(attn)</span><br><span class="line"></span><br><span class="line">        out = torch.matmul(attn, v)  <span class="comment"># softmax[QK^T/sqrt(dk)]V</span></span><br><span class="line"></span><br><span class="line">        out = rearrange(out, <span class="string">&#x27;b h n d -&gt; b n (h d)&#x27;</span>)</span><br><span class="line">        <span class="comment"># [B , heads , L , dk] -&gt; [B , L , dk * heads]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.to_out(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, depth, heads, dim_head, mlp_dim, dropout=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(nn.ModuleList([</span><br><span class="line">                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),</span><br><span class="line">                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))</span><br><span class="line">            ]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">for</span> attn, ff <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = attn(x) + x</span><br><span class="line">            x = ff(x) + x</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ViT</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool=<span class="string">&#x27;cls&#x27;</span>, channels=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 dim_head=<span class="number">64</span>, dropout=<span class="number">0.</span>, emb_dropout=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        image_height, image_width = pair(image_size)</span><br><span class="line">        patch_height, patch_width = pair(patch_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> image_height % patch_height == <span class="number">0</span> <span class="keyword">and</span> image_width % patch_width == <span class="number">0</span>, <span class="string">&#x27;Image dimensions must be divisible by the patch size.&#x27;</span></span><br><span class="line"></span><br><span class="line">        num_patches = (image_height // patch_height) * (image_width // patch_width)</span><br><span class="line">        patch_dim = channels * patch_height * patch_width</span><br><span class="line">        <span class="keyword">assert</span> pool <span class="keyword">in</span> &#123;<span class="string">&#x27;cls&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>&#125;, <span class="string">&#x27;pool type must be either cls (cls token) or mean (mean pooling)&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.to_patch_embedding = nn.Sequential(</span><br><span class="line">            Rearrange(<span class="string">&#x27;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&#x27;</span>, p1=patch_height, p2=patch_width),</span><br><span class="line">            nn.Linear(patch_dim, dim),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.pos_embedding = nn.Parameter(torch.randn(<span class="number">1</span>, num_patches + <span class="number">1</span>, dim))</span><br><span class="line">        self.cls_token = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="number">1</span>, dim))</span><br><span class="line">        self.dropout = nn.Dropout(emb_dropout)</span><br><span class="line"></span><br><span class="line">        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)</span><br><span class="line"></span><br><span class="line">        self.pool = pool</span><br><span class="line">        self.to_latent = nn.Identity()</span><br><span class="line"></span><br><span class="line">        self.mlp_head = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">            nn.Linear(dim, num_classes)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img</span>):</span><br><span class="line">        x = self.to_patch_embedding(img)</span><br><span class="line">        b, n, _ = x.shape</span><br><span class="line"></span><br><span class="line">        cls_tokens = repeat(self.cls_token, <span class="string">&#x27;1 n d -&gt; b n d&#x27;</span>, b=b)</span><br><span class="line">        x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line">        x += self.pos_embedding[:, :(n + <span class="number">1</span>)]</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line"></span><br><span class="line">        x = self.transformer(x)</span><br><span class="line"></span><br><span class="line">        x = x.mean(dim=<span class="number">1</span>) <span class="keyword">if</span> self.pool == <span class="string">&#x27;mean&#x27;</span> <span class="keyword">else</span> x[:, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        x = self.to_latent(x)</span><br><span class="line">        <span class="keyword">return</span> self.mlp_head(x)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;patch-embedding模块&quot;&gt;Patch-Embedding模块&lt;/h2&gt;
&lt;h3 id=&quot;section&quot;&gt;&lt;img src=&quot;2.png&quot; /&gt;&lt;/h3&gt;
&lt;h3 id=&quot;转换流程&quot;&gt;转换流程&lt;/h3&gt;
&lt;p&gt;在&lt;strong&gt;Patch Embedd</summary>
      
    
    
    
    <category term="代码复现" scheme="http://www.larryai.com/categories/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/"/>
    
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>python笔记</title>
    <link href="http://www.larryai.com/2022/05/06/python%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.larryai.com/2022/05/06/python%E7%AC%94%E8%AE%B0/</id>
    <published>2022-05-06T07:54:55.000Z</published>
    <updated>2022-05-21T11:29:32.941Z</updated>
    
    <content type="html"><![CDATA[<h1 id="rearrange函数">Rearrange函数</h1><h2 id="作用">作用</h2><p><img src="1.png" /></p><p>在<strong>Patch Embedding</strong>中使用这个函数进行处理</p><p>例如输入图片大小为224x224，将图片分为固定大小的patch，patch大小为16x16</p><p>则每张图像会生成224x224/16x16=196个patches</p><ul><li>即输入序列长度为patch_num = 196</li><li>每个patch维度 = patchSize x patchSize x chanels=16x16x3 = 768</li></ul><blockquote><p>相当于将[B , C , H , W ]的图片变成 [ B , PatchNum , dimension ]</p><p>其中 PathNum = <span class="math inline">\(\frac{H \times W}{p \timesp}\)</span> , dimension = <span class="math inline">\(p \times p \timesC\)</span></p></blockquote><h2 id="具体实现">具体实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> einops.layers.torch <span class="keyword">import</span> Rearrange</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">patch_size = <span class="number">16</span></span><br><span class="line">img = torch.ones(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"></span><br><span class="line">fun = Rearrange(<span class="string">&#x27;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&#x27;</span>, p1=patch_size, p2=patch_size)</span><br><span class="line"></span><br><span class="line">out = fun(img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(img.shape)  <span class="comment"># torch.Size([1, 3, 224, 224])</span></span><br><span class="line"><span class="built_in">print</span>(out.shape)  <span class="comment"># torch.Size([1, 196, 768])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="chunks函数">chunks函数</h1><p>该函数在Transformer的Attention模块将输入投影后给QKV时用到</p><h2 id="作用-1">作用</h2><blockquote><p>若对最后一个维度进行chunks操作</p><p>[B , C , N , D*3] -&gt;[B ,C , N ,D] , [B ,C , N ,D] ,[B ,C , N,D]</p></blockquote><h2 id="具体实现-1">具体实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.ones(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span> * <span class="number">3</span>)</span><br><span class="line">output = <span class="built_in">input</span>.chunk(<span class="number">3</span>, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)  <span class="comment"># torch.Size([1, 3, 672])</span></span><br><span class="line"><span class="built_in">print</span>(output[<span class="number">0</span>].shape)  <span class="comment"># torch.Size([1, 3, 224])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="adaptiveavgpool2d函数">AdaptiveAvgPool2d()函数</h1><h2 id="作用-2">作用</h2><blockquote><p>AdaptivePooling，自适应池化层</p><p>函数通过输入原始尺寸和目标尺寸，自适应地计算核的大小和每次移动的步长。</p><p>如告诉函数原来的矩阵是32x32的尺寸，我要得到18x18的尺寸，函数就会自己计算出核多大、该怎么运动。</p></blockquote><h2 id="具体实现-2">具体实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.ones(<span class="number">1</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">256</span>)</span><br><span class="line">autoPool = nn.AdaptiveAvgPool2d(output_size=(<span class="number">18</span>, <span class="number">18</span>))</span><br><span class="line">output = autoPool(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;input.shape&#x27;</span>, <span class="built_in">input</span>.shape) <span class="comment"># [1, 3, 256, 256]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;output.shape&#x27;</span>, output.shape) <span class="comment"># [1, 3, 18, 18]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;rearrange函数&quot;&gt;Rearrange函数&lt;/h1&gt;
&lt;h2 id=&quot;作用&quot;&gt;作用&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;Patch Embedding&lt;/strong&gt;中使用这个函数进行处理&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="函数笔记" scheme="http://www.larryai.com/categories/%E5%87%BD%E6%95%B0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Python" scheme="http://www.larryai.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>MASA-SR</title>
    <link href="http://www.larryai.com/2022/05/04/MASA-SR/"/>
    <id>http://www.larryai.com/2022/05/04/MASA-SR/</id>
    <published>2022-05-04T07:58:52.000Z</published>
    <updated>2022-05-16T04:16:20.361Z</updated>
    
    <content type="html"><![CDATA[<p><imgsrc="https://pic1.zhimg.com/v2-3486f59df8faa40673ddcbe4f5212844_1440w.jpg?source=172ae18b" /></p><h2 id="主要组成">主要组成</h2><ul><li><p>编码器 Encoder</p></li><li><p>匹配与提取模块（MEM） Math &amp; Extraction Modules</p></li><li><p>空间自适应模块（SAM） Spatial Adaptation Modules</p><blockquote><p>将Ref特征的分布映射到LR特征的分布</p></blockquote></li><li><p>双残差聚合模块（DRAM）Dual Residual Aggregation Modules</p><blockquote><p>进行有效的特征融合</p></blockquote></li></ul><h3 id="名词解释">名词解释</h3><blockquote><ul><li>LR 低分辨率图像</li><li>Ref↓ 表示 x4双三次下采样参考图</li><li>Ref 参考图</li></ul></blockquote><h2 id="编码器">编码器</h2><ul><li><p>与之前使用预先训练过的VGG作为自然提取器的方法不同</p></li><li><p>这里的编码器与网络的其他部分一起从头开始训练的</p></li><li><p>编码器含有三个构造块</p><ul><li>第二个和第三个 利用stride=2的方法将featue map大小折半</li></ul></li><li><p>将Ref参考图传入编码器分别经过三个构造块得到三个不同比例的特征</p><ul><li>生成<span class="math inline">\(F_{Ref}^s\)</span> 其中s =1,2,4</li></ul></li><li><p>LR图像和Ref↓ 图像只经管编码器的第一个构造块</p><ul><li>生成<span class="math inline">\(F_{LR}\)</span> 和 <spanclass="math inline">\(F_{Ref↓ }\)</span></li></ul></li></ul><h2 id="matching-extraction-module-mem">Matching &amp; Extraction Module(MEM)</h2><h3 id="概述">概述</h3><p>​众所周知，在自然图像的局部区域中，相邻像素可能来自公共对象共享相似的颜色统计数据。以往对自然图像先验的研究也表明，一幅图像中的相邻斑块很可能会发现它们之间的对应关系在空间上是一致的。</p><p>​这促使我们提出了一种从粗到精的匹配方案，即粗块匹配和精块匹配。请注意，在我们的方法中，block和patch是两个不同的概念，block的大小大于patch（在我们的实验中patch为3×3的大小）。</p><p>​ 如图3所示，我们首先只在featurespace中找到block的对应关系。具体来说，我们将LR特征(<spanclass="math inline">\(F_{LR}\)</span>)展开为不重叠的block块。每个LRblock将找到其最相关的Ref↓ block。</p><p>​ 与以前的方法相比，通过这样做，匹配的计算成本显著降低。</p><p>​ 为了达到足够的精度，我们进一步对每一个&lt;LR block，Ref↓block&gt;对进行密集patch匹配</p><p>​ 在最后一个阶段，我们根据获得的对应信息提取有用的Ref feature</p><p><imgsrc="https://pic3.zhimg.com/80/v2-e551112dcfc05e03aecc23d0b457189e_1440w.jpg" /></p><h3 id="stage-1-coarse-matching粗匹配">Stage 1: Coarsematching（粗匹配）</h3><p>将<span class="math inline">\(F_{LR}\)</span>展开成K个不重复的blocks<span class="math display">\[\left\{  B_{LR}^0,B_{LR}^1,B_{LR}^2 ,...B_{LR}^{K-1} \right\}\]</span></p><blockquote><p>一个Block中有很多patch 对每个<spanclass="math inline">\(B_{LR}^k\)</span>块找到与它<strong>最相关</strong>的<spanclass="math inline">\(F_{Ref↓}\)</span> block 记作<spanclass="math inline">\(B_{Ref↓}^k\)</span></p></blockquote><p>首先将<span class="math inline">\(B_{LR}^k\)</span>的<strong>centerpatch</strong>与<spanclass="math inline">\(F_{Ref↓}\)</span>中的每一个patch进行计算<strong>余弦相似度</strong>(cosinesimilarity) <span class="math display">\[r_{c,j}^k = \left \langle \frac{p_c^k}{\left \| p_c^k \right \|} ,\frac{q_j}{\left \| q_j \right \|} \right \rangle\]</span></p><ul><li><span class="math inline">\(p_c^k\)</span>是<spanclass="math inline">\(B_{LR}^k\)</span>块的center patch</li><li><span class="math inline">\(q_j\)</span>是<spanclass="math inline">\(F_{Ref↓}\)</span>块的第j个patch</li><li><spanclass="math inline">\(r_{c,j}^k\)</span>表示相似性大小（similarityscores）</li></ul><p>通过<strong>相似性大小</strong>(similarity score)我们可以找到<spanclass="math inline">\(F_{Ref↓}\)</span> 中与<spanclass="math inline">\(p_c^k\)</span>最相似的patch</p><p>然后crop一个围绕着这个最相似patchb并且大小为<spanclass="math inline">\([dx,dy]\)</span>的block 记作<spanclass="math inline">\(B_{Ref↓}^k\)</span></p><blockquote><p>根据局部相干特性,每个<spanclass="math inline">\(B_{LR}^k\)</span>块的center patch都能找到与在<spanclass="math inline">\(F_{Ref↓}\)</span>其中最相似的patch后找到对应的<spanclass="math inline">\(B_{Ref↓}^k\)</span></p><p>另一方面，我们可以在<spanclass="math inline">\(F_{Ref}^s\)</span>中剪切相应的大小为<spanclass="math inline">\([s*dx,s*dy]\)</span>的block，记作<spanclass="math inline">\(B_{Ref}^{s,k}\)</span></p><p>这将用于<strong>特征提取阶段</strong></p></blockquote><p>注意问题⚠️</p><ul><li>如果<spanclass="math inline">\(B_{LR}^k\)</span>的大小远大于其centerpatch的大小，则center patch可能无法代表<spanclass="math inline">\(B_{LR}^k\)</span>的全部内容</li><li>这可能会误导我们找到不相关的<spanclass="math inline">\(B_{Ref↓}^k\)</span></li></ul><p>解决方法：</p><ul><li>使用具有<strong>不同膨胀率</strong>的中心块来计算相似度</li><li>细节如图3的第1阶段所示，<ul><li>其中蓝色虚线表示<em>dilation</em>=1的情况</li><li>橙色虚线表示<em>dilation</em>=2的情况</li><li>然后将相似性得分计算为<strong>不同扩张的结果之和</strong></li></ul></li></ul><blockquote><p>这个阶段我们得到了（<spanclass="math inline">\(B_{LR}^k\)</span>，<spanclass="math inline">\(B_{Ref↓}^k\)</span>，<spanclass="math inline">\(B_{Ref}^{s,k}\)</span>）</p><p>在下面的精细匹配阶段阶段我们将限制<spanclass="math inline">\(B_{LR}^k\)</span> to <spanclass="math inline">\(B_{Ref↓}^k\)</span> 的搜索空间</p></blockquote><h3 id="stage-2-fine-matching精细匹配阶段阶段">Stage 2: Finematching（精细匹配阶段阶段）</h3><blockquote><p>对<span class="math inline">\(B_{LR}^k\)</span> to <spanclass="math inline">\(B_{Ref↓}^k\)</span>进行dense pathmatching（密集补丁匹配）</p><p>得到index maps集合 <span class="math inline">\(\left\{ D^0 , D^1 ,... D^{K-1} \right\}\)</span></p><p>similarity maps 集合<span class="math inline">\(\left\{ R^0 , R^1 ,... R^{K-1} \right\}\)</span></p></blockquote><p>拿第k对(<span class="math inline">\(B_{LR}^k\)</span> , <spanclass="math inline">\(B_{Ref↓}^k\)</span>)为例 我们计算每个patch in<span class="math inline">\(B_{LR}^k\)</span> 与 每个patch in <spanclass="math inline">\(B_{Ref↓}^k\)</span>之间的相似性分数 <spanclass="math display">\[r_{i,j}^k = \left \langle \frac{p_i^k}{\left \| p_i^k \right \|} ,\frac{q_j^k}{\left \| q_j^k \right \|} \right \rangle\]</span></p><ul><li><span class="math inline">\(p_i^k\)</span>是<spanclass="math inline">\(B_{LR}^k\)</span>的第i个patch</li><li><span class="math inline">\(q_j^k\)</span>是<spanclass="math inline">\(B_{Ref↓}^k\)</span>的第j个patch</li><li>k表示第k对(<span class="math inline">\(B_{LR}^k\)</span> , <spanclass="math inline">\(B_{Ref↓}^k\)</span>)</li><li>$r_{i,j}^k $表示它们的相似性大小</li></ul><blockquote><p><span class="math inline">\(D^k\)</span>的第i个元素的值j表示的是<spanclass="math inline">\(B_{LR}^k\)</span>的第i个patch与<spanclass="math inline">\(B_{Ref↓}^k\)</span>中第j个ptach最相似</p></blockquote><p><span class="math display">\[D_i^k = \mathop{\arg \max}_j \ r_{i,j}^k\]</span></p><blockquote><p><span class="math inline">\(R^k\)</span>的第i个元素表示的是<spanclass="math inline">\(B_{LR}^k\)</span>的第i个patch相对应的highestsimilarity score(最高相似分数)</p></blockquote><p><span class="math display">\[R_i^k = \mathop{\max}_j \ r_{i,j}^k\]</span></p><h3 id="stage-3-feature-extraction特征提取">Stage 3: Featureextraction(特征提取)</h3><p>根据index map <span class="math inline">\(D^k\)</span> 从<spanclass="math inline">\(B_{Ref}^{s,k}\)</span>中提取patches，生成新的featuremap <span class="math inline">\(B_M^{s,k}\)</span></p><p>更精准的说</p><p><span class="math inline">\(D_i^k\)</span>表示<spanclass="math inline">\(B_{Ref↓}^k\)</span>中与<spanclass="math inline">\(B_{LR}^k\)</span>的第i个patch最相似的patch</p><p>我们将<span class="math inline">\(D_i^k\)</span>个<spanclass="math inline">\(B_{Ref}^{s,k}\)</span>中的patch作为<spanclass="math inline">\(B_M^{s,k}\)</span>的第i个patch</p><p>此外，由于相似性<strong>分数较高的Ref特征更有用</strong></p><p>我们将<span class="math inline">\(B_M^{s,k}\)</span>与相应的<spanclass="math inline">\(R^k\)</span>相乘获得<strong>加权特征块</strong><span class="math display">\[B_M^{s,k} := B_M^{s,k}\odot(R^k)\uparrow\]</span></p><ul><li><span class="math inline">\(()\uparrow\)</span>表示双线性插值</li><li><span class="math inline">\(\odot\)</span> 表示element-wise mul</li></ul><p>MEM的最终结果就是将 <span class="math inline">\(\left\{ B_M^{s,0} ,B_M^{s,1} , B_M^{s,2},...B_M^{s,K-1}\right\}\)</span>进行折叠在一起获得，折叠操作是步骤一的逆向操作</p><h3 id="分析">分析</h3><h4 id="以往的配对方法">以往的配对方法</h4><ul><li><p>图像LR的像素 为 m pixels ; 图像<spanclass="math inline">\(Ref\downarrow\)</span>的像素 为 n pixels</p></li><li><p>计算复杂度为O(mn)</p></li></ul><h4 id="mem方法">MEM方法</h4><ul><li>假设<span class="math inline">\(Ref\downarrow\)</span> block 有 n’pixels</li><li>计算复杂度将被降为 O(Kn+mn’)</li><li>K远小于m</li><li>n‘ 远小于n</li><li>通过这种从粗到精的匹配方案，计算量显著降低</li></ul><h2 id="spatial-adaptation-modulesam空间自适应模块">Spatial AdaptationModule（SAM）空间自适应模块</h2><p><imgsrc="https://pic1.zhimg.com/v2-3486f59df8faa40673ddcbe4f5212844_1440w.jpg?source=172ae18b" /></p><p>在许多情况下，LR和Ref图像可能具有相似的内容和纹理，颜色和亮度不一样</p><p>因此，提取的REF特征的分布可能与LR特征的分布不一致。因此，简单地将Ref和LR特性连接到一起，并将它们输入到下面的卷积层中并不是最佳选择。我们建议使用空间自适应模块（SAM）将提取的Ref特征的分布重新映射到LR特征的分布</p><p>首先将LR特征和提取的Ref特征连接(Cat)起来，然后预先送入卷积层，以产生两个参数β和γ，这两个参数的大小与LR特征相同。</p><p>我们用特征的平均值和标准偏差更新β和γ <span class="math display">\[\beta \leftarrow \beta + \mu_{LR}\\\gamma \leftarrow \gamma +\sigma_{LR}\]</span></p><blockquote><p><span class="math inline">\(\mu_{LR}\)</span> <spanclass="math inline">\(\sigma_{LR}\)</span>的产生方式跟<spanclass="math inline">\(\mu_{Ref}\)</span> <spanclass="math inline">\(\sigma_{Ref}\)</span> 一样</p><p><span class="math inline">\(\mu_{LR}\)</span> <spanclass="math inline">\(\sigma_{LR}\)</span> 的大小是 C x 1 x 1</p><p>C表示一共有C个通道</p></blockquote><p>然后将实例规范化(Instance Norm)应用于Ref特征，如下所示： <spanclass="math display">\[F_{Ref}^c \leftarrow \frac{F_{Ref}^c - \mu_{Ref}^c}{\sigma_{Ref}^c}\]</span> <span class="math inline">\(\mu_{Ref}^c\)</span> <spanclass="math inline">\(\sigma_{Ref}^c\)</span>分别表示Ref特征图在通道c的均值和方差 <span class="math display">\[\mu_{Ref}^c = \frac{1}{HW} \sum_{y,x}F_{Ref}^{c,y,x}\]</span></p><p><span class="math display">\[\sigma_{Ref}^c  = \sqrt{\frac{1}{HW}\sum_{y,x}(F_{Ref}^{c,y,x} -\mu_{ref}^c)^2}\]</span></p><p>最后，将γ和β添加到归一化Ref特征中，如下所示： <spanclass="math display">\[F_{Ref} \leftarrow F_{Ref}·\gamma + \beta\]</span> 由于Ref特征和LR特征之间的差异随空间位置而变化</p><p><span class="math inline">\(\mu_{LR}\)</span> <spanclass="math inline">\(\sigma_{LR}\)</span> <spanclass="math inline">\(\mu_{Ref}\)</span> <spanclass="math inline">\(\sigma_{Ref}\)</span> 的大小为 C x 1 x 1</p><p>我们使用可学习卷积来预测两个空间参数β和γ</p><p>不同于只使用分割图(segmentation)去生成两个参数，SAM中的卷积将Ref和LR特征作为输入，以了解它们的差异。此外，在从卷积中获得β和γ后，我们将它们与LR特征的均值和标准偏差相加</p><h2 id="dual-residual-aggregation-module-dram-双残差聚合模块">DualResidual Aggregation Module (DRAM) 双残差聚合模块</h2><p>在空间自适应后，使用我们提出的双剩余聚合模块（DRAM），将传输的Ref特征与LR特征融合</p><p>DRAM由两个分支组成，即 <strong>LR分支</strong> 和<strong>Ref分支</strong></p><p><strong>Ref分支</strong></p><blockquote><p>旨在细化Ref功能的高频细节</p></blockquote><ul><li>首先使用stride=2的卷积对Ref Feature 进行下采样</li><li>将下采样后的Ref Feature 减去 LR Feature 得到Res_Ref 残余特征</li><li>将Res_Ref使用转置卷积（逆卷积）上采样后加上原始的RefFeatu得到新的Ref ‘ 特征图</li></ul><p><span class="math display">\[\begin{cases}    Res_{Ref} = Conv(F_{Ref}) - F_{LR}\\    F&#39;_{Ref}= F_{Ref} + DeConv(Res_{Ref})\end{cases}\]</span></p><p><strong>LR分支</strong></p><blockquote><p>LR功能的高频细节细化</p></blockquote><ul><li>首先使用stride=2的卷积对Ref Feature 进行下采样</li><li>将 <strong>LR Feature</strong> 减去<strong>下采样后的RefFeature</strong> 得到Res_LR 残余特征</li><li>将Res_LR 加上 LR Feature 相加后 进行上采样的懂新的LR’ 特征图</li></ul><p><span class="math display">\[\begin{cases}    Res_{LR} =  F_{LR}-Conv(F_{Ref})\\    F&#39;_{LR}= DeConv(F_{LR}+Res_{LR})\end{cases}\]</span></p><p>最后，将两个分支的输出串联起来，并以步长1通过另一个卷积层。</p><p>通过这种方式，LR和Ref功能中的细节得到了增强和聚合，从而产生了更具代表性的功能。</p><h2 id="loss-functions">Loss Functions</h2><h3 id="reconstruction-loss重建损失">1.Reconstructionloss(重建损失)</h3><p>采用L1损失作为重建损失</p><p><span class="math display">\[\mathcal{L}_{rec} = \left \|  I_{HR} - I_{SR}\right\|_1\]</span></p><h3 id="perceptual-loss知觉损失">2.Perceptual loss(知觉损失)</h3><p>知觉损失的表达为 <span class="math display">\[\mathcal{L}_{per} = \left \|  \phi_i(I_{HR}) - \phi_i(I_{SR}) \right\|_2\]</span></p><blockquote><p><span class="math inline">\(\phi_i\)</span>表示VGG19的第i层这里是用conv5_4</p></blockquote><h3 id="adversarial-loss对抗性损失">3.Adversarial loss(对抗性损失)</h3><p>它可以有效地生成具有自然细节的视觉愉悦图像 <spanclass="math display">\[\mathcal{L}_D =-\mathbb{E}_{I_{HR}}[\log(D(I_{HR},I_{SR}))]-\mathbb{E}_{I_{SR}}[\log(1-D(I_{HR},I_{SR}))],\\\mathcal{L}_G=-\mathbb{E}_{I_{HR}}[\log(1-D(I_{HR},I_{SR}))]-\mathbb{E}_{I_{SR}}[\log(D(I_{SR},I_{HR}))]\]</span></p><h3 id="full-objective">4.Full objective</h3><p><span class="math display">\[\mathcal{L} =\lambda_{rec}\mathcal{L}_{rec}+\lambda_{per}\mathcal{L}_{per}+\lambda_{adv}\mathcal{L_{adv}}\]</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img
src=&quot;https://pic1.zhimg.com/v2-3486f59df8faa40673ddcbe4f5212844_1440w.jpg?source=172ae18b&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;主要组成&quot;&gt;主要组成&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="超分重建" scheme="http://www.larryai.com/tags/%E8%B6%85%E5%88%86%E9%87%8D%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>informative-drawing</title>
    <link href="http://www.larryai.com/2022/05/04/informative-drawing/"/>
    <id>http://www.larryai.com/2022/05/04/informative-drawing/</id>
    <published>2022-05-04T07:56:42.000Z</published>
    <updated>2022-05-04T07:59:24.408Z</updated>
    
    <content type="html"><![CDATA[<h1id="learning-to-generate-line-drawings-that-convey-geometry-and-semantics">Learningto generate line drawings that convey geometry and semantics</h1><h2 id="摘要">摘要</h2><p>本文提出了一种从照片中生成线条图的非配对方法。目前的方法通常依赖高质量的成对数据集来生成线条图。然而，由于图纸主题属于特定do-main，或收集的数据量有限，这些数据集通常具有局限性。尽管近年来在无监督图像到图像的翻译方面取得了很大进展，但最新的方法仍然难以生成令人信服的线条图。我们观察到，线条图是场景信息的编码，并试图传达三维形状和语义。我们将这些观察构建成一组目标，并训练图像翻译，将照片映射成线条图。我们引入了一种几何损失，<strong>它从线条图的图像特征中预测深度信息</strong>，<strong>以及一种语义损失</strong>，<strong>它将线条图的剪辑特征与其相应的照片相匹配</strong>。我们的方法优于最先进的未成对图像翻译和线条绘制生成方法，可以从ar位图照片中创建线条图。</p><h2 id="方法">方法</h2><p>我们的目标是训练一个模型，在给定照片数据集和未配对的线图数据集的情况下，自动生成任意照片的线图。我们将这个问题描述为包含照片的域A和代表特定风格线条图的do-mainB之间的未配对图像转换。大多数以前的方法仅仅考虑在循环图中保持PHO图样的外观。相反，我们的方法通过评估几何和语义的目标进一步指导翻译通过线条图传达的信息。此设置如图2所示。我们在第4节中说明，这些新损失对于创建有意义的图形至关重要。</p><figure><img src="1.png" alt="截屏2022-04-11 22.10.53" /><figcaption aria-hidden="true">截屏2022-04-11 22.10.53</figcaption></figure><blockquote><p>给出一张照片a，我们的模型训练网络GA，通过四个主要损失来合成线图GA（a）。带有鉴别器DB的对抗式损失鼓励生成的线条绘制与训练集的风格相匹配。</p><p>线条、外观和几何图形的LOSS强制要求线条分别传达有效的语义、外观和几何图形</p></blockquote><p>我们对域A和域B分别使用带有生成器网络GA、GB和鉴别器DA、DB的对抗性训练设置。</p><ul><li>几何目标通过预先训练的深度网络来实现，该网络根据<strong>线图预测深度图</strong>，并对深度输出施加监督损失。这种损失促使我们的模型在几何上重要的位置（例如遮挡轮廓）绘制线。</li><li>其次，我们引入了一个<strong>CLIPloss</strong>，将语义添加到生成的线条图中。由于任意的照片往往显示复杂的场景，我们使用<strong>视觉CLIP嵌入</strong>，它可以很好地捕捉语义细节。然后，我们规定线条图的CLIP嵌入与原始照片的CLIP嵌入相似。</li><li>我们还使用弱加权<strong>循环一致性损失</strong>来保留外观信息。</li></ul><h1 id="loss">LOSS</h1><h2 id="对抗性损失">对抗性损失</h2><p>鼓励生成的图像长到各自的域[27]。使用LSGAN设置[61]的每个域的损耗公式如下</p><figure><img src="2.png" alt="截屏2022-04-11 22.14.36" /><figcaption aria-hidden="true">截屏2022-04-11 22.14.36</figcaption></figure><h2 id="几何目标损失the-geometry-objective">几何目标损失The geometryobjective</h2><p>​在训练期间，最大限度地利用自动绘制的线条图提供深度信息。我们观察到，线条图通常是3D形状的有效载体,并在培训期间应用此属性。给定一个线图的实体数据集，模型可以在没有任何明确监督的情况下学习这一序列。然而，目前没有这种几何约束的方法无法在有意义的地方放置线（见第4节）。照片数据集和线条图之间的领域差距也是显而易见的。相反，我们<strong>提出了一个几何约束，用于监督线条图的深度预测</strong></p><p>​为了监督线条图的深度预测，有必要获得用于摄影输入的深度图。不幸的是，大多数数据集通常无法获得地面真相深度信息。然而，<strong>最近的方法在为照片绘制高分辨率深度图方面非常成功</strong>。这一进展使我们能够使用从最先进的深度预测网络F获得的伪地面真深度图；实际上，我们使用[62]中的网络，它基于MiDaS[69]。我们注意到，<strong>照片的伪地面真相图仅在培训时需要，而不是在测试时需要</strong></p><p>​<strong>监督几何预测</strong>的一个简单方法是，在培训期间引入网络<spanclass="math inline">\(G_{geom}\)</span>来根据线图预测深度图。然而，这种方法有几个问题。从合成线图中学习深度的培训可能会鼓励线图生成器以一种不需要的形式灌输深度信息</p><blockquote><p>比如一个不易察觉的信号[15]。我们希望避免意外地将不可见的信息嵌入到我们的线条图中。</p><p>由于领域差距，在线条图上使用预训练深度网络不是一个选项</p></blockquote><p>​相反，我们建议学习从通常在照片和线条图之间<strong>共享的图像特征推断深度</strong>。具体来说，我们在给定ImageNet[20]特征的情况下，预先训练一个网络<spanclass="math inline">\(G_{geom}\)</span>来预测深度。这些特征，尤其是在早期阶段，对迁移学习非常有用[49]。这个场景希望通过首先将<strong>线条图编码</strong>(intoa shared representation withphotographs)为带有照片的共享演示，然后应用一个从照片特征中学习深度的网络，来避免不可见的信号问题。</p><ul><li>将线条图编码与和图片加入共享representation</li><li>应用一个从照片特征中学习深度的网络？</li></ul><p>为了获得图像特征，我们将照片输入预先训练好的<strong>Inceptionv3[76]网络</strong>，并从<strong>混合6b节点</strong>提取特征（见补充）。</p><p>我们将input a在这层提取出来的特征定义为<spanclass="math inline">\(I(a)\)</span></p><p>经过预训练后，<spanclass="math inline">\(G_{geom}\)</span>提供线条画的深度估计图</p><p>在练习中 我们在培训线条绘制生成的同时进行微调 <spanclass="math inline">\(G_{geom}\)</span></p><p>几何损失公式如下。</p><ul><li>给定照片a，我们首先将其输入到最先进的深度网络F[62]中，并获得pseudo-ground truth depth map <spanclass="math inline">\(F(a)\)</span>。</li><li>然后生成线条画<span class="math inline">\(G_A(a)\)</span>并提取它的ImageNet特征<spanclass="math inline">\(I(G_A(a)\)</span>。</li><li>然后将这些特征传递给预先训练的深度网络<spanclass="math inline">\(G_{Geom}\)</span> , 生成深度图预测<spanclass="math inline">\(G_{Geom}(I(G_A(a))\)</span></li><li>然后将该深度预测与伪地面真实深度图F(a)进行比较</li></ul><p>进一步,细节和深度重建见补充说明</p><figure><img src="Lgeom.png" alt="截屏2022-04-11 22.43.35" /><figcaption aria-hidden="true">截屏2022-04-11 22.43.35</figcaption></figure><h2 id="语义损失the-semantics-loss">语义损失The semantics loss</h2><p>​ 通过最小化 <strong>输入照片图的CLIP嵌入</strong>和<strong>生成的线条图</strong>之间的距离来实现。这一目标的目标是将原始照片中的语义信息传达到相应的合成线条图中。</p><p>​在计算机视觉中，<strong>语义通常以标签和分割图的形式学习</strong>。然而，这些<strong>表达仅限于特定领域或对象</strong>。为了对整个场景中的语义信息进行编码，我们使用了(shared visual-text embeddingCLIP)<strong>共享的视觉文本嵌入剪辑</strong>[68]，它在照片和艺术[17,24]中捕获了丰富的语义信息。然后，我们对生成的线条图和原始照片图之间的距离进行惩罚。目标如下。</p><figure><img src="LCLIP.png" alt="截屏2022-04-11 22.44.24" /><figcaption aria-hidden="true">截屏2022-04-11 22.44.24</figcaption></figure><h2id="外观损失the-appearance-loss-循环一致性损失cycle-consistency">外观损失Theappearance loss (循环一致性损失cycle consistency)</h2><p>已被用于通过图像转换对输入外观进行编码[47,89]。贴图每个方向的外观损失如下所示</p><figure><img src="Lcycle.png" alt="截屏2022-04-11 22.47.14" /><figcaption aria-hidden="true">截屏2022-04-11 22.47.14</figcaption></figure><p><br /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1
id=&quot;learning-to-generate-line-drawings-that-convey-geometry-and-semantics&quot;&gt;Learning
to generate line drawings that convey geometry and s</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图像生成" scheme="http://www.larryai.com/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"/>
    
    <category term="GAN" scheme="http://www.larryai.com/tags/GAN/"/>
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>GanGANv2</title>
    <link href="http://www.larryai.com/2022/05/04/GanGANv2/"/>
    <id>http://www.larryai.com/2022/05/04/GanGANv2/</id>
    <published>2022-05-04T07:31:06.000Z</published>
    <updated>2022-05-06T12:22:28.993Z</updated>
    
    <content type="html"><![CDATA[<h1 id="product-of-experts-gans">Product-of-experts GANs</h1><p><strong>输入：</strong></p><ul><li>图像数据集x</li><li>M个输入方式（多模态）</li></ul><p><strong>目标：</strong></p><p>训练一个单一的操作模型，该模型可以学习在可能模式的任意子集<spanclass="math inline">\(\mathcal{Y}\)</span>上捕获图像分布</p><p><strong>在本文中，我们考虑了四种不同的模式:</strong></p><ul><li><p>文本text</p></li><li><p>语义分割segmentation</p></li><li><p>草图sketch</p></li><li><p>风格参照style reference</p></li></ul><p>学习基于任何子数据的图像分布<spanclass="math inline">\(p(x\mid\mathcal{Y})\)</span>是一项挑战</p><p>因为它需要一个生成器同时去建模<spanclass="math inline">\(2^M\)</span>个分布</p><p>特别值得注意的是</p><p>当<spanclass="math inline">\(\mathcal{Y}\)</span>是空集合时，生成器需要捕获无条件的图像分布</p><p>其他几种模态下的单独的条件分布</p><p><span class="math inline">\(p(x|y_i) , \forall i \in\left\{1,2...M\right\}\)</span></p><p>例如，图像分布仅以文本为条件。这些设置在隔离单独中很受欢迎并得到了广泛的研究，我们的目标是将它们置于一个统一的框架下。</p><h2 id="product-of-experts-modeling">Product-of-experts modeling</h2><p>直观地说，每个输入模态都增加了合成图像必须满足的约束。</p><p>满足所有约束的图像集是满足单个约束的图像集的交点</p><p><strong>分布的乘积类似于集合的交集</strong></p><figure><img src="1.png"alt="The product of distributions is analogous to the intersection of sets" /><figcaption aria-hidden="true">The product of distributions is analogousto the intersection of sets</figcaption></figure><p>如上图，我们通过一个强有力的假设对此进行建模</p><p>即<strong>联合条件概率分布</strong><spanclass="math inline">\(p(x\mid y_i,y_j)\)</span>与单条件概率分布<spanclass="math inline">\(p(x \mid y_i)\)</span>和<spanclass="math inline">\(p(x \mid y_j)\)</span>的乘积成正比</p><p>在此设置下，为了使product分布在某个区域具有高密度，每个单独的分布需要在该区域具有高密度，从而满足每个约束</p><p>通过相乘的方式组合多个分布（“experts”）以前被称为<strong>Product-of-experts</strong></p><p>我们的生成器被训练用来将一个latent code z 映射到一个image x</p><p>因为输出的图像被latent code z 唯一的确定</p><p>所以评估<spanclass="math inline">\(p(x\mid\mathcal{Y})\)</span>的问题可以等价为评估<spanclass="math inline">\(p(z\mid\mathcal{Y})\)</span>的问题</p><p>我们使用Product-of-experts来对潜在(latent)条件分布进行建模 <spanclass="math display">\[p(z\mid\mathcal{Y}) \propto p&#39;(z)\prod_{y_i\in \mathcal{Y}}q(z\midy_i)\]</span></p><ul><li><span class="math inline">\(p&#39;(z)\)</span>是先验概率分布</li><li>每个expert <span class="math inline">\(q(z\midy_i)\)</span>是编码器预测的单一模态的分布</li></ul><blockquote><p>当没有给出模式时，潜在分布只是先验分布。</p><p>随着提供更多的模式，约束的数量增加，可能输出图像的空间缩小，潜在分布变窄。</p></blockquote><h2id="multiscale-and-hierarchical-latent-space多尺度层次潜在空间">Multiscaleand hierarchical latent space（多尺度层次潜在空间）</h2><p>有一些我们考虑的模态是二维的，自然包含多个尺度的信息。</p><p>因此，我们设计了一个带有不同分辨率下的潜变量的hierarchical latentspace（潜在层次空间）</p><p>这允许我们直接将信息从空间编码器的每个分辨率传递到潜在空间的相应分辨率，以便更好地保存高分辨率的控制信号</p><p>从数学上讲，我们的潜在代码z被分成若干组 <span class="math inline">\(z= (z^0 , z^1 ,z^2 ... z^N)\)</span></p><ul><li><p><span class="math inline">\(z^0 \in \mathbb{R}^{c_0}\)</span>是一个特征向量</p></li><li><p><span class="math inline">\(z^k \in \mathbb{R}^{c_k\times r_k\times r_k}\)</span> 是分辨率不断提高的特征图</p></li><li><p>$r_{k+1}= 2r_k , r_1 =4 $ <spanclass="math inline">\(r_N\)</span>是图像分辨率</p></li></ul><p>因此我们可以分解</p><ul><li>先验概率分布<spanclass="math inline">\(p&#39;(z)\)</span>分解到<spanclass="math inline">\(\prod_{k=0}^N p&#39;(z^k |z^{&lt;k})\)</span></li><li>expert <span class="math inline">\(q(z\mid y_i)\)</span> 分解到<spanclass="math inline">\(\prod_{k=0}^N q(z^k | z^{&lt;k} ,y_i)\)</span></li></ul><p>这种设计类似于等级VAE中的前后网络。不同之处在于，我们的编码器在输入模式中编码条件信息，而不是图像本身。根据潜在条件分布公式，我们假设每个分辨率的潜在条件分布是expert的产物<span class="math display">\[p(z^k\mid z^{&lt;k},\mathcal{Y}) \propto p&#39;(z^k |z^{&lt;k})\prod_{y_i\in \mathcal{Y}}q(z^k | z^{&lt;k},y_i)\]</span></p><blockquote><p><span class="math inline">\(p&#39;(z^k | z^{&lt;k}) =\mathcal{N}(\mu_0^k,\sigma_0^k)\)</span> 和 $q(z^k | z^{&lt;k},y_i)=(_i^k,_i^k) $用神经网络参数化均值和标准差的独立高斯分布</p></blockquote><blockquote><p>可以证明 Product of gaussion experts 同样也是高斯分布 <spanclass="math inline">\(p(z^k\mid z^{&lt;k},\mathcal{Y}) =\mathcal{N}(\mu^k,\sigma^k)\)</span></p></blockquote><p><img src="2.png" /></p><h2 id="generator-architecture">Generator architecture</h2><h3 id="encoder">1.Encoder</h3><p><img src="3.png" /></p><p>上图为生成器体系结构的概述。我们将每个模态编码成一个特征向量，然后在<strong>GlobalPoE-Net</strong>中进行聚合。</p><ul><li><p>使用卷积网络(with input skip connections)对分割图seg和草图sketch进行编码</p></li><li><p>使用residual network对风格图style进行编码</p></li><li><p>使用CLIP去对文本text进行编码</p></li></ul><blockquote><p>附录B中给出了所有模态编码器的详细信息。</p><p>解码器使用GlobalPoE-Net的输出以及<strong>分割编码器</strong>和<strong>草图编码器</strong>的跳过连接生成图像</p></blockquote><h3 id="global-poe-net">2.Global PoE-Net</h3><blockquote><p><span class="math inline">\(\mu和\sigma\)</span>下标有0，1，2，3，4</p><p>0表示先验分布 1表示分割编码器 2表示文本编码器 3表示style编码器4表示草图编码器</p></blockquote><p><img src="4.png" /></p><p>在GlobalPoE-Net中，我们使用MLP从每个模态中提取特征向量来预测一个高斯分布<spanclass="math inline">\(q(z^0|y_i)=\mathcal{N}(\mu_i^0,\sigma_i^0)\)</span></p><p>然后我们计算product of Gaussion包括$p'(z^0) = (_0^0,_0^0)=(0,I) $</p><p>并从product分布中采样得到<span class="math inline">\(z^0\)</span></p><p>然后用MLP将<spanclass="math inline">\(z^0\)</span>转化为另一个特征向量<spanclass="math inline">\(w\)</span></p><h3 id="decoder">3.Decoder</h3><p><img src="5.png" /></p><p>解码器主要有一堆残差块组成</p><p><strong>Local-PoE-Net</strong>在当前分辨率下对潜在feature map <spanclass="math inline">\(z^k\)</span>进行采样</p><p>当前分辨率下的product</p><p><span class="math inline">\(p&#39;(z^k | z^{&lt;k}) =\mathcal{N}(\mu_0^k,\sigma_0^k)\)</span> 特征图zk下的先验分布</p><p><span class="math inline">\(q(z^k | z^{&lt;k},y_i) =\mathcal{N}(\mu_i^k,\sigma_i^k)\)</span> 特征图zk下不同模态的分布</p><blockquote><p><spanclass="math inline">\(\mu_0^k,\sigma_0^k\)</span>根据最后一层的输出计算</p><p><spanclass="math inline">\(\mu_i^k,\sigma_i^k\)</span>通过连接最后一层的输出和相应模态的跳过连接来计算</p></blockquote><blockquote><p>请注意，只有具有跳过连接的模式(分割图和草图)对计算作出贡献</p><p>其他模式（文本和style参考）仅提供global信息，而不提供local细节。</p></blockquote><p>local-PoE-net生成的潜在特征映射<spanclass="math inline">\(z^k\)</span>和global-PoE-net生成的特征向量<spanclass="math inline">\(w\)</span>被送到LG AdaIN层</p><p>本地全局自适应实例规范化(LG AdaIN)</p><p><img src="6.png" /></p><p><img src="7.png" /></p><ul><li><p><spanclass="math inline">\(h^k\)</span>是在残差分支中通过一个卷积层得到的一个featuremap</p></li><li><p>μ(hk) and σ(hk) 是通道平均值和标准差</p></li><li><p><span class="math inline">\(\beta_{z^k} , \gamma_{z^k}\)</span>由<span class="math inline">\(z^k\)</span>通过一个1x1卷积得到</p></li><li><p><span class="math inline">\(\beta_{w} ,\gamma_{w}\)</span>由w计算得到</p></li></ul><blockquote><p>LG-AdaIN可以被看作AdaIN和SPADE的组合采用<strong>全局特征向量</strong>和<strong>空间变化特征映射</strong>来调节激活。</p></blockquote><h2id="multiscale-multimodal-projection-discriminator多尺度多模投影鉴别器">Multiscalemultimodal projection discriminator（多尺度多模投影鉴别器）</h2><blockquote><p>输入：</p><ul><li>image x</li><li>一系列的条件 <span class="math inline">\(\mathcal{Y}\)</span></li></ul><p>输出：</p><p>一个分数<span class="math inline">\(D(x,\mathcal{Y}) =sigmoid(f(x,\mathcal{Y}))\)</span>表明真实性</p><p>f的最优解是</p><p><img src="8.png" /></p></blockquote><p>我们假设给出x的不同模态下的条件独立,投影鉴别器（PD）（估计是一篇论文里的方法）建议使用<strong>内积</strong>来估计条件变量,他的实施将有条件的期限限制为,要相对简单，这会产生一个很好的归纳偏差，从而产生很强的实证结果。<img src="9.png" /></p><p>原始的PD</p><ul><li>首先将图像和条件一起输入到一个<strong>shared latentspace</strong>（潜在共享空间）</li><li>然后使用一个<strong>线性层</strong>来估计图像嵌入的<strong>无条件项（unconditionalterm）</strong></li><li>并使用图像嵌入和条件嵌入之间的<strong>内积</strong>来估计<strong>条件项(conditionalterm)</strong>。</li><li>将<strong>无条件项</strong>和<strong>条件项</strong>相加，以获得最终的鉴别器的结果</li></ul><blockquote><p>相当于PD的推广</p><p>我们提出了一种多模态投影判别器，它将投影判别器推广到处理多个条件输入。与计算图像嵌入和条件嵌入之间的单个内积的标准投影判别器不同，我们为每个输入模态计算一个内积并将它们加在一起以获得最终损失。</p></blockquote><p><img src="10.png" /></p><p><span class="math display">\[f(x,\mathcal{Y}) = Linear(D_x(x)) = \sum_{y_i \in \mathcal{Y}}D_{y_i}^T(y_i)D_x(x)\]</span></p><p>对于分割和草图等空间模式，在多个尺度下加强它们与图像的对齐更有效。</p><p>如图所示，我们将图像和空间模式编码为不同解决方案的特征图，并计算每个分辨率下的MPD损失。</p><p>我们计算每个位置和分辨率的损失值，然后通过先对位置进行平均，然后再对分辨率进行平均，得到最终损失。</p><p>我们将产生的鉴别器命名为多尺度多模投影鉴别器（MMPD），并在附录B中描述其细节</p><figure><img src="11.png" alt="截屏2022-03-12 19.59.36" /><figcaption aria-hidden="true">截屏2022-03-12 19.59.36</figcaption></figure><h2 id="losses-and-training-procedure">Losses and trainingprocedure</h2><h3 id="section"></h3><h3 id="latent-regularization">Latent regularization</h3><p>在product-of-experts的假设下他认为<strong>有条件的潜在分布</strong>应该与<strong>无条件的先验分布</strong>相匹配</p><figure><img src="12.png" alt="截屏2022-03-15 10.34.41" /><figcaption aria-hidden="true">截屏2022-03-15 10.34.41</figcaption></figure><p>我们<strong>最小化</strong>在每个分辨率下<strong>有条件的潜在分布</strong><spanclass="math inline">\(p(z|y_i)\)</span>和<strong>无条件的先验分布</strong><spanclass="math inline">\(p&#39;(z)\)</span>的KL散度</p><figure><img src="13.png" alt="截屏2022-03-15 10.37.50" /><figcaption aria-hidden="true">截屏2022-03-15 10.37.50</figcaption></figure><ul><li><spanclass="math inline">\(w_k\)</span>是分辨率相关的再平衡权重</li><li><span class="math inline">\(w_i\)</span>是一个特定误差权重</li></ul><blockquote><p>KL损失也减少了条件模式崩溃，因为它鼓励条件潜在分布接近先验分布，因此具有高熵。</p><p>从信息瓶颈的角度来看，KL损失鼓励每个模态只提供指定条件图像分布所需的最小信息。</p></blockquote><h3 id="contrastive-losses">Contrastive losses</h3><p>对比损失在<strong>表示学习</strong>中得到了广泛的应用，最近应用到图像合成</p><p>给定一批配对向量<span class="math inline">\((u,v) = \left\{(u_i,v_i), i =1,2,3...N\right\}\)</span></p><p>对称性交叉熵损失 最大化成对向量的相似性，同时分开 非成对向量</p><figure><img src="14.png" alt="截屏2022-03-15 10.46.34" /><figcaption aria-hidden="true">截屏2022-03-15 10.46.34</figcaption></figure><p>我们使用两种配对来构造两个对比损失项：<strong>图像对比损失</strong>和<strong>条件对比损失</strong></p><h4 id="图像对比损失">图像对比损失</h4><p>可最大化<strong>真实图像</strong>与<strong>基于条件生成的图像</strong>的相似性<span class="math display">\[\mathcal{L}_{cx} = \mathcal{L}^{ce}(E_{vgg}(x) , E_{vgg}(\bar{x}))\]</span></p><h4 id="条件对比损失">条件对比损失</h4><blockquote><p>条件对比损失可以更好地使图像与相应的条件一致。</p></blockquote><h5id="对识别器进行训练以最大化真实图像x的嵌入和条件输入之间的相似性">对识别器进行训练，以最大化真实图像X的嵌入和条件输入之间的相似性</h5><ul><li>辨别器的条件对比损失</li></ul><p><span class="math display">\[\mathcal{L}_{cy}^D = \mathcal{L}^{ce}(D_x(x) , D_{y_i}(\mathcal{Y}_i))\]</span></p><blockquote><p>其中，Dx和Dy分别是鉴别器中的两个模块，分别从x和y_i中提取特征</p></blockquote><h5id="生成器使用相同的损失进行训练但使用生成的图像barx代替真实图像x来计算鉴别器嵌入">生成器使用相同的损失进行训练，但使用生成的图像<spanclass="math inline">\(\bar{x}\)</span>代替真实图像x来计算鉴别器嵌入</h5><ul><li>生成器的条件对比损失</li></ul><p><span class="math display">\[\mathcal{L}_{cy}^G = \mathcal{L}^{ce}(D_x(\bar{x}) ,D_{y_i}(\mathcal{Y}_i))\]</span></p><blockquote><p>在实践中，我们只对<strong>文本模式</strong>使用条件对比损失，因为它消耗了太多的GPU内存，而对其他模式使用条件对比损失，尤其是在图像分辨率和批量较大的情况下。</p></blockquote><h3 id="full-training-objective">Full training objective</h3><p>总的LOSS包含生成器LOSS和辨别器LOSS</p><figure><img src="15.png" alt="image-20220315125032385" /><figcaption aria-hidden="true">image-20220315125032385</figcaption></figure><ul><li><span class="math inline">\(\mathcal{L}^G 和\mathcal{L}^D\)</span>是非饱和GAN损失</li><li><spanclass="math inline">\(\mathcal{L}_{GP}\)</span>是R1梯度惩罚损失</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;product-of-experts-gans&quot;&gt;Product-of-experts GANs&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;输入：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像数据集x&lt;/li&gt;
&lt;li&gt;M个输入方式（多模态）&lt;/li&gt;
&lt;/ul&gt;
&lt;p</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图像生成" scheme="http://www.larryai.com/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"/>
    
    <category term="GAN" scheme="http://www.larryai.com/tags/GAN/"/>
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>ChipGAN</title>
    <link href="http://www.larryai.com/2022/05/04/ChipGAN/"/>
    <id>http://www.larryai.com/2022/05/04/ChipGAN/</id>
    <published>2022-05-04T07:21:07.000Z</published>
    <updated>2022-05-06T08:03:21.081Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概要">概要</h1><p>​风格转换已成功应用于照片，生成逼真的西方绘画。然而，由于中西绘画技法的内在差异，直接套用已有的方法，对中国水墨画风格的转换并不能产生令人满意的效果。本文提出了一种基于ChipGAN的端到端（end-to-end）生成对抗性网络体系结构，用于照片转化为中国水墨画。</p><blockquote><p>ChipGAN的核心模块实施了三个约束</p><ul><li><p>空白（voids）</p></li><li><p>笔触（ brush strokes）（画笔描边）</p></li><li><p>水墨色调和扩散（ink wash tone and diffusion）</p></li></ul><p>以解决中国水墨画中普遍采用的三个关键技术。</p></blockquote><p>​我们通过咨询专业艺术家，基于新建的中国水墨照片和图像数据集，进行风格化感知研究，以评估生成的绘画与真实绘画的相似性。与最先进的网络和高度程式化的感知研究核心相比，该方法在视觉质量方面的优势表明了该方法的有效性。</p><h1 id="介绍">介绍</h1><h1 id="section"><img src="fig1.png" /></h1><p>​任何成功的艺术家都有自己独特的绘画风格。研究绘画风格中的这种独特性对绘画技能的训练很重要。除了传统的艺术理论培训，计算机视觉和图形技术如风格迁移和非真实感渲染，旨在帮助绘画艺术家系统地理解如何通过观察真实场景或照片，运用适当的绘画技巧呈现独特风格。</p><p>​将绘画风格迁移到图像可以通过纹理合成来实现，使用低级别的图像特征，忽略图像的语义信息。利用卷积神经网络（CNN）从图像中提取高级语义信息进行风格转换，这显示了视觉逼真的结果（如上图，根据真实西方绘画的风格从照片到生成的西方绘画）。</p><p>​然而，直接将现有的风格转换技术应用到中国水墨画中会产生不切实际的结果（图中，生成的水墨画，请注意混乱的线条和颜色）。这是因为中国水墨画和西方水墨画有几个本质的区别，在图中的最后一列中，西方真实绘画与水墨画真实绘画之间的比较表明：</p><ul><li>1）就一幅画的构图而言，西方绘画在整个图像上充满了色彩，而中国水墨画则有一定的空白区域；</li><li>2）就表达技巧而言，西方绘画很少使用强线，而它指的是白皮书中的一些区域，中国水墨画家特意留下这些区域来启发观众去想象。会议：2018年10月22日至26日，韩国首尔,中国水墨画采用线条鲜明的笔触来强调轮廓中的物体；</li><li>3）在色彩丰富性方面，西方绘画倾向于使用多种颜色，而中国水墨画主要使用不同灰度的墨水，这些墨水会扩散到一张宣纸上（水墨色调和扩散）</li></ul><p>​为了实现中国水墨画的风格转换，我们提出了一种基于生成对抗网络（GAN）的中国水墨画风格转换解决方案，名为CHIPGAN。根据中国水墨画的三种技法，我们提出了三种特殊的约束：空白、笔触、水墨色调和扩散。</p><blockquote><p>对于空洞，我们的约束结合了<strong>对抗损失</strong>和<strong>周期一致性损失</strong>，因为它们的目的是通过将信息转换为不可感知的信号来生成更真实的结果，从而留下白色区域。</p></blockquote><blockquote><p>对于画笔笔划，我们嵌入了一个预先训练好的<strong>整体嵌套边缘检测器</strong>（holistically-nestededgedetector），并在照片和假画的边缘映射之间加强重新设计的交叉熵损失，以强调有力的线条。</p></blockquote><blockquote><p>对于水墨扩散和色调，我们使用<strong>腐蚀和模糊</strong>(eroded andblurred)的图像来模拟这种绘画特性，并提出了<strong>水墨鉴别器</strong>来区分处理过的真假画</p></blockquote><p>​现有的绘画数据集主要包含西方画家的作品（如梵高、莫奈等），没有包含相应中国水墨画的真实照片和图像的可用数据集。为了解决我们的问题，我们提供了一个中国水墨画数据集，其中包括从互联网和艺术工作室收集的真实场景照片和绘画图像，我们的数据集名为“ChipPhi”。</p><blockquote><p>数据集包括</p><ul><li>1630张马的照片（不同颜色和不同姿势）</li><li>912张徐悲鸿的绘画图像</li><li>1976张风景照片（世界著名风景）</li><li>1542张黄宾虹的绘画图像的景观数据集</li></ul></blockquote><p>总之，本文的贡献有三个方面</p><ul><li>我们提出了ChipGAN，这是第一个执行从照片到中国水墨画风格转换的3个弱监督的深度网络架构，特别考虑了中国水墨画的三个基本技术：空白、笔触、水墨色调和扩散</li><li>我们引入了专业艺术家参与的风格化知觉研究，以评估原画和真画之间的风格一致性，并借助深度神经网络分析中国水墨画家的技巧</li><li>我们建立了第一个包含中国水墨画真实场景和图像的数据集ChipPhi，以便于训练和测试所提出的方法，并有助于中国水墨画风格转移的后续研究</li></ul><h1 id="相关工作">相关工作</h1><p>​<strong>图像风格迁移</strong>意味着将某个示例图像的样式迁移到目标图像。以前的图像级风格转换可以分为纹理合成和基于approache的卷积神经网络</p><p>​<strong>域级风格传递</strong>是指将给定的图像（如照片）与某个域的风格（如某个画家的风格）进行转换。它是通过基于生成性对抗网络（GAN）的方法实现的。</p><p>​ 此外，我们还回顾了一些专门为中国水墨画设计的计算方法</p><ul><li><p>纹理合成</p><blockquote><p>有一些非参数算法可以通过对给定的纹理图像重新采样来合成纹理。</p><p>Efros和Freeman提出了一种对应映射，根据目标图像的图像强度约束纹理合成过程。</p><p>Ashikhmin专注于传输高频纹理，但保留目标图像的比例。</p><p>Hertzmanet al.应用图像类比将源图像的样式转换为目标图像。</p><p>然而，由于纹理合成主要依赖于面片和低层次的表现，它们无法传递艺术作品的语义风格</p></blockquote></li><li><p>CNN based approaches</p><blockquote><p>基于CNN的模型旨在通过预先训练的卷积神经网络提取语义表示。</p><p>Gatysetal.[11]首先使用CNN获取图像的表示，并在自然照片上重现著名的喘息风格。</p><p>Liet al.[30]发现线性核是极大平方的一个很好的替代品。</p><p>Yin[48]和Chen及Hsu[3]研究了内容感知神经风格转移，并改善了结果。</p><p>这些方法大多存在速度慢、计算量大的问题，可通过[21,39]中的方法进行加速。Li和Wand[29]训练了一个马尔可夫前馈网络来解决效率问题。</p><p>Dumoulinet等人[7]建议同时学习多种风格。虽然这些方法为西方绘画创造了令人印象深刻的形象，但由于中国水墨画的本质不同，它们无法传递中国水墨画的风格</p></blockquote></li><li><p>GAN based approaches</p><blockquote><p>从GAN的角度处理风格转换任务时，一些图像到图像的翻译方法是相当有效的。</p><p>CoupledGAN[34]通过实施权重共享约束来学习多域图像的关联分布。</p><p>然而，这种方法只能以一个noise vector作为输入来生成成对的图像。</p><p>因此，它不能直接用作样式转换模型。</p><p>Liuet等人[33]将CoupledGAN[34]与变分自动编码器[24]结合起来，提出了一个名为UNIT[33]的框架。</p><p>Zhuet al.引入循环一致性损失来减少映射的置换，并提出CycleGAN[50]。</p><p>基于CycleGAN[50]的体系结构，DistanceGAN[2]实施了一个约束，即在映射到另一个域时，一个域中两个样本的距离应保持不变。</p><p>我们还在模型中选择周期一致性损失来克服模式崩溃[13]，并将其与对抗性损失相结合来模拟空洞。</p><p>虽然周期一致性损失使模型保留了原始照片中的一些细节，但它同时也会错误地删除一些重要的笔画，这促使我们为中国水墨画的笔画建模设置额外的约束</p></blockquote></li><li><p>Computational methods for Chinese ink wash paintings</p><blockquote><p>中国水墨画可以使用不同的计算方法生成。</p><p>Yuetal.将真实绘画的笔触纹理与给定景观图像的颜色信息相结合，合成一幅水墨画。</p><p>Xuetal.用事先准备好的工具分解中国水墨画的笔触用于渲染动画的笔刷笔划库。</p><p>Yang和Xu通过提供自动笔刷笔划轨迹估计，进一步完善了笔刷笔划分解方法。</p><p>Wang基于Kubelka-Munk方程，提出了一种模拟水墨扩散的有效算法。</p><p>Yehet al.和Wayetal.基于3D模型的板线笔划和内部着色生成链接水墨画。</p><p>Liang和Jin通过对边缘、颜色和纸张纹理的图像处理，从给定的照片生成水墨画。</p><p>我们的方法不再像以前那样依赖现有的<strong>笔画模拟</strong>和<strong>低级图像特征</strong>，而是<strong>探索数据驱动技术来学习真实的中国水墨画特征表示</strong></p></blockquote></li></ul><h1 id="提议的方法">提议的方法</h1><p>chipGAN学习从照片领域（例如，由现实世界的马的照片定义）到绘画领域（例如，由中国水墨画的马定义）的映射。</p><ul><li><p>在<strong>空白约束</strong>中，我们结合<strong>循环一致性损失</strong>和对抗性损失作为处理空白(voids)技术的约束条件</p></li><li><p>在<strong>笔触约束</strong>中，提出了brushstrokeloss去除不必要的笔触，同时保留精华；</p></li><li><p>在<strong>水墨约束</strong>中添加了<strong>扩散效应</strong>（diffusioneffect）和<strong>水墨损失</strong>，以确保整个图像的正确色调</p></li></ul><p><img src="chipan结构图.png" /></p><h2 id="void-constraint">1.Void constraint</h2><p>直观地说，应用空白意味着在画布上的适当位置留下空白。</p><p>以马为例，适当地应用空洞需要生成的图像完全忽略天空，并且部分地忽略照片中的草，同时清晰地保持马的轮廓，如图的中间部分所示。</p><p>马的照片和一幅中国水墨画具有不同的熵，因为照片与绘画图像相比具有丰富的颜色和纹理。</p><p>在图像到图像的翻译任务中，利用源域和目标域之间的这种不同熵，通过组合对抗性损失和循环一致性损失，将源图像的信息有效地转换为几乎不可感知的信号。</p><p>因此，我们采用了类似的策略来实施空白约束</p><h3 id="adversarial-loss">Adversarial loss</h3><p>给出被认为是分别为X和Y的域的未配对的训练集合</p><p>我们的模型给出两个映射关系：<span class="math inline">\(G :X\rightarrow Y \; F:Y \rightarrow X\)</span></p><p>对于$G : XY <span class="math inline">\(以及他的辨别器\)</span>D_Y$的对抗损失是这样定义的</p><p><img src="adv%20loss.png" /></p><h3 id="cycle-consistency-loss">Cycle consistency loss</h3><p>​ 我们通过将给定的图像X从domain X totarget域Y中翻译出来，然后返回到domainX，这将产生相同的图像，从而增加循环一致性约束，公式表达为<spanclass="math inline">\(F(G(X))\approx X\)</span>。由于循环一致性约束要求在两个方向上进行恢复，因此对于每个在DomainY的图像，还存在一个循环一致性约束$G(F(Y)) Y $</p><p><img src="cycle%20loss.png" /></p><p>这种约束使得生成的图像保留了源域的一些信息，从而可以将生成的图像转换回源域。</p><h2 id="brush-stroke-constraint">Brush stroke constraint</h2><p><img src="笔触结果.png" alt="截屏2022-03-13 13.34.26" style="zoom:20%;" /></p><p>​考虑到正确生成的空白区域，我们的下一个目标是增加笔触，以清晰地描绘中国水墨画风格的物体轮廓例如马的头部和身体应该有强烈的轮廓。</p><p>​为了以统一的方式对中国水墨画中不同厚度的各种类型的笔划进行建模，我们制定了我们的<strong>笔触约束</strong>，用于加强真实照片和生成绘画的不同级别的边缘映射之间的一致性。</p><p>​我们采用<strong>整体嵌套的边缘检测器</strong>从输入图像中提取五层边缘，以模拟五种不同厚度的笔划。</p><p>​然后，我们合并从预先训练的VGG-16特征提取程序的不同阶段生成的边缘映射，以获得最终的边缘映射。与将边缘检测任务视为像素级<strong>二值分类问题</strong>不同，我们从<strong>回归</strong>的角度训练了一个多级边缘检测器，以获得<strong>不同厚度</strong>的平滑笔划。</p><p>​ training groundtruth中的每个像素都用0到1的实数标记，这表明它们可能是边缘的一部分。</p><p>​ 我们获得真实图像的edge map E(x) 以及 生成图像的edge map E(G(x))</p><p>​ 然后我们将E(x)作为ground truth然后计算平衡交叉熵损失以让G生成正确的笔触</p><p><img src="笔触.png" /></p><ul><li>N是照片或假画边缘图中的像素总数</li><li><span class="math inline">\(\mu\)</span>是一个平衡权重<ul><li><span class="math inline">\(\mu\)</span> =N_/N and 1-<spanclass="math inline">\(\mu\)</span> = N+/N</li><li>N_ 是边缘图中所有不是边缘点的可能性之和</li><li>N+是边缘图中所有是边缘点的可能性之和</li></ul></li></ul><h2 id="ink-wash-constraint">ink wash constraint</h2><p>​正确模拟了空洞和笔触，我们的最终处理是使<strong>全局色调</strong>（例如，生成的马画的整体色温应接近真实色温）和<strong>扩散效果</strong>（例如，马的腹部显示链接扩散到宣纸上的不同灰度）在真实绘制和生成绘制g（x）之间保持一致。因此，我们进一步引入了<strong>水墨约束</strong>。</p><p>​水墨在宣纸上的扩散是近似各向同性的，所以我们用<strong>侵蚀操作</strong>和<strong>高斯模糊操作</strong>来模拟它。</p><p>​当突出的物体被模糊时，这个操作会抑制纹理和内容信息的显式比较，因此，该模型更倾向于关注tone（风格？）的一致性，如图所示</p><p><img src="ink%20water.png" /></p><p>因此，我们添加了一个对抗性鉴别器<spanclass="math inline">\(D_I\)</span>，用于区分<spanclass="math inline">\(y_{eb}\)</span>和<spanclass="math inline">\(G(x)_eb\)</span></p><p><img src="ink%20water%20yeb.png" /></p><ul><li>y_eb是经过侵蚀和模糊处理的真实绘画</li><li>G(x)_eb是经过侵蚀和模糊处理的生成绘画</li><li>⊖是侵蚀操作</li><li>B是一个侵蚀核</li><li>高斯模糊核 <span class="math inline">\(G_{k,l} =\frac{1}{2\pi\sigma^2}exp(-\frac{k^2+l^2}{2\sigma^2})\)</span></li></ul><p>最后我们定一个水墨画损失:</p><p><img src="ink%20water%20loss.png" /></p><h2 id="full-objective">Full objective</h2><p>我们的全部目标是上述四种损失的线性组</p><p><img src="funll%20loss.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概要&quot;&gt;概要&lt;/h1&gt;
&lt;p&gt;​
风格转换已成功应用于照片，生成逼真的西方绘画。然而，由于中西绘画技法的内在差异，直接套用已有的方法，对中国水墨画风格的转换并不能产生令人满意的效果。本文提出了一种基于ChipGAN的端到端（
end-to-end）生成对抗性网络体</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="风格迁移" scheme="http://www.larryai.com/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"/>
    
    <category term="图像生成" scheme="http://www.larryai.com/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"/>
    
    <category term="GAN" scheme="http://www.larryai.com/tags/GAN/"/>
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
  </entry>
  
  <entry>
    <title>MGUIT</title>
    <link href="http://www.larryai.com/2022/05/04/MGUIT/"/>
    <id>http://www.larryai.com/2022/05/04/MGUIT/</id>
    <published>2022-05-04T07:19:48.000Z</published>
    <updated>2022-05-04T07:39:26.647Z</updated>
    
    <content type="html"><![CDATA[<p><img src="1.png" /></p><h1 id="class-aware-memory-network">Class-aware Memory Network</h1><p><img src="2.png" /></p><h2 id="结构理解">结构理解</h2><blockquote><p>每个class下有<spanclass="math inline">\(N_k\)</span>个item,所有class的item数之和为N，即一共有N个item。</p><p>满足 <span class="math inline">\(\sum_{k=1}^K N_k = N\)</span></p></blockquote><h3 id="对于每个class要用n_k个item的理解">对于每个class要用<spanclass="math inline">\(N_k\)</span>个item的理解：</h3><blockquote><p>比如一个class为人脸，那么人脸上的眼睛、嘴唇、皮肤都是不一样的特征，因此需要用到多个item表示一个class</p></blockquote><h3 id="item的组成">item的组成</h3><blockquote><p>每个item由( k , <span class="math inline">\(v^x\)</span> , <spanclass="math inline">\(v^y\)</span>)组成</p><ul><li>k , <span class="math inline">\(v^x\)</span> , <spanclass="math inline">\(v^y\)</span> 的大小都是 1x1xC 其中C是通道数</li><li>k用来检索item 大小1x1xC 方便与每个像素进行求余弦相似度用来表示content feature</li><li><span class="math inline">\(v^x\)</span>表示在 x domin 上的stylefeature</li><li><span class="math inline">\(v^y\)</span>表示在 y domin 上的stylefeature</li></ul></blockquote><h3 id="特征聚类">特征聚类</h3><blockquote><p>训练的时候，会用到数据集中的objectannotations（对象注释比如物体的种类，物体的框的位置）来辅助。</p><p>每张图的特征(c,s)会被聚类为K类：（K就是这张图像的所有class）</p><p>(𝑐1,𝑠1),···,(𝑐𝐾,𝑠𝐾)</p><ul><li><p>c1中有<span class="math inline">\(N_1^c\)</span>个items1中有<span class="math inline">\(N_1^s\)</span>个item</p></li><li><p><span class="math inline">\(c_k\)</span>中 有<spanclass="math inline">\(N_k^c\)</span>个item <spanclass="math inline">\(s_k\)</span>中 有<spanclass="math inline">\(N_k^s\)</span>个item</p></li></ul><p>这些聚类后的信息read / update memory</p></blockquote><h2 id="read">Read</h2><h3 id="前置知识">前置知识</h3><ul><li><p>假设每张图像大小为CxHxW ， 那么一个通道上面就有P=HxW个像素点每个像素点的content feature 为 1x1xC</p></li><li><p>memory中有K个class，N个item 每个item有一个k其中k的大小为1x1xC</p></li><li><p>余弦相似度的公式定义 <span class="math display">\[d(c_p , k_n) = \frac{c_pk_n^T}{|\left |  c_p|\right|_2 |\left|  k_n|\right|_2}\]</span></p></li></ul><h3id="计算第p个像素点与第n个item的相似度权重">计算第p个像素点与第n个item的相似度权重</h3><blockquote><p>一共有P个像素点，第p个像素点的大小为1x1xC，记为<spanclass="math inline">\(c_p\)</span></p><p>一共有N个item，第n个item的k的大小为1x1xC，记为<spanclass="math inline">\(k_n\)</span></p></blockquote><p>计算<span class="math inline">\(c_p\)</span>与<spanclass="math inline">\(k_n\)</span>的相似度，并在N的维度上求softmax作为每个kn的权重</p><p><img src="3.png" /></p><ul><li><span class="math inline">\(\alpha_{p,n}^x\)</span>表示对于xdomin上第p个像素点与memory中第n个item的k的相似度权重（属于第n类的概率）</li><li><span class="math inline">\(\alpha_{p,n}^y\)</span>表示对于ydomin上第p个像素点与memory中第n个item的k的相似度权重（属于第n类的概率）</li></ul><h3 id="计算风格特征hats">计算风格特征<spanclass="math inline">\(\hat{s}\)</span></h3><blockquote><p>第p个像素点的风格特征就是 对每个item的style feature 进行加权求和 ，其中权重是<spanclass="math inline">\(c_p\)</span>与item的k的相似度权重</p></blockquote><p><img src="4.png" /></p><ul><li><span class="math inline">\(v_{n}^x\)</span>表示xdomin上第n个item的style feature</li><li><span class="math inline">\(v_{n}^y\)</span>表示ydomin上第n个item的style feature</li></ul><blockquote><p>最终所有的p聚合成最后的特征图</p></blockquote><h2 id="update">update</h2><p>update是求权重然后按权重更新（<span class="math inline">\(k\)</span>, <span class="math inline">\(v^x\)</span> , <spanclass="math inline">\(v^y\)</span>）</p><h3id="计算第n个item的k与第p个像素点的相似度权重">计算第n个item的k与第p个像素点的相似度权重</h3><p><img src="5.png" /></p><blockquote><p>与read的计算权重不同，update是在P的维度上求softmax作为每个p的权重（第n个类与哪些p比较接近）</p></blockquote><h3 id="更新k-vx-vy">更新（<span class="math inline">\(k\)</span> ,<span class="math inline">\(v^x\)</span> , <spanclass="math inline">\(v^y\)</span>）</h3><blockquote><p>对第n个item的content feature进行更新 加上每个像素点的contentfeature的加权和</p><p>对第n个item的style feature进行更新 加上每个像素点对应的stylefeature的加权和</p></blockquote><p><img src="6.png" /></p><blockquote><p>k保存的content feature是两个domain共享的，所以一起更新</p><p>而v保存的style feature是两个domain单独的，所以分开更新。</p></blockquote><p>更新步骤如下:</p><p><img src="7.png" /></p><h1 id="loss-function">Loss Function</h1><h2 id="image-to-image-translation-network">image-to-image translationnetwork</h2><h3 id="reconstruction-loss-重建损失">1.Reconstruction loss(重建损失)</h3><p><img src="8.png" /></p><ul><li><span class="math inline">\(L^{self}\)</span>是x的原始contentfeature与构建的x style生成的图像与原图越逼近 ， 使得xstyle更加精确表达x的风格</li><li><spanclass="math inline">\(L^{cyc}\)</span>是将x内容特征与y风格特征产生的图像再用x风格特征产生的图像与 原图逼近</li></ul><h3 id="adversarial-loss">2.Adversarial loss</h3><blockquote><p>目的是为了最小化两个不同功能之间的分布差异</p><p>我们采用了两种对抗性损失函数：</p><ul><li><strong>contentdiscriminato</strong>：Cx和Cy之间的内容对抗性损失函数<ul><li>使得x的内容在y风格下仍旧保持原本的内容</li></ul></li><li><strong>domain discriminator</strong>：X和Y领域对抗性损失函数</li></ul></blockquote><h3 id="kl-loss">3.KL loss</h3><blockquote><p>使style的分布更接近先前的高斯分布</p></blockquote><h3 id="latent-regression-loss">4.Latent regression loss</h3><blockquote><p>使得style和image之间的映射是可逆的</p></blockquote><h2 id="class-aware-memory-network-1">Class-aware memory network</h2><h3 id="feature-contrastive-loss特征对比损失">Feature contrastiveloss（特征对比损失）</h3><blockquote><p>对于每一个特征<span class="math inline">\(c_p\)</span>(或<spanclass="math inline">\(s_p\)</span>)，我们将它最近的item <spanclass="math inline">\(k_p\)</span>（或<spanclass="math inline">\(v_p\)</span>）定义为正样本，其他样本为负样本。</p><p>到正/负样本的距离如如下方式惩罚</p><p>τ是控制浓度分布水平的温度参数</p></blockquote><p><img src="9.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;1.png&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;class-aware-memory-network&quot;&gt;Class-aware Memory Network&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;2.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;结构理解&quot;&gt;结构理解</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="风格迁移" scheme="http://www.larryai.com/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"/>
    
    <category term="GAN" scheme="http://www.larryai.com/tags/GAN/"/>
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>线性链表</title>
    <link href="http://www.larryai.com/2022/05/04/%E7%BA%BF%E6%80%A7%E9%93%BE%E8%A1%A8/"/>
    <id>http://www.larryai.com/2022/05/04/%E7%BA%BF%E6%80%A7%E9%93%BE%E8%A1%A8/</id>
    <published>2022-05-04T07:15:02.000Z</published>
    <updated>2022-05-04T07:15:30.981Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性链表">线性链表</h1><h3 id="源代码清单">1.1源代码清单:</h3><ul><li><h5 id="linklist.cpp">LinkList.cpp</h5></li><li><h5 id="linklist.h">LinkList.h</h5></li></ul><h3 id="线性链表数据结构">1.2线性链表数据结构:</h3><blockquote><p>本程序元素类型为int,读者可根据需求自行更改数据类型。<br /></p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//单链表数据结构</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">LNode</span>&#123;</span><br><span class="line">    <span class="type">int</span> data;</span><br><span class="line">   <span class="keyword">struct</span> <span class="title class_">LNode</span> *next;</span><br><span class="line">&#125;LNode , *LinkList;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="线性链表的基本操作">1.3线性链表的基本操作:</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">InitList</span><span class="params">(LinkList &amp;L)</span></span>;</span><br><span class="line"><span class="comment">// 销毁 释放链表所占内存，头结点也会被清理。</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">DestroyList</span><span class="params">(LinkList* L)</span></span>;</span><br><span class="line"><span class="comment">// 置空 这里需要释放链表中非头结点处的空间。</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">ClearList</span><span class="params">(LinkList L)</span></span>;</span><br><span class="line"><span class="comment">// 判空 判断链表中是否包含有效数据。</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ListEmpty</span><span class="params">(LinkList L)</span></span>;</span><br><span class="line"><span class="comment">// 计数</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">ListLength</span><span class="params">(LinkList L)</span></span>;</span><br><span class="line"><span class="comment">// 取值</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">GetElem</span><span class="params">(LinkList L, <span class="type">int</span> i, <span class="type">int</span> &amp;e)</span></span>;</span><br><span class="line"><span class="comment">// 查找 返回链表中首个与e满足Compare关系的元素位序。 如果不存在这样的元素，则返回0。</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">LocateElem</span><span class="params">(LinkList L, <span class="type">int</span> e, <span class="type">bool</span>(Compare)(<span class="type">int</span>, <span class="type">int</span>))</span></span>;</span><br><span class="line"><span class="comment">// 前驱</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">PriorElem</span><span class="params">(LinkList L, <span class="type">int</span> cur_e,<span class="type">int</span>* pre_e)</span></span>;</span><br><span class="line"><span class="comment">// 后继</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">NextElem</span><span class="params">(LinkList L, <span class="type">int</span> cur_e, <span class="type">int</span>* next_e)</span></span>;</span><br><span class="line"><span class="comment">// 插入</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">ListInsert</span><span class="params">(LinkList L, <span class="type">int</span> i, <span class="type">int</span> e)</span></span>;</span><br><span class="line"><span class="comment">// 删除</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">ListDelete</span><span class="params">(LinkList L, <span class="type">int</span> i, <span class="type">int</span>* e)</span></span>;</span><br><span class="line"><span class="comment">// 遍历</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ListTraverse</span><span class="params">(LinkList L, <span class="type">void</span>(Visit)(<span class="type">int</span>))</span></span>;</span><br></pre></td></tr></table></figure><h3 id="linklist.h-1">1.4 LinkList.h</h3><ul><li><h4 id="宏定义">宏定义</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">/* 状态码 */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TRUE        1   <span class="comment">// 真/是</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> FALSE       0   <span class="comment">// 假/否</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OK          1   <span class="comment">// 通过/成功</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ERROR       -1   <span class="comment">// 错误/失败</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//系统中已有此状态码定义，要防止冲突</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> OVERFLOW</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OVERFLOW    -2  <span class="comment">//堆栈上溢</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><ul><li><h4 id="初始化表">初始化表</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">InitList</span><span class="params">(LinkList &amp;L)</span></span>&#123;</span><br><span class="line">    <span class="comment">//创建头节点</span></span><br><span class="line">    L = (LinkList) <span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(LNode));</span><br><span class="line">    <span class="comment">//创建是否成功</span></span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)&#123;</span><br><span class="line">        <span class="built_in">exit</span>(OVERFLOW);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//头节点指向空</span></span><br><span class="line">    L-&gt;next=<span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="销毁线性表">销毁线性表</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">DestroyList</span><span class="params">(LinkList&amp; L)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    &#125;</span><br><span class="line">    LinkList p =L;</span><br><span class="line">    <span class="keyword">while</span>(p-&gt;next!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">        p=L-&gt;next;</span><br><span class="line">        <span class="built_in">free</span>(L);</span><br><span class="line">        L=p;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="置空线性表">置空线性表</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">ClearList</span><span class="params">(SqList &amp;L)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line"></span><br><span class="line">    L.length=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="判断是否为空">判断是否为空</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ListEmpty</span><span class="params">(LinkList L)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">return</span> L-&gt;next==<span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="线性表长度">线性表长度</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">ListLength</span><span class="params">(LinkList L)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    LinkList p=L-&gt;next;</span><br><span class="line">    <span class="type">int</span> count=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="获取值">获取值</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">GetElem</span><span class="params">(LinkList L, <span class="type">int</span> i, <span class="type">int</span> &amp;e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="type">int</span> index=<span class="number">0</span>;</span><br><span class="line">    LinkList p=L-&gt;next;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span> &amp;&amp; index&lt;i)&#123;</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">        index++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(p==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        e = p-&gt;data;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="比较">比较</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Compare</span><span class="params">(<span class="type">int</span> a , <span class="type">int</span> b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a==b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="定位">定位</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">LocateElem</span><span class="params">(LinkList L, <span class="type">int</span> e, <span class="type">bool</span>(Compare)(<span class="type">int</span>, <span class="type">int</span>))</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    LinkList p = L-&gt;next;</span><br><span class="line">    <span class="type">int</span> index = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span> &amp;&amp; !<span class="built_in">Compare</span>(p-&gt;data,e))&#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">        index++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(p==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> index;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="前驱">前驱</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">PriorElem</span><span class="params">(LinkList L, <span class="type">int</span> cur_e,<span class="type">int</span>&amp; pre_e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)<span class="keyword">return</span> ERROR;</span><br><span class="line">    LinkList p = L-&gt;next;</span><br><span class="line">    <span class="comment">//第一个节点没有前驱</span></span><br><span class="line">    <span class="keyword">if</span>(cur_e==p-&gt;data)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">while</span>(p-&gt;next!=<span class="literal">NULL</span> &amp;&amp; p-&gt;next-&gt;data!=cur_e)&#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(p-&gt;next==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">       pre_e =  p-&gt;data;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="后继">后继</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">NextElem</span><span class="params">(LinkList L, <span class="type">int</span> cur_e, <span class="type">int</span>&amp; next_e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)<span class="keyword">return</span> ERROR;</span><br><span class="line">    LinkList p = L-&gt;next;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span> &amp;&amp; p-&gt;data!=cur_e)&#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(p-&gt;next==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        next_e =  p-&gt;next-&gt;data;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="插入">插入</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">ListInsert</span><span class="params">(LinkList L, <span class="type">int</span> i, <span class="type">int</span> e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)<span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="comment">//移动到第i-1个节点 因为要到i-1个节点 当i=0是就要到头节点 所以p一开始只指向头节点</span></span><br><span class="line">    <span class="type">int</span> index =<span class="number">0</span>;</span><br><span class="line">    LinkList p =L;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span> &amp;&amp; index&lt;i)&#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">        index++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//新建一个节点</span></span><br><span class="line">    LNode* newNode = (LNode*) <span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(LNode));</span><br><span class="line">    newNode-&gt;data = e;</span><br><span class="line">    <span class="comment">//进行插入</span></span><br><span class="line">    newNode-&gt;next = p-&gt;next;</span><br><span class="line">    p-&gt;next = newNode;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="删除">删除</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">ListDelete</span><span class="params">(LinkList L, <span class="type">int</span> i, <span class="type">int</span>&amp; e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)<span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="comment">//移动到第i-1个节点 因为要到i-1个节点 当i=0是就要到头节点 所以p一开始只指向头节点</span></span><br><span class="line">    <span class="type">int</span> index =<span class="number">0</span>;</span><br><span class="line">    LinkList p =L;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span> &amp;&amp; index&lt;i)&#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">        index++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//删除节点</span></span><br><span class="line">    LinkList q;</span><br><span class="line">    q = p-&gt;next;</span><br><span class="line">    p-&gt;next = q-&gt;next;</span><br><span class="line">    e = q-&gt;data;</span><br><span class="line">    <span class="built_in">free</span>(q);</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="访问元素">访问元素</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Visit</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;</span><br><span class="line">    cout&lt;&lt;x&lt;&lt;<span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="输出顺序表">输出顺序表</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ListTraverse</span><span class="params">(LinkList L, <span class="type">void</span>(Visit)(<span class="type">int</span>))</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L==<span class="literal">NULL</span>)</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;数据为空&quot;</span>&lt;&lt;endl;</span><br><span class="line">    LinkList p =L-&gt;next;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">        <span class="built_in">Visit</span>(p-&gt;data);</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;<span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sqlist.cpp">1.5 SqList.cpp</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;LinkList.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">const</span> <span class="type">char</span> * argv[])</span> </span>&#123;</span><br><span class="line">    LinkList myList;</span><br><span class="line">    <span class="built_in">InitList</span>(myList);</span><br><span class="line">    <span class="type">int</span> num;</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;输入数据数量:&quot;</span>&lt;&lt;endl;</span><br><span class="line">    cin&gt;&gt;num;</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;输入数据:&quot;</span>&lt;&lt;endl;</span><br><span class="line">    <span class="type">int</span> elem;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span> ; i&lt;num;i++)&#123;</span><br><span class="line">        cin&gt;&gt;elem;</span><br><span class="line">        <span class="built_in">ListInsert</span>(myList, i, elem);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">ListTraverse</span>(myList, Visit);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;长度是:&quot;</span>&lt;&lt;<span class="built_in">ListLength</span>(myList);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;是否为空:&quot;</span>&lt;&lt;<span class="built_in">ListEmpty</span>(myList);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;输入一个想定位的数据:&quot;</span>;</span><br><span class="line">    <span class="type">int</span> data;</span><br><span class="line">    cin&gt;&gt;data;</span><br><span class="line">    cout&lt;&lt;data&lt;&lt;<span class="string">&quot;定位是:&quot;</span>&lt;&lt;<span class="built_in">LocateElem</span>(myList, data, Compare)&lt;&lt;endl;</span><br><span class="line">    <span class="type">int</span> pre_data;</span><br><span class="line">    <span class="built_in">PriorElem</span>(myList, data, pre_data);</span><br><span class="line">    <span class="type">int</span> after_data;</span><br><span class="line">    <span class="built_in">NextElem</span>(myList, data, after_data);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;前驱是:&quot;</span>&lt;&lt;pre_data&lt;&lt;<span class="string">&#x27;\t&#x27;</span>&lt;&lt;<span class="string">&quot;后继是:&quot;</span>&lt;&lt;after_data&lt;&lt;<span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;删除元素&quot;</span>&lt;&lt;endl;</span><br><span class="line">    <span class="type">int</span> deldata;</span><br><span class="line">    <span class="built_in">ListDelete</span>(myList, <span class="number">3</span>, deldata);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;删除的元素是:&quot;</span>&lt;&lt;deldata&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">ListTraverse</span>(myList, Visit);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;线性链表&quot;&gt;线性链表&lt;/h1&gt;
&lt;h3 id=&quot;源代码清单&quot;&gt;1.1源代码清单:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;h5 id=&quot;linklist.cpp&quot;&gt;LinkList.cpp&lt;/h5&gt;&lt;/li&gt;
&lt;li&gt;&lt;h5 id=&quot;linklist.h&quot;&gt;LinkList</summary>
      
    
    
    
    <category term="数据结构" scheme="http://www.larryai.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="C++" scheme="http://www.larryai.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>顺序表</title>
    <link href="http://www.larryai.com/2022/05/04/%E9%A1%BA%E5%BA%8F%E8%A1%A8/"/>
    <id>http://www.larryai.com/2022/05/04/%E9%A1%BA%E5%BA%8F%E8%A1%A8/</id>
    <published>2022-05-04T03:37:36.000Z</published>
    <updated>2022-05-04T07:14:49.099Z</updated>
    
    <content type="html"><![CDATA[<h1 id="顺序表">顺序表</h1><h3 id="源代码清单">1.1源代码清单:</h3><ul><li><h5 id="sqlist.cpp">SqList.cpp</h5></li><li><h5 id="sqlist.h">SqList.h</h5></li></ul><h3 id="顺序表数据结构">1.2顺序表数据结构:</h3><blockquote><p>本程序元素类型为int,读者可根据需求自行更改数据类型。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//线性表结构体</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">    <span class="type">int</span>* elem; <span class="comment">//线性表数据</span></span><br><span class="line">    <span class="type">int</span> length; <span class="comment">//线性表长度</span></span><br><span class="line">    <span class="type">int</span> listSize; <span class="comment">//线性表大小</span></span><br><span class="line">&#125;SqList;</span><br></pre></td></tr></table></figure><h3 id="该顺序表设计到的方法">1.3该顺序表设计到的方法:</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span>  <span class="title">InitList</span><span class="params">(SqList &amp;L)</span></span>; <span class="comment">//初始化线性表</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">DestroyList</span><span class="params">(SqList &amp;L)</span></span>; <span class="comment">//销毁线性表</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">ClearList</span><span class="params">(SqList &amp;L)</span></span>; <span class="comment">//置空线性表</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ListEmpty</span><span class="params">(SqList L)</span></span>; <span class="comment">//判断是否为空</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">ListLength</span><span class="params">(SqList &amp;L)</span></span>; <span class="comment">//线性表长度</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">GetElem</span><span class="params">(SqList L, <span class="type">int</span> i, <span class="type">int</span> &amp;e)</span></span>; <span class="comment">//获取值</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Compare</span><span class="params">(<span class="type">int</span> a , <span class="type">int</span> b)</span></span>; <span class="comment">//比较</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">LocateElem</span><span class="params">(SqList L, <span class="type">int</span> e, <span class="type">bool</span>(Compare)(<span class="type">int</span>, <span class="type">int</span>))</span></span>; <span class="comment">//定位</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">PriorElem</span><span class="params">(SqList L, <span class="type">int</span> cur_e , <span class="type">int</span> &amp;pre_e)</span></span>; <span class="comment">//前驱</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">NestElem</span><span class="params">(SqList L , <span class="type">int</span> cur_e , <span class="type">int</span> &amp;next_e)</span></span>; <span class="comment">//后继</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">InsertList</span><span class="params">(SqList &amp;L,<span class="type">int</span> i ,<span class="type">int</span> elem)</span></span>; <span class="comment">//插入</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">ListDelete</span><span class="params">(SqList &amp;L, <span class="type">int</span> i, <span class="type">int</span> &amp;e)</span></span>; <span class="comment">//删除</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Visit</span><span class="params">(<span class="type">int</span> x)</span></span>; <span class="comment">//访问</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">visitList</span><span class="params">(SqList L,<span class="type">void</span>(Visit)(<span class="type">int</span>))</span></span>; <span class="comment">//输出顺序表</span></span><br></pre></td></tr></table></figure><h3 id="sqlist.h-1">1.4 SqList.h</h3><ul><li><h4 id="宏定义">宏定义</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">/* 状态码 */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TRUE        1   <span class="comment">// 真/是</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> FALSE       0   <span class="comment">// 假/否</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OK          1   <span class="comment">// 通过/成功</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ERROR       0   <span class="comment">// 错误/失败</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//系统中已有此状态码定义，要防止冲突</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> OVERFLOW</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OVERFLOW    -2  <span class="comment">//堆栈上溢</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//线性表的宏定义</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> listInitSize 20</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> listSizeStride 10 <span class="comment">//空间增加的步长</span></span></span><br></pre></td></tr></table></figure><ul><li><h4 id="初始化表">初始化表</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//初始化线性表</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">InitList</span><span class="params">(SqList &amp;L)</span></span>&#123;</span><br><span class="line">    <span class="comment">//给线性表数据部分分配空间</span></span><br><span class="line">    L.elem = (<span class="type">int</span>*)<span class="built_in">malloc</span>(listInitSize * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    <span class="comment">//分配空间失败</span></span><br><span class="line">    <span class="keyword">if</span>(L.elem==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="comment">// 存储内存失败</span></span><br><span class="line">        <span class="built_in">exit</span>(OVERFLOW);</span><br><span class="line">    <span class="comment">//线性表长度</span></span><br><span class="line">    L.length=<span class="number">0</span>;</span><br><span class="line">    <span class="comment">//线性表大小</span></span><br><span class="line">    L.listSize=listInitSize;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="销毁线性表">销毁线性表</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//销毁线性表</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">DestroyList</span><span class="params">(SqList &amp;L)</span></span>&#123;</span><br><span class="line">    <span class="comment">//确保线性表存在</span></span><br><span class="line">    <span class="keyword">if</span>( L.elem == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放内存</span></span><br><span class="line">    <span class="built_in">free</span>(L.elem);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//置空指针</span></span><br><span class="line">    L.elem = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//长度内存的改变</span></span><br><span class="line">    L.length =<span class="number">0</span>;</span><br><span class="line">    L.listSize=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="置空线性表">置空线性表</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">ClearList</span><span class="params">(SqList &amp;L)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line"></span><br><span class="line">    L.length=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="判断是否为空">判断是否为空</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span>  <span class="title">ListEmpty</span><span class="params">(SqList L)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> L.length==<span class="number">0</span>?TRUE:ERROR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="线性表长度">线性表长度</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">ListLength</span><span class="params">(SqList &amp;L)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> L.length;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="获取值">获取值</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">GetElem</span><span class="params">(SqList L, <span class="type">int</span> i, <span class="type">int</span> &amp;e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    e = L.elem[i];</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="比较">比较</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Compare</span><span class="params">(<span class="type">int</span> a , <span class="type">int</span> b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a==b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="定位">定位</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">LocateElem</span><span class="params">(SqList L, <span class="type">int</span> e, <span class="type">bool</span>(Compare)(<span class="type">int</span>, <span class="type">int</span>))</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="comment">//下标</span></span><br><span class="line">    <span class="type">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="comment">//新建指针指向数据域</span></span><br><span class="line">    <span class="type">int</span>* p = L.elem;</span><br><span class="line">    <span class="comment">//遍历</span></span><br><span class="line">    <span class="keyword">while</span>(i&lt;L.length &amp;&amp; !<span class="built_in">Compare</span>(*p++,e))&#123;</span><br><span class="line">        ++i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i&lt;L.length)</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;<span class="comment">//没找到</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="前驱">前驱</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span>  <span class="title">PriorElem</span><span class="params">(SqList L, <span class="type">int</span> cur_e , <span class="type">int</span> &amp;pre_e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="type">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> *p = L.elem;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;L.length &amp;&amp; !<span class="built_in">Compare</span>(*p++, cur_e))&#123;</span><br><span class="line">        ++i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i==<span class="number">0</span>||i&gt;=L.length)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        pre_e = L.elem[i<span class="number">-1</span>];</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="后继">后继</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">NestElem</span><span class="params">(SqList L , <span class="type">int</span> cur_e , <span class="type">int</span> &amp;next_e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="type">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> *p = L.elem;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;L.length &amp;&amp; !<span class="built_in">Compare</span>(*p++, cur_e))&#123;</span><br><span class="line">        ++i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i&gt;=L.length<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        next_e = L.elem[i+<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="插入">插入</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">InsertList</span><span class="params">(SqList &amp;L,<span class="type">int</span> i ,<span class="type">int</span> elem)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="comment">//插入位置是否正确</span></span><br><span class="line">    <span class="keyword">if</span>(i&lt;<span class="number">0</span> || i&gt;L.length)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span>* newbase;<span class="comment">//预计新建空间</span></span><br><span class="line">    <span class="comment">//是否空间不足</span></span><br><span class="line">    <span class="keyword">if</span>(L.length&gt;=L.listSize)&#123;</span><br><span class="line">        newbase = (<span class="type">int</span>*) <span class="built_in">realloc</span>(L.elem, (L.listSize+listSizeStride)*<span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">        <span class="comment">//创建是否成功</span></span><br><span class="line">        <span class="keyword">if</span>(newbase==<span class="literal">NULL</span>)</span><br><span class="line">            <span class="built_in">exit</span>(OVERFLOW);</span><br><span class="line">        L.elem = newbase;</span><br><span class="line">        L.listSize += listSizeStride;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span>*q = &amp;L.elem[i]; <span class="comment">//q指向要插入的位置</span></span><br><span class="line">    <span class="type">int</span>*p = &amp;L.elem[L.length<span class="number">-1</span>]; <span class="comment">//p指向数据尾部位</span></span><br><span class="line">    <span class="comment">//右移元素</span></span><br><span class="line">    <span class="keyword">while</span>(p&gt;=q)&#123;</span><br><span class="line">        *(p+<span class="number">1</span>) = *p;</span><br><span class="line">        p--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//插入元素</span></span><br><span class="line">    *q = elem;</span><br><span class="line">    <span class="comment">//表长加1</span></span><br><span class="line">    L.length++;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="删除">删除</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">ListDelete</span><span class="params">(SqList &amp;L, <span class="type">int</span> i, <span class="type">int</span> &amp;e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="comment">//删除位置是否正确</span></span><br><span class="line">    <span class="keyword">if</span>(i&lt;<span class="number">0</span> || i&gt;L.length)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="type">int</span> *q = &amp;L.elem[i] ;<span class="comment">//指向要被删除的位置</span></span><br><span class="line">    <span class="type">int</span> *p = &amp;L.elem[L.length<span class="number">-1</span>]; <span class="comment">// 指向表尾元素</span></span><br><span class="line">    <span class="comment">//要删除的元素赋值给e</span></span><br><span class="line">    e = *q;</span><br><span class="line">    <span class="keyword">while</span>(q&lt;p)&#123;</span><br><span class="line">        *q = *(q+<span class="number">1</span>);</span><br><span class="line">        q++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//表长减1</span></span><br><span class="line">    L.length--;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="访问元素">访问元素</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Visit</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;</span><br><span class="line">    cout&lt;&lt;x&lt;&lt;<span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><h4 id="输出顺序表">输出顺序表</h4></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">visitList</span><span class="params">(SqList L,<span class="type">void</span>(Visit)(<span class="type">int</span>))</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(L.elem==<span class="literal">NULL</span>)</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;数据为空&quot;</span>&lt;&lt;endl;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;L.length;i++)</span><br><span class="line">        <span class="built_in">Visit</span>(L.elem[i]);</span><br><span class="line">    cout&lt;&lt;<span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sqlist.cpp-1">1.5 SqList.cpp</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;SqList.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">const</span> <span class="type">char</span> * argv[])</span> </span>&#123;</span><br><span class="line">    SqList myList;</span><br><span class="line">    <span class="built_in">InitList</span>(myList);</span><br><span class="line">    <span class="type">int</span> num;</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;输入数据数量:&quot;</span>&lt;&lt;endl;</span><br><span class="line">    cin&gt;&gt;num;</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;输入数据:&quot;</span>&lt;&lt;endl;</span><br><span class="line">    <span class="type">int</span> elem;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span> ; i&lt;num;i++)&#123;</span><br><span class="line">        cin&gt;&gt;elem;</span><br><span class="line">        <span class="built_in">InsertList</span>(myList, i, elem);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">visitList</span>(myList, Visit);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;长度是:&quot;</span>&lt;&lt;<span class="built_in">ListLength</span>(myList);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;是否为空:&quot;</span>&lt;&lt;<span class="built_in">ListEmpty</span>(myList);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;输入一个想定位的数据:&quot;</span>;</span><br><span class="line">    <span class="type">int</span> data;</span><br><span class="line">    cin&gt;&gt;data;</span><br><span class="line">    cout&lt;&lt;data&lt;&lt;<span class="string">&quot;定位是:&quot;</span>&lt;&lt;<span class="built_in">LocateElem</span>(myList, data, Compare)&lt;&lt;endl;</span><br><span class="line">    <span class="type">int</span> pre_data;</span><br><span class="line">    <span class="built_in">PriorElem</span>(myList, data, pre_data);</span><br><span class="line">    <span class="type">int</span> after_data;</span><br><span class="line">    <span class="built_in">NestElem</span>(myList, data, after_data);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;前驱是:&quot;</span>&lt;&lt;pre_data&lt;&lt;<span class="string">&#x27;\t&#x27;</span>&lt;&lt;<span class="string">&quot;后继是:&quot;</span>&lt;&lt;after_data&lt;&lt;<span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;删除元素&quot;</span>&lt;&lt;endl;</span><br><span class="line">    <span class="type">int</span> deldata;</span><br><span class="line">    <span class="built_in">ListDelete</span>(myList, <span class="number">3</span>, deldata);</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;删除的元素是:&quot;</span>&lt;&lt;deldata&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">visitList</span>(myList, Visit);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;顺序表&quot;&gt;顺序表&lt;/h1&gt;
&lt;h3 id=&quot;源代码清单&quot;&gt;1.1源代码清单:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;h5 id=&quot;sqlist.cpp&quot;&gt;SqList.cpp&lt;/h5&gt;&lt;/li&gt;
&lt;li&gt;&lt;h5 id=&quot;sqlist.h&quot;&gt;SqList.h&lt;/h5&gt;&lt;/l</summary>
      
    
    
    
    <category term="数据结构" scheme="http://www.larryai.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="C++" scheme="http://www.larryai.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Perceptual Losses for Real-Time Style Transfer and Super-Resolution</title>
    <link href="http://www.larryai.com/2022/05/04/PLST-SR/"/>
    <id>http://www.larryai.com/2022/05/04/PLST-SR/</id>
    <published>2022-05-03T18:56:42.000Z</published>
    <updated>2022-05-04T07:37:36.967Z</updated>
    
    <content type="html"><![CDATA[<h2 id="网络模型">1.网络模型</h2><p><imgsrc="https://pic4.zhimg.com/v2-8e9936fdcfd4e8371720b9834f8f97d7_r.jpg" /></p><h3 id="组成部分">1.1 组成部分</h3><blockquote><p>网络模型总体分为两部分:Image Transform Net和VGG-16</p></blockquote><ul><li><strong>Image Transform Net</strong>是参数W待训练的网络</li><li><strong>VGG-16</strong>是已经预训练好参数的网络</li></ul><h3 id="工作原理">1.2 工作原理</h3><p><strong>(1) 输入</strong>为 :</p><ul><li>原始图像<span class="math inline">\(x\)</span></li><li>风格目标图<span class="math inline">\(y_s\)</span></li><li>内容目标图<span class="math inline">\(y_c\)</span></li></ul><p><strong>(2) Image Transform Net</strong>作用：</p><ul><li>将原始图像<span class="math inline">\(x\)</span>经过<strong>ImageTransform Net</strong>得到输出图像<spanclass="math inline">\(\hat{y}\)</span></li><li>映射关系为: <span class="math inline">\(\hat{y} =f_W(x)\)</span></li><li>其中W是Images Transform Net的参数 ， x是网络输入，y是网络输出。</li></ul><p><strong>(3) VGG-16</strong>作用：</p><ul><li><p>内容层面</p><blockquote><p>将<span class="math inline">\(\hat{y}\)</span> 与<spanclass="math inline">\(y_c\)</span>在VGG中间层的欧式距离作为Loss训练<strong>图像转换网络</strong></p><p>使得Image Transform Net输出的<spanclass="math inline">\(\hat{y}\)</span>与目标内容图<spanclass="math inline">\(y_c\)</span>越来越接近</p></blockquote></li><li><p>风格层面</p><blockquote><p>将<span class="math inline">\(\hat{y}\)</span> 与<spanclass="math inline">\(y_s\)</span>在VGG多个中间层得到的featuremap生成的Gram矩阵的欧式距离加权和作为Loss训练<strong>图像转换网络</strong></p><p>使得Image Transform Net输出的<spanclass="math inline">\(\hat{y}\)</span>与目标风格图<spanclass="math inline">\(y_s\)</span>越来越接近</p></blockquote></li></ul><h2 id="损失函数">2.损失函数</h2><h3 id="特征内容损失feature-reconstruction-loss">2.1特征内容损失(FeatureReconstruction Loss)</h3><p><span class="math display">\[\ell_{feat}^{\phi , j}(\hat{y},y) = \frac{1}{C_jH_jW_j}\Vert\phi_j(\hat{y})-\phi_j(y)\Vert_2\]</span></p><ul><li>j 表示VGG-16中间层代号</li><li>y表示特征目标图像</li><li><span class="math inline">\(\hat{y}\)</span>表示image transform net输出的图像</li><li><span class="math inline">\(\phi_{j}(y)\)</span>表示图像y在VGG-16中间层j时的输出</li><li><span class="math inline">\(\phi_{j}(\hat{y})\)</span> 表示图像<spanclass="math inline">\(\hat{y}\)</span>在VGG-16中间层j时的输出</li><li><spanclass="math inline">\(C_jH_jW_j\)</span>分别表示在VGG-16中间层j时的通道数、高度、宽度</li></ul><blockquote><p><strong>Feature Reconstruction Loss</strong>这数学公式就可以理解为两个图像在VGG-16中间层j的欧氏距离</p><p>越小说明VGG-16网络认为这两张图越接近</p></blockquote><h3 id="风格损失style-reconstruction-loss">2.2风格损失(<strong>StyleReconstruction Loss</strong>)</h3><ul><li><strong>Gram特征矩阵中的元素</strong> <span class="math display">\[G_{j}^{\phi}(x)_{c,c^{&#39;}} = \frac{1}{C_jH_jW_j} \sum_{h=1}^{H_j}\sum_{w=1}^{W_j}\phi_j(x)_{h,w,c}\phi_{j}(x)_{h,w,c^{&#39;}}\]</span></li></ul><blockquote><p>VGG中间层j的<strong>feature map</strong>大小为[<spanclass="math inline">\(C_j\)</span>,<spanclass="math inline">\(H_j\)</span>,<spanclass="math inline">\(W_j\)</span>]</p><p>我们经过<strong>flatten</strong>和<strong>矩阵转置</strong>操作可以变形为[<spanclass="math inline">\(C_j\)</span> , <spanclass="math inline">\(H_j*W_j\)</span>]和的[<spanclass="math inline">\(H_j*W_j\)</span> , <spanclass="math inline">\(C_j\)</span>]矩阵</p><p>再对两个作<strong>内积</strong>得到Gram Matrices大小为[<spanclass="math inline">\(C_j,C_j\)</span>]</p></blockquote><ul><li><strong>中间层j的风格损失</strong></li></ul><p><span class="math display">\[\ell_{style}^{\phi,j}(\hat{y},y) =\Vert G_j^{\phi}(\hat{y}) -G_j^{\phi}(y)\Vert_{F}^{2}\]</span></p><blockquote><p>计算图像<span class="math inline">\(y\)</span>和图像<spanclass="math inline">\(\hat{y}\)</span>两者VGG-16中间层j中gram矩阵距离的平方和</p></blockquote><h3 id="简单损失函数">2.3简单损失函数</h3><ul><li><p><strong>像素损失</strong></p><p>像素损失是输出图和目标图之间标准化的差距 <spanclass="math display">\[\ell_{pixel}({\hat{y},y}) = \frac{1}{CHW}\Vert \hat{y}-y\Vert_2^2\]</span></p></li><li><p><strong>全变差正则化</strong></p></li></ul><p>​为使得输出图像比较平滑，遵循了前人在特征反演上的研究，在超分辨率重建上使用了全变差正则化<spanclass="math inline">\(\ell_{TV}(\hat{y})\)</span></p><h2 id="image-transform-net细节">3.Image Transform Net细节</h2><h3 id="风格迁移">3.1 风格迁移</h3><table><thead><tr class="header"><th style="text-align: center;">Layer</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">9x9 conv , stride=2</td></tr><tr class="even"><td style="text-align: center;">3x3 conv , stride=2</td></tr><tr class="odd"><td style="text-align: center;">Residual blocks</td></tr><tr class="even"><td style="text-align: center;">Residual blocks</td></tr><tr class="odd"><td style="text-align: center;">...</td></tr><tr class="even"><td style="text-align: center;">Residual blocks</td></tr><tr class="odd"><td style="text-align: center;">3x3 conv , stride=<spanclass="math inline">\(\frac{1}{2}\)</span></td></tr><tr class="even"><td style="text-align: center;">9x9 conv , stride=<spanclass="math inline">\(\frac{1}{2}\)</span></td></tr></tbody></table><p><strong>具体解释</strong></p><blockquote><p>1.输入<span class="math inline">\(x\)</span> 大小为3x256x256</p><p>2.使用2层 stride=2 的卷积层进行<strong>下采样</strong></p><p>3.使用5个残差模块</p><p>4.使用2层stride=<spanclass="math inline">\(\frac{1}{2}\)</span>的卷积层进行<strong>上采样</strong></p><p>5.输出<span class="math inline">\(\hat{y}\)</span>大小为3x256x256</p></blockquote><p><strong>输入图像与输出图像大小相同先下采样再上采样的好处</strong></p><ul><li><strong><em>可计算复杂性</em></strong><ul><li>比较</li><li>3x3的C个卷积核 在CxHxW的图像上 需要 <spanclass="math inline">\(9C^2HW\)</span></li><li>3x3的DC个卷积核 在DC x <spanclass="math inline">\(\frac{H}{D}\)</span>x<spanclass="math inline">\(\frac{W}{D}\)</span> 的图像上 也需要<spanclass="math inline">\(9C^2HW\)</span></li><li>在下采样之后，我们可以使用一个<strong>更大的网络来获得相同的计算成本</strong></li></ul></li><li><strong><em>有效的感受野大小</em></strong><ul><li>优势就在于在输出中的每个像素都有输入中的<strong>大面积有效的感受野</strong></li><li>一个附加的3x3卷积层都能把感受野的大小<strong>增加2倍</strong></li><li>在用因子D进行下采样后，每个3x3的卷积增加<strong>感受野的大小到2D</strong></li><li>下采样使得相同数量的层<strong>给出了更大的感受野大小</strong></li></ul></li></ul><h3 id="超分辨率">3.2超分辨率</h3><p>假设<strong>上采样因子</strong>为<spanclass="math inline">\(f\)</span></p><table><thead><tr class="header"><th style="text-align: center;">Layer</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Residual blocks</td></tr><tr class="even"><td style="text-align: center;">Residual blocks</td></tr><tr class="odd"><td style="text-align: center;">...</td></tr><tr class="even"><td style="text-align: center;">Residual blocks</td></tr><tr class="odd"><td style="text-align: center;">3x3 conv , stride=<spanclass="math inline">\(\frac{1}{2}\)</span></td></tr><tr class="even"><td style="text-align: center;">3x3 conv , stride=<spanclass="math inline">\(\frac{1}{2}\)</span></td></tr><tr class="odd"><td style="text-align: center;">(<spanclass="math inline">\(一共使用\log_2{f}个conv\)</span>)</td></tr><tr class="even"><td style="text-align: center;">9x9 conv , stride=<spanclass="math inline">\(\frac{1}{2}\)</span></td></tr></tbody></table><p><strong>具体解释</strong></p><blockquote><p>1.输入<span class="math inline">\(x\)</span> 大小为3 x <spanclass="math inline">\(\frac{288}{f}\)</span> x <spanclass="math inline">\(\frac{288}{f}\)</span></p><p>2.使用 <strong>5</strong>个残差模块</p><p>3.使用_2{f}个stride=<spanclass="math inline">\(\frac{1}{2}\)</span>的卷积层进行<strong>上采样</strong></p><p>5.输出<span class="math inline">\(\hat{y}\)</span>大小为3x288x288</p></blockquote><h3 id="残差连接">3.3 残差连接</h3><p><imgsrc="https://pic2.zhimg.com/80/v2-c7677c713fa2df00682e864f41d581e9_720w.png" /></p><h3 id="其他细节">3.4其他细节</h3><ul><li>除开<strong>第一个和最后一个</strong>层用<strong>9x9</strong>的kernel其他所有卷积层都用<strong>3x3</strong>的kernels</li><li>优化方法选的是SGD（随机梯度下降法）</li><li>除去最后一层卷积层后连接Tanh激活层，其他非残差卷积层都连接BatchNorm归一层和ReLu激活层</li><li>上面的做法可以使得输出图像的像素值在 [0<em>,</em> 255]这个范围</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;网络模型&quot;&gt;1.网络模型&lt;/h2&gt;
&lt;p&gt;&lt;img
src=&quot;https://pic4.zhimg.com/v2-8e9936fdcfd4e8371720b9834f8f97d7_r.jpg&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;组成部分&quot;&gt;1.1 组成部分&lt;/h3&gt;
</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="风格迁移" scheme="http://www.larryai.com/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"/>
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="超分重建" scheme="http://www.larryai.com/tags/%E8%B6%85%E5%88%86%E9%87%8D%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Image Style Transfer</title>
    <link href="http://www.larryai.com/2022/05/04/Image%20Style%20Transfer/"/>
    <id>http://www.larryai.com/2022/05/04/Image%20Style%20Transfer/</id>
    <published>2022-05-03T18:54:56.000Z</published>
    <updated>2022-05-16T04:23:29.926Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图像风格迁移">图像风格迁移</h1><p><img src="fig1.png" /></p><h2 id="损失函数组成">损失函数组成</h2><blockquote><h4 id="loss-w1-lc-w2-ls">Loss = w1 * Lc + w2 * Ls</h4></blockquote><ul><li><h3 id="loss-of-contentlc"><strong>Loss ofcontent(Lc)</strong></h3></li><li><h3 id="loss-of-stylels"><strong>Loss ofstyle(Ls)</strong></h3></li></ul><h2 id="loss-of-content">Loss of content</h2><blockquote><p>内容图和随机噪声图经过多次卷积滤波后，conten和noise在第4层的featuremap的距离的平方和</p></blockquote><p><span class="math display">\[mathcal{L}_{\text {content }}(\vec{p}, \vec{x}, l)=\frac{1}{2} \sum_{i,j}\left(F_{i j}^{l}-P_{i j}^{l}\right)^{2}\]</span></p><h2 id="loss-of-style">Loss of style</h2><blockquote><p>先对风格图和噪声图的每一层卷积得到feature map</p><p>对feature map求gram矩阵</p><p>计算两者gram距离的平方和</p><p>将5层的结果加权求和</p></blockquote><p><span class="math display">\[G_{i j}^{l}=\sum_{k} F_{i k}^{l} F_{j k}^{l}\]</span></p><h2 id="实验图">实验图</h2><p><img src="fig4.png" /></p><blockquote><p>随着卷积网络层数增加，获得的特征映射更加抽象。</p><p>上图可以看出，层数增高的时候：</p><ul><li><p>内容<strong>重构图可变化性</strong>增加，具有更大的风格变化能力。</p></li><li><p>风格随着使用的层数越多，<strong>风格迁移的稳定性越强</strong>。</p></li></ul></blockquote><h2 id="gram矩阵">Gram矩阵</h2><h3 id="定义">定义</h3><blockquote><p>n维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的<strong>格拉姆矩阵<em>(Grammatrix)</em></strong>，很明显，这是一个对称矩阵。</p></blockquote><p><span class="math display">\[\Delta\left(\alpha_{1}, \alpha_{2}, \ldots,\alpha_{k}\right)=\left(\begin{array}{cccc}\left(\alpha_{1},\alpha_{1}\right) &amp; \left(\alpha_{1}, \alpha_{2}\right) &amp; \ldots&amp; \left(\alpha_{1}, \alpha_{k}\right) \\ \left(\alpha_{2},\alpha_{1}\right) &amp; \left(\alpha_{2}, \alpha_{2}\right) &amp; \ldots&amp; \left(\alpha_{2}, \alpha_{k}\right) \\ \ldots &amp; \ldots &amp;\ldots &amp; \ldots \\ \left(\alpha_{k}, \alpha_{1}\right) &amp;\left(\alpha_{k}, \alpha_{2}\right) &amp; \ldots &amp; \left(\alpha_{k},\alpha_{k}\right)\end{array}\right)\]</span></p><p><img src="fig7.png" /></p><h3 id="计算">计算</h3><blockquote><p>输入图像的feature map为<strong>[ ch, h, w]</strong>。</p><p>我们经过<strong>flatten</strong>和<strong>矩阵转置</strong>操作</p><p>可以变形为<strong>[ ch, h*w]</strong>和<strong>[ h*w,ch]</strong>的矩阵</p><p>再对两个作<strong>内积</strong>得到Gram Matrices</p></blockquote><h3 id="理解">理解</h3><blockquote><p>格拉姆矩阵可以看做feature之间的偏心协方差矩阵（即没有减去均值的协方差矩阵）</p><p>在featuremap中，每个数字都来自于一个特定滤波器在特定位置的卷积，因此<strong>每个数字代表一个特征的强度</strong></p><p>Gram计算的实际上是<strong>两两特征之间的相关性</strong>，哪两个特征是同时出现的，哪两个是此消彼长的等等。</p><p>因为为乘法操作 两两特征同时为高 结果才高</p></blockquote><blockquote><p>格拉姆矩阵用于度量<strong>各个维度自己的特性</strong>以及<strong>各个维度之间的关系</strong></p><p>内积之后得到的多尺度矩阵中:</p><ul><li><p>对角线元素提供了<strong>不同特征图各自的信息</strong></p></li><li><p>其余元素提供了<strong>不同特征图之间的相关信息</strong>。这样一个矩阵，既能体现出有哪些特征，又能体现出不同特征间的紧密程度</p></li></ul></blockquote><blockquote><p>gram矩阵是计算每个通道 i 的feature map与每个通道 j 的featuremap的内积</p><p>gram matrix的每个值可以说是代表 <strong>I 通道的feature map与 j通道的feature map的互相关程度</strong></p></blockquote><h2 id="参考链接">参考链接</h2><ul><li>https://www.cnblogs.com/yifanrensheng/p/12862174.html</li><li>https://blog.csdn.net/weixin_40759186/article/details/87804316</li><li>https://www.cnblogs.com/subic/p/8110478.html</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;图像风格迁移&quot;&gt;图像风格迁移&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;fig1.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;损失函数组成&quot;&gt;损失函数组成&lt;/h2&gt;
&lt;blockquote&gt;
&lt;h4 id=&quot;loss-w1-lc-w2-ls&quot;&gt;Loss = w1 * Lc </summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="风格迁移" scheme="http://www.larryai.com/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"/>
    
    <category term="cs.CV" scheme="http://www.larryai.com/tags/cs-CV/"/>
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Transformer</title>
    <link href="http://www.larryai.com/2022/05/04/transformer/"/>
    <id>http://www.larryai.com/2022/05/04/transformer/</id>
    <published>2022-05-03T18:42:20.000Z</published>
    <updated>2022-05-16T04:19:09.100Z</updated>
    
    <content type="html"><![CDATA[<h1 id="abstract">Abstract</h1><p>主要的序列转导模型基于复杂的循环或卷积神经网络，包括编码器和解码器。</p><p>性能最好的模型还通过注意力机制连接编码器和解码器。</p><p>我们提出了一种新的简单网络架构 <strong>Transformer</strong></p><p><strong>它完全基于注意力机制，完全摒弃了递归和卷积</strong></p><p>对两个机器翻译任务的实验表明，这些模型在质量上更优越，同时更可并行化，并且需要的训练时间显着减少。</p><ul><li>我们的模型在 WMT 2014 英德翻译任务上达到了 28.4BLEU，比现有的最佳结果（包括合奏）提高了 2 BLEU 以上。</li><li>在 WMT 2014 英语到法语翻译任务中，我们的模型在 8 个 GPU 上训练 3.5天后，建立了一个新的单模型 state-of-the-art BLEU 得分41.0，这是最好的训练成本的一小部分 文献中的模型。</li></ul><h1 id="introduction">1.Introduction</h1><p>循环神经网络(RNN)、长短期记忆(LSTM)和门控循环神经网络，尤其是在语言建模和机器翻译等序列建模和转导问题已被牢固确立为最先进的方法此后，许多努力继续推动循环语言模型和编码器-解码器架构的界限</p><p>循环模型通常沿输入和输出序列的符号位置考虑计算。</p><p>将位置与计算时间的步骤对齐，它们生成一系列隐藏状态ht，作为先前隐藏状态 ht-1 和位置 t 的输入的函数。</p><p>这种固有的顺序性质排除了训练示例中的并行化，这在更长的序列长度下变得至关重要，因为内存限制限制了示例之间的批处理。</p><p>最近的工作通过因式分解技巧 和条件计算显着提高了计算效率，同时在后者的情况下也提高了模型性能。</p><p>然而，顺序计算的基本约束仍然存在。</p><p>注意机制已成为各种任务中引人注目的序列建模和转导模型的组成部分，允许对依赖项进行建模，而无需考虑它们在输入或输出序列中的距离</p><p>然而，除了少数情况，这种注意力机制与循环网络结合使用。</p><p>在这项工作中，我们提出了<strong>Transformer，这是一种避免重复的模型架构，而是完全依赖注意力机制来绘制输入和输出之间的全局依赖关系</strong></p><p>在八个 P100 GPU 上经过短短 12 小时的训练后，Transformer可以实现更多的并行化，并且可以在翻译质量方面达到新的水平</p><h1 id="background">2.Background</h1><p>减少顺序计算的目标也构成了扩展神经 GPU 、ByteNet 和 ConvS2S的基础，所有这些都使用卷积神经网络作为基本构建块，并行计算所有输入的隐藏表示和输出位置。</p><p>在这些模型中，关联来自两个任意输入或输出位置的信号所需的操作数量随着位置之间的距离而增长</p><p>对于 ConvS2S 呈线性增长，而对于 ByteNet 则呈对数增长。</p><p>这使得学习远距离位置之间的依赖关系变得更加困难</p><p>在 Transformer中，这被减少到恒定数量的操作，尽管由于平均注意力加权位置而降低了有效分辨率，我们使用<strong>多头注意力(Multi-HeadAttention)</strong>来抵消这种影响</p><p><strong>自注意力(Self-attention)</strong>，有时称为内部注意力，是一种将单个序列的不同位置关联起来以计算序列表示的注意力机制</p><p>自注意力已成功用于各种任务，包括阅读理解、抽象摘要、文本蕴涵和学习任务无关的句子表示</p><p><strong>端到端记忆网络(End-to-end memorynetwork)</strong>基于循环注意机制而不是序列对齐循环，并且已被证明在简单语言问答和语言建模任务中表现良好</p><p>然而，据我们所知</p><p><strong>Transformer是第一个完全依赖自注意力来计算其输入和输出表示而不使用序列对齐 RNN或卷积的转换模型</strong></p><p>在接下来的部分中，我们将描述Transformer，激发自注意力并讨论其相对于其他模型的优势</p><h1 id="model-architecture">3.Model Architecture</h1><p>大多数竞争性神经序列转导模型具有编码器-解码器结构</p><p>编码器将符号表示的输入序列 (x1, ..., xn) 映射到连续表示的序列 z =(z1, ..., zn)</p><blockquote><p>其中z1是一个向量 用一个向量来表示x1</p></blockquote><p>给定 z，解码器然后一次生成一个元素的符号输出序列 (y1, ..., ym)</p><p>在每个步骤中，模型都是自回归(auto-regressive)的,<strong><em>在生成下一个时将先前生成的符号用作附加输入</em></strong></p><p>Transformer遵循这种整体架构，对编码器和解码器使用堆叠的自注意力(self-attention)和point-wise</p><p>编码器和解码器的全连接层，分别如图 1 的左半部分和右半部分所示</p><p><img src="fig1.png" alt="结构图" style="zoom:100%;" /></p><h2 id="encoder-and-decoder-stacks">3.1Encoder and Decoder Stacks</h2><h4 id="encoder">3.1.1Encoder</h4><p>编码器由 N = 6 个相同的层组成 , 每层有两个子层</p><ul><li><p>第一个子层是 <strong>多头自注意力机制(multi-head self-attentionmechanism)</strong></p></li><li><p>第二个子层是simple, position-wise fully connected feed-forwardnetwork.（说简单点就是<strong>MLP</strong>）</p></li></ul><p>我们在两个子层中的每一个周围使用残差连接，然后进行层归一化</p><p>即每个子层的输出为<strong>LayerNorm(x + Sublayer(x))</strong></p><p>其中Sublayer(x)是子层自己实现的函数</p><p>为了促进这些残差连接，模型中的所有子层以及嵌入层都会产生维度 dmodel =512 的输出</p><blockquote><p>LayerNorm的细节可以参考下面链接</p><p>https://blog.csdn.net/jump882/article/details/119795466</p></blockquote><h4 id="decoder">3.1.1Decoder</h4><p>解码器也由一堆 N = 6 个相同的层组成。</p><p>除了每个编码器层中的两个子层之外，解码器还插入了第三个子层</p><p>该子层对编码器堆栈的输出执行多头注意力（multi-head attention）</p><p>与编码器类似，我们在每个子层周围使用残差连接，然后进行层归一化</p><p>我们还修改了解码器堆栈中的自注意力子层，以<strong>防止位置关注后续位置</strong></p><p><strong>这种掩蔽与输出嵌入偏移一个位置的事实相结合，确保对位置 i的预测只能依赖于位置小于 i 的已知输出</strong></p><h2 id="attention">3.2Attention</h2><p>注意力函数可以描述为将aquery(查询)和一组key-value键值对映射到输出</p><p>其中<strong>查询query</strong>、<strong>键key</strong>、<strong>值value</strong>和<strong>输出</strong>都是向量</p><p><strong>输出可以理解为计算值value的加权和所得</strong></p><p>其中<strong>分配给每个value的权重weight由查询query与相应键key的相似度函数计算</strong></p><p>下面给了一张参考图</p><p><img src="attention1.png" /></p><h4 id="scaled-dot-product-attention">3.2.1 Scaled Dot-ProductAttention</h4><p><img src="fig2_left.png" /></p><p>我们将我们的particular attention称为“Scaled Dot-ProductAttention”</p><p>输入由维度 dk 的query和key以及维度 dv 的value组成</p><p><strong>我们计算的query和所有keys的点积，将每个key除以 <spanclass="math inline">\(\sqrt{d_k}\)</span>，然后应用 softmax函数来获得value的权重</strong></p><p>在实践中，我们同时计算一组querys的注意力函数，并打包到矩阵 Q 中</p><p>key和value也打包到矩阵 K 和 V 中</p><p>我们将输出矩阵计算为： <span class="math display">\[Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\]</span> 下面给了一张参考图 当m=1时就跟单独运算一样</p><p><img src="attention2.png" /></p><p>两个最常用的注意功能是</p><ul><li><p>加性注意 （additive attention ）</p></li><li><p>点积（乘法）注意（dot-product (multiplicative)attention）</p></li></ul><p>点积注意力与我们的算法相同，除了 <spanclass="math inline">\(\sqrt{d_k}\)</span> 的比例因子</p><p>Additive attention使用具有单个隐藏层的前馈网络计算兼容性函数</p><p>虽然两者在理论上的复杂性相似，但<strong>点积注意力在实践中更快且更节省空</strong>间，因为它可以使用高度优化的矩阵乘法代码来实现</p><p>虽然对于较小的 dk值，这两种机制的性能相似，但加法注意力优于点积注意力，而无需对较大的 dk值进行缩放</p><p>我们怀疑对于较大的 dk 值，点积的幅度会变大，从而将 softmax函数推入具有极小梯度的区域</p><p>为了抵消这种影响，我们将点积缩放<spanclass="math inline">\(\sqrt{d_k}\)</span></p><blockquote><p>注意Mask部分具体操作就是将qt之后的值给换成一个非常大的负数，在后续的softmax时候就会变成0</p><p>使得计算结果只用到了v1到vt-1的结果</p></blockquote><h4 id="multi-head-attention">3.2.2 Multi-Head Attention</h4><p><img src="fig2_right.png" /></p><p>与使用 dmodel维度的key、value和query执行单个注意函数不同</p><p>我们发现将查询、键和值分别线性投影到 dk、dk 和 dv维度上的不同学习线性投影是有益的（投影到低维度）</p><blockquote><p>相当于给h次机会 希望能够学到不一样的投影的方式</p><p>使得在投影进去的度量空间里面 能够去匹配不同模式的相似函数</p><p>类似卷积神经网络中有多个输出通道的感觉</p></blockquote><p>然后，在每个查询、键和值的投影版本上，我们并行执行 Scaled Dot-ProductAttention，产生 dv 维输出值。</p><p>这些被连接cat起来并再次投影，产生最终值</p><p>Multi-HeadAttention允许模型共同关注来自不同位置的不同表示子空间的信息</p><p>对于单个注意力头，平均化会抑制这一点</p><p><span class="math inline">\(\operatorname{MultiHead}(Q, K,V)=\operatorname{Concat}\left(\operatorname{head}_{1},\ldots\right.\)</span>, head <spanclass="math inline">\(\left._{\mathrm{h}}\right) W^{O}\)</span> <spanclass="math display">\[\text { where head } \text { h}_{\mathrm{i}}=\operatorname{Attention}\left(Q W_{i}^{Q}, K W_{i}^{K}, VW_{i}^{V}\right)\]</span></p><ul><li><p>Q 矩阵从[m,dmodel] 降维到[m , dk] 那么<spanclass="math inline">\(W_i^Q \in \mathbb{R}^{d_{model}\timesd_k}\)</span></p></li><li><p>K 矩阵从[n,dmodel] 降维到[n , dk] 那么<spanclass="math inline">\(W_i^K \in \mathbb{R}^{d_{model}\timesd_k}\)</span></p></li><li><p>V 矩阵从[n,dmodel] 降维到[n , dv] 那么<spanclass="math inline">\(W_i^V \in \mathbb{R}^{d_{model}\timesd_v}\)</span></p></li></ul><p>在这项工作中，我们使用 h = 8 个并行注意力层或头</p><p>对于其中的每一个，我们使用 dk = dv = dmodel/h = 64</p><p>由于每个头的维度减少，总计算成本类似于具有全维度的单头注意力</p><h4 id="applications-of-attention-in-our-model">3.2.3 Applications ofAttention in our Model</h4><p>Transformer 以三种不同的方式使用多头注意力：</p><ul><li>在“编码器-解码器注意力”层中，query来自前一个解码器层，记忆key和value来自编码器的输出。这允许解码器中的每个位置参与输入序列中的所有位置。这模仿了序列到序列模型中典型的编码器-解码器注意机制</li><li>编码器包含自注意力层在自注意力层中，所有的键、值和查询都来自同一个地方，在这种情况下，是编码器中前一层的输出。编码器中的每个位置都可以关注编码器上一层中的所有位置。</li><li>类似地，解码器中的自注意力层允许解码器中的每个位置关注解码器中直到并包括该位置的所有位置。我们需要防止解码器中的信息向左流动，以保持自回归特性。我们通过屏蔽掉（设置为 -∞）softmax输入中与非法连接相对应的所有值来实现缩放点积注意力的内部</li></ul><h2 id="position-wise-feed-forward-networks">3.3Position-wiseFeed-Forward Networks</h2><p>除了注意力子层之外，我们的编码器和解码器中的每一层都包含一个完全连接的前馈网络，该网络分别且相同地应用于每个位置。这包括两个线性变换，中间有一个 ReLU 激活。 <span class="math display">\[FFN(x) = max(0,xW_1 + b_1 )W_2 + b_2\]</span></p><blockquote><p>输入层 - 隐藏层 - 输出层</p><p>输入( n , dmodel = 512 )</p><p>隐藏层( n , dmodel*4 = 2048)</p><p>输出层（n ， dmodel = 512）</p></blockquote><p>虽然线性变换在不同位置上是相同的，但它们在层与层之间使用不同的参数。另</p><p>一种描述方式是内核大小为 1 的两个卷积</p><p>输入和输出的维度为 dmodel = 512，内层的维度为 dff = 2048</p><h2 id="embeddings-and-softmax">3.4 Embeddings and Softmax</h2><p>与其他序列转导模型类似，我们<strong>使用learnedembedding将输入标记和输出标记转换为维度 dmodel 的向量</strong></p><p>我们还使用通常的学习线性变换和 softmax函数将解码器输出转换为预测的下一个token概率</p><p>在我们的模型中，我们在两个embedding和 pre-softmax线性变换之间共享相同的权重矩阵</p><p>在embedding中，我们将这些权重乘以 <spanclass="math inline">\(\sqrt{d_{model}}\)</span></p><h2 id="positional-encoding">3.5 Positional Encoding</h2><p>由于我们的模型不包含递归和卷积，为了让模型利用序列的顺序，我们必须注入一些关于标记在序列中的相对或绝对位置的信息</p><p>为此，我们在输入嵌入编码器和解码器堆栈的底部中添加“位置编码”</p><p>位置编码与嵌入具有相同的维度 dmodel，因此可以将两者相加</p><p>位置编码有很多选择，学习的和固定的</p><p>在这项工作中，我们使用不同频率的正弦和余弦函数： <spanclass="math display">\[PE(pos,2i) = sin(pos/1000^{2i/d_{model}})\]</span></p><p><span class="math display">\[PE(pos,2i+1) = cos(pos/1000^{2i/d_{model}})\]</span></p><ul><li>pos 是位置</li><li>i 是维度</li></ul><p>也就是说，位置编码的每个维度对应一个正弦曲线。</p><p>波长形成从 2π 到 10000 · 2π 的几何级数</p><p>我们选择这个函数是因为我们假设它可以让模型轻松学习通过相对位置来参与，因为对于任何固定的偏移量k</p><p><span class="math inline">\(PE_{pos+k}\)</span>可以表示为 <spanclass="math inline">\(PE_{pos}\)</span> 的线性函数</p><p>我们还尝试使用学习的位置嵌入 , 发现这两个版本产生了几乎相同的结果</p><p>我们选择了正弦版本，因为它可以让模型推断出比训练期间遇到的序列长度更长的序列长度</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;主要的序列转导模型基于复杂的循环或卷积神经网络，包括编码器和解码器。&lt;/p&gt;
&lt;p&gt;性能最好的模型还通过注意力机制连接编码器和解码器。&lt;/p&gt;
&lt;p&gt;我们提出了一种新的简单网络架构 &lt;strong&gt;Transf</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://www.larryai.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="深度学习" scheme="http://www.larryai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Transformer" scheme="http://www.larryai.com/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>Shell变量</title>
    <link href="http://www.larryai.com/2021/06/08/Shell%E5%8F%98%E9%87%8F/"/>
    <id>http://www.larryai.com/2021/06/08/Shell%E5%8F%98%E9%87%8F/</id>
    <published>2021-06-08T15:21:56.000Z</published>
    <updated>2022-06-09T05:02:19.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="变量">变量</h2><h4 id="概念">2.1 概念</h4><p>Shell变量就是计算机中用于记录一个值（不一定是数值，也可以是字符或字符串）的符号，而这些符号将用于不同的运算处理中。通常变量与值是一对一的关系，可以通过表达式读取它的值并赋值给其它变量，也可以直接指定数值赋值给任意变量。为了便于运算和处理，大部分的编程语言会区分变量的类型，用于分别记录数值、字符或者字符串等等数据类型。Shell中的变量也基本如此，有不同类型（但不用专门指定类型名），可以参与运算，有作用域限定。</p><blockquote><p>变量的作用域即变量的有效范围（比如一个函数中、一个源文件中或者全局范围），在该范围内只能有一个同名变量。一旦离开则该变量无效，如同不存在这个变量一般。</p></blockquote><h4 id="变量声明">2.2 变量声明</h4><p>这里简单举例说明在 Shell 中如何创建一个变量：</p><p>使用 <code>declare</code> 命令创建一个变量名为 <code>tmp</code>的变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">declare</span> tmp</span><br></pre></td></tr></table></figure><blockquote><p>其实也可以不用 declare 预声明一个变量，直接即用即创建，这里只是告诉你declare 的作用，这在创建其它指定类型的变量（如数组）时会用到。</p></blockquote><h4 id="变量名">2.3 变量名</h4><p>变量名的命名须遵循如下规则：</p><ul><li>首个字符必须为字母（a-z，A-Z）。</li><li>中间不能有空格，可以使用下划线（_）。</li><li>不能使用标点符号。</li><li>不能使用 bash 里的关键字（可用 help 命令查看保留关键字）。</li></ul><h4 id="变量赋值">2.4 变量赋值</h4><p>变量赋值时，变量名不加美元符号（$，PHP 语言中变量需要）。</p><p>使用 <code>=</code> 号赋值运算符，将变量 <code>tmp</code> 赋值为<code>shiyanlou</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正确的赋值</span></span><br><span class="line">$ tmp=shiyanlou</span><br><span class="line"></span><br><span class="line"><span class="comment"># 错误的赋值</span></span><br><span class="line">$ tmp = shiyanlou</span><br></pre></td></tr></table></figure><p><strong>注意:变量名和等号之间不能有空格。</strong></p><p>除了直接赋值，还可以用语句给变量赋值，如 <code>for</code>循环中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> `<span class="built_in">ls</span> /etc`</span><br></pre></td></tr></table></figure><h4 id="变量取值">2.5 变量取值</h4><p><strong>变量的名字</strong>就是变量保存值的地方。引用变量的值就叫做<strong>变量取值</strong>。</p><p>如果 <code>variable</code> 是一个变量的名字，那么<code>$variable</code>就是引用这个变量的值，即这变量所包含的数据。</p><p><code>$variable</code> 事实上只是 <code>$&#123;variable&#125;</code>的简写形式。在某些上下文中 <code>$variable</code>可能会引起错误，这时候你就需要用 <code>$&#123;variable&#125;</code> 了。</p><p>读取变量的值，使用 <code>echo</code> 命令和 <code>$</code>符号（<strong>$符号用于表示引用一个变量的值，初学者经常忘记输入</strong>）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$tmp</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">myname=<span class="string">&quot;shiyanlou&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$myname</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;myname&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;myname&#125;</span>Good</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$mynameGood</span></span><br><span class="line"></span><br><span class="line">myname=<span class="string">&quot;miao&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;myname&#125;</span></span><br></pre></td></tr></table></figure><p>加花括号帮助解释器识别变量的边界，若不加，解释器会把<code>mynameGood</code>当成一个变量（值为空）。推荐给所有变量加花括号</p><h4 id="只读变量">3.1 只读变量</h4><p>使用 <code>readonly</code>命令可以将变量定义为只读变量，只读变量的值不能被改变。下面的例子尝试更改只读变量，结果报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">myUrl=<span class="string">&quot;http://www.shiyanlou.com&quot;</span></span><br><span class="line"><span class="built_in">readonly</span> myUrl</span><br><span class="line">myUrl=<span class="string">&quot;http://www.shiyanlou.com&quot;</span></span><br></pre></td></tr></table></figure><h2 id="环境变量">环境变量</h2><h4 id="简介">4.1 简介</h4><p><strong>环境变量的作用域比自定义变量的要大</strong>，如 Shell的环境变量作用于自身和它的子进程。</p><p>在所有的 UNIX 和类 UNIX系统中，<strong>每个进程都有其各自的环境变量设置</strong>，且默认情况下，当一个进程被创建时，除了创建过程中明确指定的话，它将<strong>继承其父进程的绝大部分环境设置</strong>。</p><p>Shell 程序也作为一个进程运行在操作系统之上，而我们在 Shell中运行的大部分命令都将以 Shell 的子进程的方式运行</p><figure><img src="5-2.png" alt="5-2" /><figcaption aria-hidden="true">5-2</figcaption></figure><p>通常我们会涉及到的变量类型有三种：</p><ul><li>当前 Shell 进程私有用户自定义变量，如上面我们创建的 tmp变量，只在当前 Shell 中有效。</li><li>Shell 本身内建的变量。</li><li>从自定义变量导出的环境变量。</li></ul><p>也有三个与上述三种环境变量相关的命令：<code>set</code>，<code>env</code>，<code>export</code>。这三个命令很相似，都是用于打印环境变量信息，区别在于涉及的变量范围不同。详见下表：</p><table><colgroup><col style="width: 11%" /><col style="width: 88%" /></colgroup><thead><tr class="header"><th style="text-align: center;">命 令</th><th>说 明</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><code>set</code></td><td>显示当前 Shell 所有变量，包括其内建环境变量（与 Shell外观等相关），用户自定义变量及导出的环境变量。</td></tr><tr class="even"><td style="text-align: center;"><code>env</code></td><td>显示与当前用户相关的环境变量，还可以让命令在指定环境中运行。</td></tr><tr class="odd"><td style="text-align: center;"><code>export</code></td><td>显示从 Shell中导出成环境变量的变量，也能通过它将自定义变量导出为环境变量。</td></tr></tbody></table><figure><img src="5-3.png" alt="5-3" /><figcaption aria-hidden="true">5-3</figcaption></figure><p>你可以更直观的使用 <code>vimdiff</code>工具比较一下它们之间的差别：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">temp=shiyanlou</span><br><span class="line"><span class="built_in">export</span> temp_env=shiyanlou</span><br><span class="line"><span class="built_in">env</span>|<span class="built_in">sort</span>&gt;env.txt</span><br><span class="line"><span class="built_in">export</span>|<span class="built_in">sort</span>&gt;export.txt</span><br><span class="line"><span class="built_in">set</span>|<span class="built_in">sort</span>&gt;set.txt</span><br></pre></td></tr></table></figure><p>上述操作将命令输出通过管道 <code>|</code> 使用 <code>sort</code>命令排序，再重定向到对象文本文件中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vimdiff env.txt export.txt set.txt</span><br></pre></td></tr></table></figure><p>使用 <code>vimdiff</code> 工具比较导出的几个文件的内容，退出<code>vimdiff</code> 需要按下 Esc 后输入 <code>:q</code> 即可退出。</p><p>关于哪些变量是环境变量，可以简单地理解成在当前进程的子进程有效则为环境变量，否则不是（有些人也将所有变量统称为环境变量，只是以全局环境变量和局部环境变量进行区分，我们只要理解它们的实质区别即可）</p><p>我们这里用 <code>export</code> 命令来体会一下，先在 Shell中设置一个变量 <code>temp=shiyanlou</code>，然后再新创建一个子 Shell查看 <code>temp</code> 变量的值：</p><figure><img src="1.png" alt="1" /><figcaption aria-hidden="true">1</figcaption></figure><p><strong>注意：为了与普通变量区分，通常我们习惯将环境变量名设为大写。</strong></p><h4 id="变量时效">4.2 变量时效</h4><p>当关机后，或者关闭当前的 shell之后，环境变量就失效了。怎样才能让环境变量<strong>永久生效</strong>呢？</p><p>按变量的生存周期来划分，Linux 变量可分为两类：</p><ol type="1"><li>永久的：需要<strong>修改配置文件</strong>，变量永久生效；</li><li>临时的：使用 export 命令行声明即可，变量在关闭 shell 时失效。</li></ol><p>这里介绍两个重要文件 <code>/etc/bashrc</code>（有的 Linux没有这个文件） 和 <code>/etc/profile</code></p><p>它们分别存放的是 shell变量和环境变量。还有要注意区别的是每个用户目录下的一个隐藏文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .profile 可以用 ls -a 查看</span></span><br><span class="line"><span class="built_in">cd</span> /home/shiyanlou</span><br><span class="line"><span class="built_in">ls</span> -a</span><br></pre></td></tr></table></figure><p>这个 <code>·只对当前用户永久</code>生效</p><p>因为它保存在<strong>当前用户</strong>的 Home目录下，当切换用户时，工作目录可能一并被切换到对应的目录中，这个文件就无法生效</p><p>写在 <code>/etc/profile</code>里面的是<strong>对所有用户永久生效</strong>，所以如果想要添加一个永久生效的环境变量，只需要打开<code>/etc/profile</code>，在最后加上要添加的环境变量</p><h4 id="path变量">4.3 PATH变量</h4><p>你可能很早之前就有疑问，我们在 Shell 中输入一个命令，Shell是怎么知道去哪找到这个命令然后执行的呢？</p><p>这是通过环境变量 <code>PATH</code> 来进行搜索的，熟悉 Windows的用户可能知道 Windows 中的也是有这么一个 PATH 环境变量。这个<code>PATH</code> 里面就保存了 Shell 中执行的命令的搜索路径。</p><ol type="1"><li>查看PATH内容</li></ol><p>查看 <code>PATH</code> 环境变量的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>默认情况下你会看到如下输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games</span><br></pre></td></tr></table></figure><p>如果你还记得 Linux目录结构那一节的内容，你就应该知道上面这些目录下放的是哪一类文件了。</p><p>通常这一类目录下放的都是可执行文件，当我们在 Shell中执行一个命令时，系统就会按照 PATH中设定的路径按照顺序依次到目录中去查找，如果存在同名的命令，则执行先找到的那个。</p><ol start="3" type="1"><li>自定义PATH变量</li></ol><p>现在，我们添加自定义路径到“ PATH ”环境变量。在前面我们应该注意到<code>PATH</code> 里面的路径是以 <code>:</code>作为分割符的，所以我们可以这样添加自定义路径：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PATH=<span class="variable">$PATH</span>:/home/shiyanlou/mybin</span><br></pre></td></tr></table></figure><p><strong>注意这里一定要使用绝对路径。</strong></p><p>现在你就可以在任意目录执行那两个命令了（注意需要去掉前面的<code>./</code>）。</p><p>你可能会意识到这样还并没有很好的解决问题，因为我给 PATH环境变量追加了一个路径，它也只是在当前 Shell有效，我一旦退出终端，再打开就会发现又失效了</p><p>有没有方法让添加的环境变量全局有效？或者每次启动 Shell时自动执行上面添加自定义路径到 PATH 的命令？</p><p>下面我们就来说说后一种方式——让它自动执行。</p><p>在每个用户的 home 目录中有一个 Shell每次启动时会默认执行一个配置脚本，以初始化环境，包括添加一些用户自定义环境变量等等。</p><p>实验楼的环境使用的 Shell 是 zsh，它的配置文件是<code>.zshrc</code>，相应的如果使用的 Shell 是 Bash，则配置文件为<code>.bashrc</code></p><p>它们在 <code>etc</code>下还都有一个或多个全局的配置文件，不过我们一般只修改用户目录下的配置文件。</p><p>Shell 的种类有很多，可以使用 <code>cat /etc/shells</code>命令查看当前系统已安装的 Shell</p><figure><img src="3.png" alt="3" /><figcaption aria-hidden="true">3</figcaption></figure><p>我们可以简单地使用下面命令直接添加内容到 <code>.zshrc</code>中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;PATH=<span class="variable">$PATH</span>:/home/shiyanlou/mybin&quot;</span> &gt;&gt; .zshrc</span><br></pre></td></tr></table></figure><ol start="4" type="1"><li>修改PATH变量</li></ol><p>PATH变量的修改有以下几种方式：</p><table><colgroup><col style="width: 40%" /><col style="width: 59%" /></colgroup><thead><tr class="header"><th>变量设置方式</th><th>说明</th></tr></thead><tbody><tr class="odd"><td><code>$&#123;变量名#匹配字串&#125;</code></td><td>从头向后开始匹配，删除符合匹配字串的最短数据</td></tr><tr class="even"><td><code>$&#123;变量名##匹配字串&#125;</code></td><td>从头向后开始匹配，删除符合匹配字串的最长数据</td></tr><tr class="odd"><td><code>$&#123;变量名%匹配字串&#125;</code></td><td>从尾向前开始匹配，删除符合匹配字串的最短数据</td></tr><tr class="even"><td><code>$&#123;变量名%%匹配字串&#125;</code></td><td>从尾向前开始匹配，删除符合匹配字串的最长数据</td></tr><tr class="odd"><td><code>$&#123;变量名/旧的字串/新的字串&#125;</code></td><td>将符合旧字串的第一个字串替换为新的字串</td></tr><tr class="even"><td><code>$&#123;变量名//旧的字串/新的字串&#125;</code></td><td>将符合旧字串的全部字串替换为新的字串</td></tr></tbody></table><p>比如我们可以修改前面添加到 PATH 的环境变量，将添加的 mybin目录从环境变量里删除。为了避免操作失误导致命令找不到，我们先将 PATH赋值给一个新的自定义变量 mypath：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mypath=<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$mypath</span></span><br><span class="line">mypath=<span class="variable">$&#123;mypath%/home/shiyanlou/mybin&#125;</span></span><br><span class="line"><span class="comment"># 或使用通配符,*表示任意多个任意字符</span></span><br><span class="line">mypath=<span class="variable">$&#123;mypath%*/mybin&#125;</span></span><br></pre></td></tr></table></figure><h4 id="环境变量删除">4.4 环境变量删除</h4><p>可以使用 <code>unset</code> 命令删除一个环境变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">unset</span> mypath</span><br></pre></td></tr></table></figure><h4 id="环境变量立即生效">4.5 环境变量立即生效</h4><p>前面我们在 Shell 中修改了一个配置脚本文件之后（比如 zsh 的配置文件home 目录下的<code>.zshrc</code>），每次都要退出终端重新打开甚至重启主机之后其才能生效，很是麻烦，我们可以使用<code>source</code> 命令来让其立即生效，如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/shiyanlou</span><br><span class="line"><span class="built_in">source</span> .zshrc</span><br></pre></td></tr></table></figure><p><code>source</code> 命令还有一个别名就是<code>.</code>，上面的命令如果替换成 <code>.</code> 的方式就该是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">. ./.zshrc</span><br></pre></td></tr></table></figure><p>在使用<code>.</code>的时候，需要注意<strong>与表示当前路径的那个点区分开</strong>。</p><p>注意第一个点后面有一个空格，而且后面的文件必须指定完整的绝对或相对路径名，source则不需要</p><h2 id="位置变量">位置变量</h2><p>位置变量用于接收从命令行传递到脚本的参数：<code>$0</code>，<code>$1</code>，<code>$2</code>，<code>$3</code>...</p><p><code>$0</code> 就是脚本文件自身的名字，<code>$1</code>是第一个参数，<code>$2</code>是第二个参数，<code>$3</code>是第三个参数，然后是第四个</p><p><code>$9</code>之后的位置参数就必须用大括号括起来了，比如，<code>$&#123;10&#125;</code>，<code>$&#123;11&#125;</code>，<code>$&#123;12&#125;</code>。</p><h4 id="位置参数实例">位置参数实例</h4><p>在运行脚本的时候，有时候是需要参数的，这里我们学习如何获取参数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim test30.sh</span><br></pre></td></tr></table></figure><h2 id="特殊变量">特殊变量</h2><ul><li><code>$#</code> ： 传递到脚本的参数个数</li><li><code>$*</code> ：以一个单字符串显示所有向脚本传递的参数。与位置变量不同,此选项参数可超过9 个</li><li><code>$$</code> ： 脚本运行的当前进程 ID 号</li><li><code>$!</code> ： 后台运行的最后一个进程的进程 ID 号</li><li><code>$@</code> ： 与 $*相同,但是使用时加引号，并在引号中返回每个参数</li><li><code>$?</code> ： 显示最后命令的退出状态。 0表示没有错误，其他任何值表明有错误。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;变量&quot;&gt;变量&lt;/h2&gt;
&lt;h4 id=&quot;概念&quot;&gt;2.1 概念&lt;/h4&gt;
&lt;p&gt;Shell
变量就是计算机中用于记录一个值（不一定是数值，也可以是字符或字符串）的符号，而这些符号将用于不同的运算处理中。通常变量与值是一对一的关系，可以通过表达式读取它的值并赋值给其它</summary>
      
    
    
    
    
    <category term="Linux" scheme="http://www.larryai.com/tags/Linux/"/>
    
    <category term="Shell" scheme="http://www.larryai.com/tags/Shell/"/>
    
  </entry>
  
</feed>
